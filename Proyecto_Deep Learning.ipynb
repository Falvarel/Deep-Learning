{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8up9kWdin3v"
   },
   "source": [
    "# **Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KX8zKrS-hRJk"
   },
   "source": [
    "# Lab assignment: the hunger games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vanYztAMhRJt"
   },
   "source": [
    "<table><tr>\n",
    "    <td><img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/breakfast.jpg\" style=\"width:300px;height:300px;\"></td>\n",
    "    <td><img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/hamburger.jpg\" style=\"width:300px;height:300px;\"></td>\n",
    "    <td><img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/fruits.jpg\" style=\"width:300px;height:300px;\"></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6E7BW750hRJu"
   },
   "source": [
    "In this assignment we will face a challenging image classification problem, building a deep learning model that is able to classify different kinds of foods. Let the hunger games begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mnn_FAm8hRJv"
   },
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZmf8R9DhRJy"
   },
   "source": [
    "The following code will embed any plots into the notebook instead of generating a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DxmdgWqNhRJz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K733uf0ghRJ2"
   },
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZYPquwFhRJ2"
   },
   "source": [
    "We will use a food images dataset available at [Kaggle](https://www.kaggle.com/trolukovich/food11-image-dataset). To download it you will need to create a user account in Kaggle, and obtain your API credential by following the instructions on [this section](https://github.com/Kaggle/kaggle-api#api-credentials). Once you have your credentials JSON file, you can inform this notebook of them by setting the appropriate enviroment variables, as follows\n",
    "\n",
    "    import os\n",
    "\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = \"YOUR KAGGLE USERNAME HERE\"\n",
    "    os.environ[\"KAGGLE_KEY\"] = \"YOUR KAGGLE KEY HERE\"\n",
    "    \n",
    "Once this is done, you will be able to download the dataset to this computer using the command\n",
    "\n",
    "    !kaggle datasets download trolukovich/food11-image-dataset --unzip -p YOUR_LOCAL_FOLDER\n",
    "    \n",
    "where you should write a valid directory in your computer in \"YOUR_LOCAL_FOLDER\". If you are fine with downloading the data in the same folder as this notebook, just skip the `-p YOUR_LOCAL_FOLDER` part of the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "pX-eF84bo1Qg",
    "outputId": "c3eb8a16-0d68-4529-a368-69e26a7fe2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading food11-image-dataset.zip to /content\n",
      " 99% 1.07G/1.08G [00:07<00:00, 155MB/s]\n",
      "100% 1.08G/1.08G [00:07<00:00, 152MB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"XXX\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"XXX\"\n",
    "\n",
    "!kaggle datasets download trolukovich/food11-image-dataset --unzip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F4QGJPujiNro"
   },
   "outputs": [],
   "source": [
    "TRAINDIR = \"/content/training\"\n",
    "VALDIR = \"/content/validation\"\n",
    "TESTDIR = \"/content/evaluation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmh27gIEhRJ4"
   },
   "source": [
    "Take now a look into the folder where you downloaded the data. You will find it is made up of three subfolders:\n",
    "\n",
    "* **training**, containing the images to use to train the model.\n",
    "* **validation**, containing additional images you could use as more training data, or for some kind of validation strategy such as Early Stopping.\n",
    "* **evaluation**, containing the images you must use to test your model. Images in this folder can **only** be used to measure the model performance after the training procedure is completed.\n",
    "\n",
    "Furthermore, within each one of these folders you will find one folder for each one of the 11 classes in this problem:\n",
    "\n",
    "* Bread\n",
    "* Dairy product\n",
    "* Dessert\n",
    "* Egg\n",
    "* Fried food\n",
    "* Meat\n",
    "* Noodles-Pasta\n",
    "* Rice\n",
    "* Seafood\n",
    "* Soup\n",
    "* Vegetable-Fruit\n",
    "\n",
    "This is a standard structure for organizing image datasets: one folder per class. To easen the following data processing steps, let us define some variables telling us where the data is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtoTuArehRJ5"
   },
   "source": [
    "Let's plot a random sample of training images from each class, using the ipyplot package. If you are running this notebook in Google Colab, you will need to install this package first with\n",
    "\n",
    "    !pip install ipyplot\n",
    "\n",
    "You can inspect each class by clicking the different tabs in the interface that will appear when running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import ipyplot\n",
    "import numpy as np\n",
    "\n",
    "all_images = glob(f\"{TRAINDIR}/*/*.jpg\")  # Get all image paths\n",
    "np.random.shuffle(all_images)  # Randomize to show different images each run\n",
    "all_labels = [f.split(\"/\")[-2] for f in all_images]  # Extract class names from path\n",
    "\n",
    "ipyplot.plot_class_tabs(all_images, all_labels, max_imgs_per_tab=6, img_width=300, force_b64=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikYtQyR-hRJ6"
   },
   "source": [
    "### Class reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWsLot-7hRJ6"
   },
   "source": [
    "To make the problem more approachable for this exercise, we will focus on just six classes: `Bread`, `Dairy product`, `Dessert`, `Egg`, `Fried food` and `Meat`. To do so, we will delete from the downloaded data the folders from other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "TXoNw1-thRJ7",
    "outputId": "bbbbb9b4-ce66-45b2-8861-d7db29f22a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting /content/evaluation/Soup...\n",
      "Deleting /content/evaluation/Seafood...\n",
      "Deleting /content/evaluation/Rice...\n",
      "Deleting /content/evaluation/Vegetable-Fruit...\n",
      "Deleting /content/evaluation/Noodles-Pasta...\n",
      "Deleting /content/validation/Soup...\n",
      "Deleting /content/validation/Seafood...\n",
      "Deleting /content/validation/Rice...\n",
      "Deleting /content/validation/Vegetable-Fruit...\n",
      "Deleting /content/validation/Noodles-Pasta...\n",
      "Deleting /content/training/Soup...\n",
      "Deleting /content/training/Seafood...\n",
      "Deleting /content/training/Rice...\n",
      "Deleting /content/training/Vegetable-Fruit...\n",
      "Deleting /content/training/Noodles-Pasta...\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "valid_classes = {\"Bread\", \"Dairy product\", \"Dessert\", \"Egg\", \"Fried food\", \"Meat\"}\n",
    "datasets = {TRAINDIR, VALDIR, TESTDIR}\n",
    "\n",
    "for dataset in datasets:\n",
    "    for classdir in glob(f\"{dataset}/*\"):  # Find subfolders with classes\n",
    "        if classdir.split(\"/\")[-1] not in valid_classes:  # Ignore those in valid_classes\n",
    "            print(f\"Deleting {classdir}...\")\n",
    "            for fname in glob(f\"{classdir}/*.jpg\"):  # Remove each image file\n",
    "                os.remove(fname)\n",
    "            os.rmdir(classdir)  # Remove folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fncCfOYihRJ7"
   },
   "source": [
    "## Image processing from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wTWrPr-hRJ7"
   },
   "source": [
    "This dataset of images is large, with images of larger resolution than in the tutorial MNIST problem, each one having different sizes and image ratios. Also, while for MNIST we had a keras function that prepared the dataset for us, this time we will need to do some loading and image processing work.\n",
    "\n",
    "A convenient way to do this work is through the use of Keras `image_dataset_from_directory` function. This function creates a TensorFlow `Dataset` with the images in the directory, loading images dynamically only when the neural network needs to use them, and also allowing us to specify some useful preprocessing options.\n",
    "\n",
    "For example, we can create such a `Dataset` with the data in the training folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-edpP7-NhRJ8",
    "outputId": "93a49093-2f5e-43bd-bd9d-5ce0b7aaf5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6082 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "image_size = 32\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    TRAINDIR, \n",
    "    image_size = (image_size, image_size),\n",
    "    batch_size = batch_size, \n",
    "    label_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGEdEuF5hRJ8"
   },
   "source": [
    "Note the parameters used to configure the dataset:\n",
    "\n",
    "* The **directory** from which to load the images.\n",
    "* An **image size** that will be used to resize all the images to a common resolution, here 32x32.\n",
    "* The **size of the batches** of images to be generated. Note we define this parameter here instead in the network fit step, as the `Dataset` will make use of this information to keep in memory only a few batches of images at the same time in order to save memory.\n",
    "* The **label mode**, that is, the encoding used for the labels. `categorical` means we will use one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgeGjQDVhRJ9"
   },
   "source": [
    "A `Dataset` object works like a Python generator, which means we can iterate over it to obtain batches of processed images. For instance, to get the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPAIrHu7hRJ9",
    "outputId": "27db9578-32c5-4e0a-8e8f-f7c78eaf3c7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input batch: (64, 32, 32, 3)\n",
      "Shape of output batch: (64, 6)\n",
      "Input batch:\n",
      "[[[[108.03125  10.90625   5.6875 ]\n",
      "   [215.1875  163.875   159.625  ]\n",
      "   [  5.5625    2.1875    8.65625]\n",
      "   ...\n",
      "   [217.53125 228.53125 230.53125]\n",
      "   [222.      233.      235.     ]\n",
      "   [224.09375 235.09375 237.09375]]\n",
      "\n",
      "  [[  0.        1.5       0.     ]\n",
      "   [  0.        0.28125   0.     ]\n",
      "   [  0.        0.        0.     ]\n",
      "   ...\n",
      "   [217.96875 228.46875 231.46875]\n",
      "   [220.      234.      237.     ]\n",
      "   [222.      236.      239.     ]]\n",
      "\n",
      "  [[  7.9375    8.4375   10.4375 ]\n",
      "   [  0.        0.28125   0.     ]\n",
      "   [  0.        0.        0.     ]\n",
      "   ...\n",
      "   [215.      225.      224.     ]\n",
      "   [216.      226.      227.     ]\n",
      "   [217.5     226.5     231.5    ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[189.21875 205.21875 205.21875]\n",
      "   [188.34375 203.46875 203.90625]\n",
      "   [192.03125 206.03125 207.03125]\n",
      "   ...\n",
      "   [212.78125 226.78125 235.78125]\n",
      "   [221.4375  235.4375  246.4375 ]\n",
      "   [214.375   228.375   239.375  ]]\n",
      "\n",
      "  [[193.59375 207.59375 208.59375]\n",
      "   [196.65625 210.65625 211.65625]\n",
      "   [188.90625 202.90625 203.90625]\n",
      "   ...\n",
      "   [207.53125 221.53125 230.53125]\n",
      "   [213.78125 230.78125 240.78125]\n",
      "   [218.5     235.5     245.5    ]]\n",
      "\n",
      "  [[207.3125  218.8125  219.8125 ]\n",
      "   [205.84375 220.96875 221.125  ]\n",
      "   [213.9375  227.9375  230.9375 ]\n",
      "   ...\n",
      "   [212.625   229.625   237.625  ]\n",
      "   [213.0625  230.0625  238.0625 ]\n",
      "   [218.6875  235.6875  243.6875 ]]]\n",
      "\n",
      "\n",
      " [[[ 56.75     19.5       0.5    ]\n",
      "   [ 62.25     29.25      3.5    ]\n",
      "   [ 67.       29.75      3.5    ]\n",
      "   ...\n",
      "   [ 90.75     53.       13.75   ]\n",
      "   [ 80.5      48.        7.     ]\n",
      "   [ 84.5      50.75     12.     ]]\n",
      "\n",
      "  [[ 77.25     33.        4.5    ]\n",
      "   [ 96.75     48.25      9.25   ]\n",
      "   [ 78.       32.75      0.5    ]\n",
      "   ...\n",
      "   [ 79.75     49.5      14.     ]\n",
      "   [ 64.5      40.25      6.5    ]\n",
      "   [ 54.25     33.75      7.75   ]]\n",
      "\n",
      "  [[ 63.75     26.75      2.     ]\n",
      "   [ 91.5      48.25      6.75   ]\n",
      "   [ 51.5      66.      100.     ]\n",
      "   ...\n",
      "   [ 56.5      66.25     99.5    ]\n",
      "   [ 58.75     73.75     97.     ]\n",
      "   [ 70.       46.5       3.75   ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 80.25     65.       73.25   ]\n",
      "   [ 74.75     68.75     87.75   ]\n",
      "   [ 62.       62.75     76.25   ]\n",
      "   ...\n",
      "   [ 59.25     63.25     90.75   ]\n",
      "   [ 85.5      82.      100.     ]\n",
      "   [ 86.25     70.75     97.     ]]\n",
      "\n",
      "  [[ 66.25     70.25     89.75   ]\n",
      "   [ 95.5      77.       73.     ]\n",
      "   [ 67.       64.       65.5    ]\n",
      "   ...\n",
      "   [ 73.75     72.25     95.25   ]\n",
      "   [ 83.75     76.25     91.75   ]\n",
      "   [ 74.75     72.5     104.25   ]]\n",
      "\n",
      "  [[ 61.       75.      101.     ]\n",
      "   [ 60.75     66.75     96.     ]\n",
      "   [ 67.       60.5      65.25   ]\n",
      "   ...\n",
      "   [ 81.5      73.      105.5    ]\n",
      "   [ 67.25     56.       64.     ]\n",
      "   [102.25    105.25    123.25   ]]]\n",
      "\n",
      "\n",
      " [[[135.75    158.25    177.75   ]\n",
      "   [156.      180.25    198.     ]\n",
      "   [156.      181.5     200.     ]\n",
      "   ...\n",
      "   [103.5      66.5      37.5    ]\n",
      "   [ 78.5      49.75     24.     ]\n",
      "   [ 84.25     56.25     32.25   ]]\n",
      "\n",
      "  [[160.25    184.75    198.25   ]\n",
      "   [149.5     174.5     187.     ]\n",
      "   [137.25    160.25    174.25   ]\n",
      "   ...\n",
      "   [102.       62.5      33.75   ]\n",
      "   [ 84.75     53.75     28.25   ]\n",
      "   [ 74.       47.       22.5    ]]\n",
      "\n",
      "  [[150.5     178.      190.25   ]\n",
      "   [150.75    178.75    192.75   ]\n",
      "   [156.      182.      198.     ]\n",
      "   ...\n",
      "   [102.       65.5      36.25   ]\n",
      "   [ 85.75     54.75     29.25   ]\n",
      "   [ 72.75     45.75     21.25   ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[167.25    174.75    174.25   ]\n",
      "   [167.      176.      174.     ]\n",
      "   [168.      177.      174.     ]\n",
      "   ...\n",
      "   [112.5     111.       89.     ]\n",
      "   [157.25    161.75    152.25   ]\n",
      "   [157.25    163.75    154.75   ]]\n",
      "\n",
      "  [[150.25    165.75    175.25   ]\n",
      "   [170.75    180.75    185.25   ]\n",
      "   [167.75    179.75    178.75   ]\n",
      "   ...\n",
      "   [149.75    149.75    140.75   ]\n",
      "   [157.25    165.25    154.25   ]\n",
      "   [159.      165.      158.5    ]]\n",
      "\n",
      "  [[146.75    155.      152.25   ]\n",
      "   [146.      156.      157.5    ]\n",
      "   [131.5     149.5     156.5    ]\n",
      "   ...\n",
      "   [156.      163.      155.5    ]\n",
      "   [158.25    165.25    157.75   ]\n",
      "   [158.75    165.75    158.25   ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[168.5     111.75     99.5    ]\n",
      "   [ 54.5       6.        2.5    ]\n",
      "   [ 66.        9.5       1.5    ]\n",
      "   ...\n",
      "   [ 71.5       9.        9.     ]\n",
      "   [ 64.75      3.25      2.5    ]\n",
      "   [ 89.5       3.5       6.75   ]]\n",
      "\n",
      "  [[ 58.75     10.75      3.5    ]\n",
      "   [ 74.       13.5       3.     ]\n",
      "   [ 85.5      13.5       2.5    ]\n",
      "   ...\n",
      "   [ 51.75      1.75      0.     ]\n",
      "   [ 67.5       3.5       4.25   ]\n",
      "   [ 98.75      7.5      10.75   ]]\n",
      "\n",
      "  [[ 84.       12.25      1.5    ]\n",
      "   [ 89.25     15.75      0.75   ]\n",
      "   [121.75     24.75      6.5    ]\n",
      "   ...\n",
      "   [ 77.        3.5       4.5    ]\n",
      "   [ 80.25      4.5       3.     ]\n",
      "   [ 77.25      3.75      7.25   ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[243.5     254.25    250.5    ]\n",
      "   [245.75    253.25    249.75   ]\n",
      "   [245.75    254.5     249.75   ]\n",
      "   ...\n",
      "   [234.      234.      239.25   ]\n",
      "   [236.75    227.75    225.75   ]\n",
      "   [229.75    211.75    196.5    ]]\n",
      "\n",
      "  [[240.25    249.25    249.75   ]\n",
      "   [236.      245.      244.     ]\n",
      "   [240.5     250.5     250.5    ]\n",
      "   ...\n",
      "   [233.75    231.75    242.75   ]\n",
      "   [234.      227.25    237.     ]\n",
      "   [231.      219.      220.     ]]\n",
      "\n",
      "  [[112.75     50.75     45.75   ]\n",
      "   [187.5     177.25    187.75   ]\n",
      "   [249.25    253.25    254.75   ]\n",
      "   ...\n",
      "   [233.5     226.5     239.5    ]\n",
      "   [223.75    209.5     231.25   ]\n",
      "   [196.      161.5     191.75   ]]]\n",
      "\n",
      "\n",
      " [[[190.      206.5     196.5    ]\n",
      "   [128.      162.5     197.75   ]\n",
      "   [174.      208.      227.     ]\n",
      "   ...\n",
      "   [136.25     99.       80.5    ]\n",
      "   [ 77.25     62.       55.75   ]\n",
      "   [123.       98.5      81.     ]]\n",
      "\n",
      "  [[184.      202.75    174.75   ]\n",
      "   [240.      254.5     249.     ]\n",
      "   [157.25    174.25    189.5    ]\n",
      "   ...\n",
      "   [164.5     153.      143.25   ]\n",
      "   [174.25    157.25    133.75   ]\n",
      "   [176.5     156.5     127.     ]]\n",
      "\n",
      "  [[217.75    243.5     220.5    ]\n",
      "   [185.25    204.75    128.     ]\n",
      "   [216.      235.5     215.5    ]\n",
      "   ...\n",
      "   [171.5     154.75    130.25   ]\n",
      "   [163.      126.75     87.     ]\n",
      "   [185.25    149.75    104.75   ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 92.75     99.75    118.75   ]\n",
      "   [ 83.       90.      108.     ]\n",
      "   [ 96.      100.5     117.     ]\n",
      "   ...\n",
      "   [ 15.75     15.25     23.25   ]\n",
      "   [ 14.       12.       14.5    ]\n",
      "   [ 14.5      12.5      13.5    ]]\n",
      "\n",
      "  [[ 80.75     87.75    105.75   ]\n",
      "   [ 76.75     78.75     98.25   ]\n",
      "   [ 79.75     82.25     99.5    ]\n",
      "   ...\n",
      "   [  9.75      9.75      9.75   ]\n",
      "   [  8.75      8.75      8.75   ]\n",
      "   [ 12.75     12.75     12.75   ]]\n",
      "\n",
      "  [[ 91.5      97.      110.     ]\n",
      "   [ 74.5      81.5      94.     ]\n",
      "   [ 80.       85.25     99.5    ]\n",
      "   ...\n",
      "   [  9.75      9.75      9.75   ]\n",
      "   [  6.5       6.5       6.5    ]\n",
      "   [ 12.       10.       11.     ]]]\n",
      "\n",
      "\n",
      " [[[  0.        0.        0.     ]\n",
      "   [  0.        0.        0.     ]\n",
      "   [  0.        0.        0.     ]\n",
      "   ...\n",
      "   [  7.5       9.5      21.5    ]\n",
      "   [  2.        3.25      3.75   ]\n",
      "   [  1.5       1.5       1.5    ]]\n",
      "\n",
      "  [[  0.        0.        0.     ]\n",
      "   [  0.        0.        0.     ]\n",
      "   [  1.        1.        1.     ]\n",
      "   ...\n",
      "   [ 11.       13.       26.     ]\n",
      "   [  1.5       5.5       4.5    ]\n",
      "   [ 11.       13.5      24.     ]]\n",
      "\n",
      "  [[  0.        0.        0.     ]\n",
      "   [  0.        0.        0.     ]\n",
      "   [  0.        0.        0.     ]\n",
      "   ...\n",
      "   [ 11.25     13.25     26.5    ]\n",
      "   [  0.        4.        3.     ]\n",
      "   [ 14.5      16.5      29.     ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0.        2.5       1.5    ]\n",
      "   [  0.        2.        0.5    ]\n",
      "   [112.25    106.75    165.75   ]\n",
      "   ...\n",
      "   [  0.        3.        2.     ]\n",
      "   [  0.        2.        1.     ]\n",
      "   [  0.        1.5       0.5    ]]\n",
      "\n",
      "  [[  0.        2.        1.     ]\n",
      "   [  0.        1.75      0.75   ]\n",
      "   [ 36.25     31.75     46.25   ]\n",
      "   ...\n",
      "   [  0.        3.        2.     ]\n",
      "   [  0.        2.        1.     ]\n",
      "   [  0.        2.        1.     ]]\n",
      "\n",
      "  [[  0.        2.        1.     ]\n",
      "   [  0.        2.5       1.5    ]\n",
      "   [  0.        2.        1.     ]\n",
      "   ...\n",
      "   [  0.        2.5       1.5    ]\n",
      "   [  0.        2.5       1.5    ]\n",
      "   [  0.5       1.        0.5    ]]]]\n",
      "Output batch:\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_dataset:\n",
    "    print(f\"Shape of input batch: {X_batch.shape}\")\n",
    "    print(f\"Shape of output batch: {y_batch.shape}\")\n",
    "    print(f\"Input batch:\\n{X_batch}\")\n",
    "    print(f\"Output batch:\\n{y_batch}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2UaPCEthRJ-"
   },
   "source": [
    "We can see that indeed the generator produces a tensor of the appropriate dimensions with the inputs for the neural network, and that the outputs have also been properly codified in one-hot form. However, there is still an issue with the data: the pixel values are in the range [0, 255], which might produce training problems. We will solve this later in the network definition. For now, let's move on and prepare a funcion that builds the training, validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0XAy13Sc1jEe"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "def  create_datasets(traindir, valdir, testdir, image_size, batch_size):\n",
    "\n",
    "  train_dataset = image_dataset_from_directory(\n",
    "      traindir, \n",
    "      image_size = (image_size, image_size),\n",
    "      batch_size = batch_size, \n",
    "      label_mode = 'categorical'\n",
    "  )\n",
    "\n",
    "  val_dataset = image_dataset_from_directory(\n",
    "      valdir, \n",
    "      image_size = (image_size, image_size),\n",
    "      batch_size = batch_size, \n",
    "      label_mode = 'categorical'\n",
    "  )\n",
    "    \n",
    "  test_dataset = image_dataset_from_directory(\n",
    "      testdir, \n",
    "      image_size = (image_size, image_size),\n",
    "      batch_size = batch_size, \n",
    "      label_mode = 'categorical'\n",
    "  )\n",
    "\n",
    "  return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wGaULQsjwJz"
   },
   "source": [
    "Let's test if the function you just implemented works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtZlNbHhiOIR",
    "outputId": "253f1656-8d46-446e-97ed-5d2e40980905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6082 files belonging to 6 classes.\n",
      "Found 2108 files belonging to 6 classes.\n",
      "Found 2070 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(TRAINDIR, VALDIR, TESTDIR, image_size=32, batch_size=64)\n",
    "\n",
    "# Test whether all returned objects are valid Tensorflow datasets\n",
    "assert isinstance(train_dataset, tf.data.Dataset)\n",
    "assert isinstance(val_dataset, tf.data.Dataset)\n",
    "assert isinstance(test_dataset, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLIo6LBfhRJ-"
   },
   "source": [
    "Now that we have our datasets we can train a deep learning model using them! For illustration purposes, let's build an extremely simple convolutional network. Note how we have added a special pre-processing layer `Rescaling` that takes care of normalizing the data to the range [0, 1].\n",
    "\n",
    "Be careful! This network will work, but has some flaws in its design you might want to fix in the network you will desing later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbwmYJiLhRJ_"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
    "model.add(Convolution2D(4, 3, activation='linear'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4v9OxA-AhRJ_"
   },
   "source": [
    "The `fit` method of a Keras model can receive a `Dataset` with training data, instead of a pair of tensors with (inputs, outputs). Since when building the `Dataset` we already specified the batch size, we don't need to do it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZXjs6CghRKA",
    "outputId": "09d15f22-2e88-4dcd-82a9-40b858f67f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 10s 89ms/step - loss: 1.7142 - accuracy: 0.2669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe16d36fc10>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_ux64pchRKA"
   },
   "source": [
    "Similarly, we can evaluate the performance of our model over our test `Dataset` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_kQhkY-hRKA",
    "outputId": "dde8b42c-28bb-44c5-9a2c-25a25ca8e2ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 9s 219ms/step - loss: 1.9268 - accuracy: 0.2343\n",
      "Loss 1.93, accuracy 23.4%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_dataset)\n",
    "print(f\"Loss {loss:.3}, accuracy {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlXf9OBehRKB"
   },
   "source": [
    "The accuracy might seem poor, but take into account we have used a very simple model and this problem has 6 classes. Will you be able to do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kZnaNQIhRKB"
   },
   "source": [
    "## Building your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMd6Lstb-ReB"
   },
   "source": [
    "#### **\"LeNet_01\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Jgz7w3VqhRKC"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"LeNet_01\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "\n",
    "image_size = 32\n",
    "\n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "LeNet_01 = Sequential()\n",
    "\n",
    "LeNet_01.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "LeNet_01.add(Convolution2D(\n",
    "    32, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_01.add(BatchNormalization())\n",
    "\n",
    "LeNet_01.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_01.add(Convolution2D(\n",
    "    64, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_01.add(BatchNormalization())\n",
    "\n",
    "LeNet_01.add(MaxPooling2D(pool_size=(pool_size, pool_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "YjKATwts6FRq"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "LeNet_01.add(Flatten())\n",
    "LeNet_01.add(Dense(256, activation=\"relu\"))\n",
    "LeNet_01.add(Dropout(0.75))\n",
    "LeNet_01.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "e_wusrc86FYJ"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "LeNet_01.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iln2j7xS6FaP",
    "outputId": "c1c315df-6fef-49b5-d7f8-676bdd1ce5e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "96/96 - 7s - loss: 2.0403 - accuracy: 0.2831\n",
      "Epoch 2/20\n",
      "96/96 - 6s - loss: 1.6204 - accuracy: 0.3206\n",
      "Epoch 3/20\n",
      "96/96 - 6s - loss: 1.5684 - accuracy: 0.3486\n",
      "Epoch 4/20\n",
      "96/96 - 6s - loss: 1.5299 - accuracy: 0.3528\n",
      "Epoch 5/20\n",
      "96/96 - 6s - loss: 1.5056 - accuracy: 0.3742\n",
      "Epoch 6/20\n",
      "96/96 - 6s - loss: 1.4590 - accuracy: 0.3869\n",
      "Epoch 7/20\n",
      "96/96 - 6s - loss: 1.4355 - accuracy: 0.4140\n",
      "Epoch 8/20\n",
      "96/96 - 6s - loss: 1.4247 - accuracy: 0.4107\n",
      "Epoch 9/20\n",
      "96/96 - 6s - loss: 1.4029 - accuracy: 0.4226\n",
      "Epoch 10/20\n",
      "96/96 - 6s - loss: 1.3844 - accuracy: 0.4193\n",
      "Epoch 11/20\n",
      "96/96 - 6s - loss: 1.3358 - accuracy: 0.4617\n",
      "Epoch 12/20\n",
      "96/96 - 6s - loss: 1.3118 - accuracy: 0.4625\n",
      "Epoch 13/20\n",
      "96/96 - 6s - loss: 1.2812 - accuracy: 0.4832\n",
      "Epoch 14/20\n",
      "96/96 - 6s - loss: 1.2342 - accuracy: 0.5046\n",
      "Epoch 15/20\n",
      "96/96 - 6s - loss: 1.2008 - accuracy: 0.5178\n",
      "Epoch 16/20\n",
      "96/96 - 6s - loss: 1.1884 - accuracy: 0.5286\n",
      "Epoch 17/20\n",
      "96/96 - 6s - loss: 1.2102 - accuracy: 0.5148\n",
      "Epoch 18/20\n",
      "96/96 - 6s - loss: 1.1744 - accuracy: 0.5398\n",
      "Epoch 19/20\n",
      "96/96 - 6s - loss: 1.0858 - accuracy: 0.5681\n",
      "Epoch 20/20\n",
      "96/96 - 6s - loss: 1.0335 - accuracy: 0.5936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f574ca090>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeNet_01.fit(\n",
    "    train_dataset, # Training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUIba4VN6D7n"
   },
   "outputs": [],
   "source": [
    "probs = LeNet_01.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8ZAT0XL6D-m",
    "outputId": "750374d7-0fb3-45c5-c7f1-5a9e18ed407f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.20054293e-02, 6.02992804e-05, 6.95663393e-02, 1.59418141e-03,\n",
       "        9.47257411e-03, 8.87301266e-01],\n",
       "       [1.58360433e-02, 1.45257695e-03, 9.06817615e-01, 4.99280286e-04,\n",
       "        1.48611376e-04, 7.52458572e-02],\n",
       "       [6.65064726e-04, 8.97512131e-04, 9.98250544e-01, 8.37463303e-05,\n",
       "        6.31299145e-07, 1.02385959e-04],\n",
       "       ...,\n",
       "       [1.12698786e-01, 3.08150407e-02, 3.78167838e-01, 6.13643602e-02,\n",
       "        7.21549913e-02, 3.44798952e-01],\n",
       "       [4.86004800e-01, 1.24727711e-02, 2.14583009e-01, 2.18560278e-01,\n",
       "        6.49203211e-02, 3.45888757e-03],\n",
       "       [2.86728472e-01, 1.26311732e-02, 2.43173897e-01, 1.07253335e-01,\n",
       "        2.45201886e-01, 1.05011284e-01]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PTvLCYz6EBg",
    "outputId": "ba6b5a48-cf82-499c-d293-402f4458adac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 3s 59ms/step - loss: 1.3601 - accuracy: 0.5300\n",
      "Test loss 1.36005437374115\n",
      "Test accuracy 0.5299516916275024\n"
     ]
    }
   ],
   "source": [
    "score = LeNet_01.evaluate(test_dataset)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYvB2G9R3dRD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4rArOKgbaIn"
   },
   "source": [
    "### **Conclusiones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etTW2Y0bW8c7"
   },
   "source": [
    "Dado que el modelo **\"LetNet_01\"** alcanza el rendimiento buscado se toma como válido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_4-6NfLGI0A"
   },
   "source": [
    "### **PRO**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE1H64xtqnvI"
   },
   "source": [
    "Ya tenemos un \"accuracy\" en train en torno al 40%, siendo el de test en torno al 34% por lo que tenemos algo de \"overfitting\" en la red neuronal entrenada. Para aumentar el \"accuracy\" y tratar de reducir el \"overfitting\" de la red vamos a definir una nueva, tratando de aplicar en ella algunos parámetros adicionales.\n",
    "\n",
    "Uno de los aspectos que vamos a utilizar es aumentar el tamaño de las imágenes de entrada para tratar de conseguir más datos de cada imagen. Para tratar esas imágenes más grandes vamos a incrementar el nº de capas de procesamiento de nuestra red y vamos a incluir otras técnicas para aumentar la variabilidad del dataset de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B24SjFhVGVmS",
    "outputId": "aa336065-e8ac-4b1c-ca75-717276989106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6082 files belonging to 6 classes.\n",
      "Found 2108 files belonging to 6 classes.\n",
      "Found 2070 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Datasets imágenes tamaño 128x128\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "train_dataset128, val_dataset128, test_dataset128 = create_datasets(TRAINDIR, VALDIR, TESTDIR, image_size=128, batch_size=64)\n",
    "\n",
    "# Test whether all returned objects are valid Tensorflow datasets\n",
    "assert isinstance(train_dataset128, tf.data.Dataset)\n",
    "assert isinstance(val_dataset128, tf.data.Dataset)\n",
    "assert isinstance(test_dataset128, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGrSfvdqGagS",
    "outputId": "73189beb-6ba6-44b7-a8ff-26f8e14b5e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6082 files belonging to 6 classes.\n",
      "Found 2108 files belonging to 6 classes.\n",
      "Found 2070 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Datasets imágenes tamaño 256x256\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "train_dataset256, val_dataset256, test_dataset256 = create_datasets(TRAINDIR, VALDIR, TESTDIR, image_size=256, batch_size=64)\n",
    "\n",
    "# Test whether all returned objects are valid Tensorflow datasets\n",
    "assert isinstance(train_dataset256, tf.data.Dataset)\n",
    "assert isinstance(val_dataset256, tf.data.Dataset)\n",
    "assert isinstance(test_dataset256, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtZUR7_gqnvR"
   },
   "source": [
    "#### **\"LeNet_02\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "v60tLGbpqnvR"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"LeNet_02\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.models import Sequential\n",
    "\n",
    "image_size=128\n",
    "\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "LeNet_02 = Sequential()\n",
    "\n",
    "LeNet_02.add(RandomFlip(mode=\"horizontal\"))\n",
    "LeNet_02.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_02.add(RandomRotation(factor=(-0.1,0.1)))\n",
    "LeNet_02.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#LeNet_02.add(RandomCrop(height=85, width=85))\n",
    "\n",
    "LeNet_02.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "LeNet_02.add(Convolution2D(\n",
    "    64, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_02.add(BatchNormalization())\n",
    "\n",
    "LeNet_02.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_02.add(Convolution2D(\n",
    "    64, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_02.add(BatchNormalization())\n",
    "\n",
    "LeNet_02.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_02.add(Convolution2D(\n",
    "    128, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_02.add(BatchNormalization())\n",
    "\n",
    "LeNet_02.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_02.add(Convolution2D(\n",
    "    128, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_02.add(BatchNormalization())\n",
    "\n",
    "LeNet_02.add(MaxPooling2D(pool_size=(pool_size, pool_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "1vucJlqyqnvR"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "LeNet_02.add(Flatten())\n",
    "LeNet_02.add(Dense(256, activation=\"relu\"))\n",
    "LeNet_02.add(Dropout(0.45))\n",
    "LeNet_02.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "YEeTCTNgqnvS"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "LeNet_02.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-7El-wyqnvS",
    "outputId": "ffb127d3-9390-4bec-9284-c2a0e1c0eb97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 11s - loss: 1.9719 - accuracy: 0.3053 - val_loss: 2.4724 - val_accuracy: 0.2367\n",
      "Epoch 2/20\n",
      "191/191 - 8s - loss: 1.6162 - accuracy: 0.3366 - val_loss: 1.6430 - val_accuracy: 0.3083\n",
      "Epoch 3/20\n",
      "191/191 - 8s - loss: 1.5775 - accuracy: 0.3520 - val_loss: 1.4322 - val_accuracy: 0.4303\n",
      "Epoch 4/20\n",
      "191/191 - 8s - loss: 1.5411 - accuracy: 0.3699 - val_loss: 1.4646 - val_accuracy: 0.3971\n",
      "Epoch 5/20\n",
      "191/191 - 8s - loss: 1.5202 - accuracy: 0.3731 - val_loss: 1.4421 - val_accuracy: 0.4108\n",
      "Epoch 6/20\n",
      "191/191 - 8s - loss: 1.4761 - accuracy: 0.3976 - val_loss: 2.9209 - val_accuracy: 0.3321\n",
      "Epoch 7/20\n",
      "191/191 - 8s - loss: 1.4677 - accuracy: 0.4127 - val_loss: 1.4540 - val_accuracy: 0.4004\n",
      "Epoch 8/20\n",
      "191/191 - 8s - loss: 1.4612 - accuracy: 0.4152 - val_loss: 1.4212 - val_accuracy: 0.4265\n",
      "Epoch 9/20\n",
      "191/191 - 8s - loss: 1.4331 - accuracy: 0.4217 - val_loss: 1.6428 - val_accuracy: 0.3676\n",
      "Epoch 10/20\n",
      "191/191 - 8s - loss: 1.4119 - accuracy: 0.4479 - val_loss: 1.4675 - val_accuracy: 0.4341\n",
      "Epoch 11/20\n",
      "191/191 - 8s - loss: 1.4026 - accuracy: 0.4553 - val_loss: 1.3887 - val_accuracy: 0.4587\n",
      "Epoch 12/20\n",
      "191/191 - 8s - loss: 1.3876 - accuracy: 0.4656 - val_loss: 1.5849 - val_accuracy: 0.4355\n",
      "Epoch 13/20\n",
      "191/191 - 8s - loss: 1.3601 - accuracy: 0.4735 - val_loss: 1.3618 - val_accuracy: 0.4554\n",
      "Epoch 14/20\n",
      "191/191 - 8s - loss: 1.3268 - accuracy: 0.4857 - val_loss: 1.7315 - val_accuracy: 0.4132\n",
      "Epoch 15/20\n",
      "191/191 - 8s - loss: 1.3304 - accuracy: 0.4962 - val_loss: 1.7252 - val_accuracy: 0.4198\n",
      "Epoch 16/20\n",
      "191/191 - 8s - loss: 1.3187 - accuracy: 0.4859 - val_loss: 1.3304 - val_accuracy: 0.4858\n",
      "Epoch 17/20\n",
      "191/191 - 8s - loss: 1.2825 - accuracy: 0.5074 - val_loss: 1.3950 - val_accuracy: 0.5085\n",
      "Epoch 18/20\n",
      "191/191 - 8s - loss: 1.2582 - accuracy: 0.5222 - val_loss: 1.6148 - val_accuracy: 0.4658\n",
      "Epoch 19/20\n",
      "191/191 - 8s - loss: 1.2489 - accuracy: 0.5288 - val_loss: 1.3441 - val_accuracy: 0.4829\n",
      "Epoch 20/20\n",
      "191/191 - 8s - loss: 1.2487 - accuracy: 0.5222 - val_loss: 1.2275 - val_accuracy: 0.5398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b48347a50>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "LeNet_02.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=256, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "qXof9FooqnvS"
   },
   "outputs": [],
   "source": [
    "probs = LeNet_02.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRV49mUeqnvT",
    "outputId": "233c6c41-ecc3-4b6b-f75c-15b4fae231a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8054570e-01, 7.8031518e-02, 3.6543319e-01, 9.3800917e-02,\n",
       "        1.4711839e-01, 1.3507034e-01],\n",
       "       [2.0207924e-01, 1.5819007e-01, 2.2820020e-01, 1.3225992e-01,\n",
       "        2.1580835e-01, 6.3462205e-02],\n",
       "       [9.3618065e-02, 3.0819002e-01, 2.6223880e-01, 2.3721616e-01,\n",
       "        6.5871388e-02, 3.2865580e-02],\n",
       "       ...,\n",
       "       [1.4244377e-04, 3.7992286e-04, 5.9555155e-01, 1.5435053e-05,\n",
       "        4.7771879e-05, 4.0386292e-01],\n",
       "       [1.5800887e-01, 6.8806656e-02, 2.8750533e-01, 6.7117617e-02,\n",
       "        3.0358168e-01, 1.1497986e-01],\n",
       "       [9.7606041e-02, 6.6495100e-05, 5.3270608e-02, 7.2183408e-04,\n",
       "        3.8696048e-01, 4.6137455e-01]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llVymXf9qnvT",
    "outputId": "7ceb3ecd-b692-43b1-d877-6b2e7a316b77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s 29ms/step - loss: 1.2246 - accuracy: 0.5440\n",
      "Test loss 1.224624752998352\n",
      "Test accuracy 0.5439613461494446\n"
     ]
    }
   ],
   "source": [
    "score = LeNet_02.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1E2gtmYfNYY"
   },
   "source": [
    "#### **\"LeNet_03\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "cvq_5PQefNYZ"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"LeNet_03\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.models import Sequential\n",
    "\n",
    "image_size=256\n",
    "\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "LeNet_03 = Sequential()\n",
    "\n",
    "LeNet_03.add(RandomFlip(mode=\"horizontal\"))\n",
    "LeNet_03.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_03.add(RandomRotation(factor=(-0.1,0.1)))\n",
    "LeNet_03.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_03.add(RandomCrop(height=128, width=128))\n",
    "\n",
    "LeNet_03.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "LeNet_03.add(Convolution2D(\n",
    "    64, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_03.add(BatchNormalization())\n",
    "\n",
    "LeNet_03.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_03.add(Convolution2D(\n",
    "    64, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_03.add(BatchNormalization())\n",
    "\n",
    "LeNet_03.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_03.add(Convolution2D(\n",
    "    128, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_03.add(BatchNormalization())\n",
    "\n",
    "LeNet_03.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_03.add(Convolution2D(\n",
    "    128, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_03.add(BatchNormalization())\n",
    "\n",
    "LeNet_03.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_03.add(Convolution2D(\n",
    "    256, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_03.add(BatchNormalization())\n",
    "\n",
    "LeNet_03.add(MaxPooling2D(pool_size=(pool_size, pool_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "z6ssl6wgfNYZ"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "LeNet_03.add(Flatten())\n",
    "LeNet_03.add(Dense(512, activation=\"relu\"))\n",
    "LeNet_03.add(Dropout(0.4))\n",
    "LeNet_03.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "DvFs_Al7fNYa"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "LeNet_03.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzXknsnNfNYa",
    "outputId": "dfb2bdca-0d65-47d6-8d5c-bb2890d4ace9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 14s - loss: 2.1306 - accuracy: 0.2728 - val_loss: 2.3654 - val_accuracy: 0.2415\n",
      "Epoch 2/20\n",
      "191/191 - 12s - loss: 1.6832 - accuracy: 0.3170 - val_loss: 1.6588 - val_accuracy: 0.2946\n",
      "Epoch 3/20\n",
      "191/191 - 12s - loss: 1.6336 - accuracy: 0.3351 - val_loss: 1.5410 - val_accuracy: 0.3610\n",
      "Epoch 4/20\n",
      "191/191 - 12s - loss: 1.5992 - accuracy: 0.3542 - val_loss: 1.5077 - val_accuracy: 0.3980\n",
      "Epoch 5/20\n",
      "191/191 - 12s - loss: 1.5610 - accuracy: 0.3703 - val_loss: 1.4402 - val_accuracy: 0.4336\n",
      "Epoch 6/20\n",
      "191/191 - 12s - loss: 1.5649 - accuracy: 0.3775 - val_loss: 1.6027 - val_accuracy: 0.3776\n",
      "Epoch 7/20\n",
      "191/191 - 12s - loss: 1.5391 - accuracy: 0.3800 - val_loss: 1.4879 - val_accuracy: 0.4293\n",
      "Epoch 8/20\n",
      "191/191 - 12s - loss: 1.5233 - accuracy: 0.4025 - val_loss: 1.8380 - val_accuracy: 0.3411\n",
      "Epoch 9/20\n",
      "191/191 - 12s - loss: 1.4979 - accuracy: 0.4043 - val_loss: 1.5867 - val_accuracy: 0.4260\n",
      "Epoch 10/20\n",
      "191/191 - 12s - loss: 1.5081 - accuracy: 0.4046 - val_loss: 1.7172 - val_accuracy: 0.3857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b108bfed0>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "LeNet_03.fit(\n",
    "    train_dataset256, # Training data\n",
    "    validation_data=val_dataset256,\n",
    "    batch_size=256, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "dXkaaA6sfNYa"
   },
   "outputs": [],
   "source": [
    "probs = LeNet_03.predict(test_dataset256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHS-T6GyfNYa",
    "outputId": "664550ea-3e65-479b-f864-a9897fd56cb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22204264, 0.10496853, 0.21231613, 0.3238781 , 0.10044695,\n",
       "        0.03634764],\n",
       "       [0.1755103 , 0.09802694, 0.15507923, 0.42139372, 0.11896059,\n",
       "        0.03102923],\n",
       "       [0.14411916, 0.04601154, 0.15305254, 0.16551422, 0.4060129 ,\n",
       "        0.08528964],\n",
       "       ...,\n",
       "       [0.10149255, 0.05892523, 0.5131337 , 0.11614926, 0.03620072,\n",
       "        0.1740985 ],\n",
       "       [0.22552486, 0.02892091, 0.3054738 , 0.06075696, 0.05740061,\n",
       "        0.3219228 ],\n",
       "       [0.1307102 , 0.1247412 , 0.32563496, 0.24119198, 0.07085649,\n",
       "        0.1068651 ]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCBqrGLafNYa",
    "outputId": "51998e02-272e-4595-ab86-158c40c2af6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 45ms/step - loss: 1.4166 - accuracy: 0.4556\n",
      "Test loss 1.4165751934051514\n",
      "Test accuracy 0.4555555582046509\n"
     ]
    }
   ],
   "source": [
    "score = LeNet_03.evaluate(test_dataset256)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQiDE3jqkcMy"
   },
   "source": [
    "#### **\"LeNet_04\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "J67qKp2YkcMy"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"LeNet_04\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.models import Sequential\n",
    "\n",
    "image_size=256\n",
    "\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "kernel_size = 4 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "LeNet_04 = Sequential()\n",
    "\n",
    "LeNet_04.add(RandomFlip(mode=\"horizontal\"))\n",
    "LeNet_04.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_04.add(RandomRotation(factor=(-0.1,0.1)))\n",
    "LeNet_04.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_04.add(RandomCrop(height=128, width=128))\n",
    "\n",
    "LeNet_04.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "LeNet_04.add(Convolution2D(\n",
    "    120, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_04.add(BatchNormalization())\n",
    "\n",
    "LeNet_04.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_04.add(Convolution2D(\n",
    "    256, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_04.add(BatchNormalization())\n",
    "\n",
    "LeNet_04.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_04.add(Convolution2D(\n",
    "    360, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_04.add(BatchNormalization())\n",
    "\n",
    "LeNet_04.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_04.add(Convolution2D(\n",
    "    360, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_04.add(BatchNormalization())\n",
    "\n",
    "LeNet_04.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_04.add(Convolution2D(\n",
    "    360, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_04.add(BatchNormalization())\n",
    "\n",
    "LeNet_04.add(MaxPooling2D(pool_size=(pool_size, pool_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "-Vx4fysQkcMz"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "LeNet_04.add(Flatten())\n",
    "LeNet_04.add(Dense(512, activation=\"relu\"))\n",
    "LeNet_04.add(Dropout(0.4))\n",
    "LeNet_04.add(Dense(256, activation=\"relu\"))\n",
    "LeNet_04.add(Dropout(0.4))\n",
    "LeNet_04.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "07of9Zo_kcM0"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "LeNet_04.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAD6WZrSkcM0",
    "outputId": "0314b5a6-48a7-4d41-9d61-c60d7a4362e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 20s - loss: 1.8461 - accuracy: 0.2673 - val_loss: 1.7880 - val_accuracy: 0.1959\n",
      "Epoch 2/20\n",
      "191/191 - 17s - loss: 1.6903 - accuracy: 0.2895 - val_loss: 1.6405 - val_accuracy: 0.3083\n",
      "Epoch 3/20\n",
      "191/191 - 17s - loss: 1.6574 - accuracy: 0.3017 - val_loss: 1.6577 - val_accuracy: 0.2766\n",
      "Epoch 4/20\n",
      "191/191 - 17s - loss: 1.6573 - accuracy: 0.2948 - val_loss: 1.5587 - val_accuracy: 0.3710\n",
      "Epoch 5/20\n",
      "191/191 - 17s - loss: 1.6285 - accuracy: 0.3172 - val_loss: 1.5269 - val_accuracy: 0.3743\n",
      "Epoch 6/20\n",
      "191/191 - 17s - loss: 1.6214 - accuracy: 0.3195 - val_loss: 1.7345 - val_accuracy: 0.3041\n",
      "Epoch 7/20\n",
      "191/191 - 17s - loss: 1.6137 - accuracy: 0.3402 - val_loss: 1.6176 - val_accuracy: 0.3515\n",
      "Epoch 8/20\n",
      "191/191 - 17s - loss: 1.6051 - accuracy: 0.3320 - val_loss: 1.5033 - val_accuracy: 0.4198\n",
      "Epoch 9/20\n",
      "191/191 - 17s - loss: 1.6003 - accuracy: 0.3446 - val_loss: 1.7035 - val_accuracy: 0.2789\n",
      "Epoch 10/20\n",
      "191/191 - 17s - loss: 1.6001 - accuracy: 0.3463 - val_loss: 1.4779 - val_accuracy: 0.4080\n",
      "Epoch 11/20\n",
      "191/191 - 17s - loss: 1.5953 - accuracy: 0.3428 - val_loss: 1.6852 - val_accuracy: 0.3041\n",
      "Epoch 12/20\n",
      "191/191 - 17s - loss: 1.5881 - accuracy: 0.3494 - val_loss: 1.5863 - val_accuracy: 0.3468\n",
      "Epoch 13/20\n",
      "191/191 - 17s - loss: 1.5880 - accuracy: 0.3551 - val_loss: 1.5451 - val_accuracy: 0.3933\n",
      "Epoch 14/20\n",
      "191/191 - 17s - loss: 1.5571 - accuracy: 0.3768 - val_loss: 1.5370 - val_accuracy: 0.3809\n",
      "Epoch 15/20\n",
      "191/191 - 17s - loss: 1.5620 - accuracy: 0.3696 - val_loss: 1.6110 - val_accuracy: 0.3767\n",
      "Epoch 16/20\n",
      "191/191 - 17s - loss: 1.5746 - accuracy: 0.3673 - val_loss: 1.5202 - val_accuracy: 0.4184\n",
      "Epoch 17/20\n",
      "191/191 - 17s - loss: 1.5353 - accuracy: 0.3905 - val_loss: 1.4334 - val_accuracy: 0.4554\n",
      "Epoch 18/20\n",
      "191/191 - 17s - loss: 1.5365 - accuracy: 0.3826 - val_loss: 1.4362 - val_accuracy: 0.4350\n",
      "Epoch 19/20\n",
      "191/191 - 17s - loss: 1.5163 - accuracy: 0.3981 - val_loss: 1.6578 - val_accuracy: 0.3302\n",
      "Epoch 20/20\n",
      "191/191 - 17s - loss: 1.5145 - accuracy: 0.4002 - val_loss: 1.5318 - val_accuracy: 0.3966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06e4125d10>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "LeNet_04.fit(\n",
    "    train_dataset256, # Training data\n",
    "    validation_data=val_dataset256,\n",
    "    batch_size=64, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "Vy26xPrikcM0"
   },
   "outputs": [],
   "source": [
    "probs = LeNet_04.predict(test_dataset256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Imc-Pv9mkcM0",
    "outputId": "4f4b1039-ce65-41a4-ac6f-653e67e39de1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07110782, 0.01232759, 0.45568112, 0.02015596, 0.02725954,\n",
       "        0.41346794],\n",
       "       [0.21364509, 0.05447133, 0.14137186, 0.3384344 , 0.12619202,\n",
       "        0.12588526],\n",
       "       [0.14029978, 0.05671131, 0.4947207 , 0.09293626, 0.06833907,\n",
       "        0.14699288],\n",
       "       ...,\n",
       "       [0.23054138, 0.01920655, 0.22091192, 0.08061139, 0.1279186 ,\n",
       "        0.3208101 ],\n",
       "       [0.1851802 , 0.12959221, 0.29531616, 0.18701449, 0.07794872,\n",
       "        0.12494823],\n",
       "       [0.22437544, 0.0048871 , 0.09598884, 0.04297594, 0.32951248,\n",
       "        0.30226022]], dtype=float32)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WQa2yb_kcM0",
    "outputId": "1af71892-3b60-4d27-bc2d-d614d781159b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 49ms/step - loss: 1.5260 - accuracy: 0.3957\n",
      "Test loss 1.5260251760482788\n",
      "Test accuracy 0.395652174949646\n"
     ]
    }
   ],
   "source": [
    "score = LeNet_04.evaluate(test_dataset256)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adsQItgxm4PH"
   },
   "source": [
    "#### **\"LeNet_05\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "NuS0UMc9m4PH"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"LeNet_05\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.models import Sequential\n",
    "\n",
    "image_size=128\n",
    "\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "kernel_size = 4 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "LeNet_05 = Sequential()\n",
    "\n",
    "LeNet_05.add(RandomFlip(mode=\"horizontal\"))\n",
    "LeNet_05.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_05.add(RandomRotation(factor=(-0.1,0.1)))\n",
    "LeNet_05.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_05.add(RandomCrop(height=128, width=128))\n",
    "\n",
    "LeNet_05.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "LeNet_05.add(Convolution2D(\n",
    "    128, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_05.add(BatchNormalization())\n",
    "\n",
    "LeNet_05.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_05.add(Convolution2D(\n",
    "    256, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_05.add(BatchNormalization())\n",
    "\n",
    "LeNet_05.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_05.add(Convolution2D(\n",
    "    360, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_05.add(BatchNormalization())\n",
    "\n",
    "LeNet_05.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_05.add(Convolution2D(\n",
    "    360, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_05.add(BatchNormalization())\n",
    "\n",
    "LeNet_05.add(MaxPooling2D(pool_size=(pool_size, pool_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "chsPfxvdm4PH"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "LeNet_05.add(Flatten())\n",
    "LeNet_05.add(Dense(4096, activation=\"relu\"))\n",
    "LeNet_05.add(Dropout(0.4))\n",
    "LeNet_05.add(Dense(4096, activation=\"relu\"))\n",
    "LeNet_05.add(Dropout(0.4))\n",
    "LeNet_05.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "QYSRyyYIm4PI"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "LeNet_05.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCPAJMKrm4PI",
    "outputId": "e6220051-fa64-44a5-c3cf-a9e943c5eb9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 19s - loss: 3.4706 - accuracy: 0.2803 - val_loss: 2.2343 - val_accuracy: 0.1902\n",
      "Epoch 2/20\n",
      "191/191 - 16s - loss: 1.7233 - accuracy: 0.3131 - val_loss: 1.8644 - val_accuracy: 0.2310\n",
      "Epoch 3/20\n",
      "191/191 - 16s - loss: 1.7584 - accuracy: 0.3093 - val_loss: 1.6077 - val_accuracy: 0.3316\n",
      "Epoch 4/20\n",
      "191/191 - 16s - loss: 1.7404 - accuracy: 0.3114 - val_loss: 1.8338 - val_accuracy: 0.2514\n",
      "Epoch 5/20\n",
      "191/191 - 16s - loss: 1.7306 - accuracy: 0.3213 - val_loss: 2.2330 - val_accuracy: 0.2481\n",
      "Epoch 6/20\n",
      "191/191 - 16s - loss: 1.7259 - accuracy: 0.3119 - val_loss: 1.7394 - val_accuracy: 0.2448\n",
      "Epoch 7/20\n",
      "191/191 - 16s - loss: 1.6997 - accuracy: 0.3265 - val_loss: 2.0706 - val_accuracy: 0.2552\n",
      "Epoch 8/20\n",
      "191/191 - 16s - loss: 1.6930 - accuracy: 0.3269 - val_loss: 1.5868 - val_accuracy: 0.3657\n",
      "Epoch 9/20\n",
      "191/191 - 16s - loss: 1.6590 - accuracy: 0.3415 - val_loss: 1.5248 - val_accuracy: 0.3871\n",
      "Epoch 10/20\n",
      "191/191 - 16s - loss: 1.6389 - accuracy: 0.3430 - val_loss: 1.5765 - val_accuracy: 0.3624\n",
      "Epoch 11/20\n",
      "191/191 - 16s - loss: 1.6334 - accuracy: 0.3486 - val_loss: 1.5209 - val_accuracy: 0.3781\n",
      "Epoch 12/20\n",
      "191/191 - 16s - loss: 1.6201 - accuracy: 0.3491 - val_loss: 1.6040 - val_accuracy: 0.3805\n",
      "Epoch 13/20\n",
      "191/191 - 16s - loss: 1.6108 - accuracy: 0.3555 - val_loss: 1.4493 - val_accuracy: 0.4279\n",
      "Epoch 14/20\n",
      "191/191 - 16s - loss: 1.5844 - accuracy: 0.3698 - val_loss: 1.6960 - val_accuracy: 0.3458\n",
      "Epoch 15/20\n",
      "191/191 - 16s - loss: 1.5812 - accuracy: 0.3708 - val_loss: 1.4486 - val_accuracy: 0.4208\n",
      "Epoch 16/20\n",
      "191/191 - 16s - loss: 1.5669 - accuracy: 0.3690 - val_loss: 1.4195 - val_accuracy: 0.4165\n",
      "Epoch 17/20\n",
      "191/191 - 16s - loss: 1.5328 - accuracy: 0.3824 - val_loss: 2.1050 - val_accuracy: 0.3344\n",
      "Epoch 18/20\n",
      "191/191 - 16s - loss: 1.5219 - accuracy: 0.3877 - val_loss: 1.7596 - val_accuracy: 0.3643\n",
      "Epoch 19/20\n",
      "191/191 - 16s - loss: 1.5307 - accuracy: 0.3979 - val_loss: 1.9823 - val_accuracy: 0.3212\n",
      "Epoch 20/20\n",
      "191/191 - 16s - loss: 1.4992 - accuracy: 0.4142 - val_loss: 1.5954 - val_accuracy: 0.3748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06f4041790>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "LeNet_05.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=64, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "K_MJRnpKm4PI"
   },
   "outputs": [],
   "source": [
    "probs = LeNet_05.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DyuYjEwm4PJ",
    "outputId": "0c13e6b7-7c2e-4a2e-8172-bae235756d99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3125909 , 0.02136292, 0.06988531, 0.16051504, 0.35256255,\n",
       "        0.08308335],\n",
       "       [0.09492423, 0.26242226, 0.38774174, 0.10518987, 0.06767455,\n",
       "        0.0820474 ],\n",
       "       [0.05093157, 0.25259507, 0.5651257 , 0.085617  , 0.01740827,\n",
       "        0.02832237],\n",
       "       ...,\n",
       "       [0.11123084, 0.15662013, 0.34573632, 0.14774717, 0.08865571,\n",
       "        0.15000978],\n",
       "       [0.4323015 , 0.05099925, 0.04530528, 0.04340688, 0.4134024 ,\n",
       "        0.01458475],\n",
       "       [0.09545962, 0.22143811, 0.3610211 , 0.2195411 , 0.05419194,\n",
       "        0.0483482 ]], dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xt9CWWr1m4PJ",
    "outputId": "260a12e6-13d0-4944-eb32-362bd82c46b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 32ms/step - loss: 1.5507 - accuracy: 0.3836\n",
      "Test loss 1.5506917238235474\n",
      "Test accuracy 0.38357487320899963\n"
     ]
    }
   ],
   "source": [
    "score = LeNet_05.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMy__3-0p_ty"
   },
   "source": [
    "#### **\"LeNet_06\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "5NOndy2Zp_ty"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"LeNet_06\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.models import Sequential\n",
    "\n",
    "image_size=128\n",
    "\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "LeNet_06 = Sequential()\n",
    "\n",
    "LeNet_06.add(RandomFlip(mode=\"horizontal\"))\n",
    "LeNet_06.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_06.add(RandomRotation(factor=(-0.1,0.1)))\n",
    "LeNet_06.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_06.add(RandomCrop(height=85, width=85))\n",
    "\n",
    "LeNet_06.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "LeNet_06.add(Convolution2D(\n",
    "    32, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_06.add(BatchNormalization())\n",
    "\n",
    "LeNet_06.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_06.add(Convolution2D(\n",
    "    64, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_06.add(BatchNormalization())\n",
    "\n",
    "LeNet_06.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_06.add(Convolution2D(\n",
    "    128, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_06.add(BatchNormalization())\n",
    "\n",
    "LeNet_06.add(MaxPooling2D(pool_size=(pool_size, pool_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "rx5LE8cIp_tz"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "LeNet_06.add(Flatten())\n",
    "LeNet_06.add(Dense(1024, activation=\"relu\"))\n",
    "LeNet_06.add(Dropout(0.5))\n",
    "LeNet_06.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "jxn9LXMOp_tz"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "LeNet_06.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uW6VgQSxp_tz",
    "outputId": "25dd6e1f-bb9b-41f6-f69b-39a0eb1c6bee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 - 11s - loss: 3.4718 - accuracy: 0.2631 - val_loss: 1.9086 - val_accuracy: 0.2410\n",
      "Epoch 2/50\n",
      "191/191 - 8s - loss: 1.7077 - accuracy: 0.3086 - val_loss: 1.7826 - val_accuracy: 0.2462\n",
      "Epoch 3/50\n",
      "191/191 - 8s - loss: 1.6385 - accuracy: 0.3200 - val_loss: 1.5416 - val_accuracy: 0.3643\n",
      "Epoch 4/50\n",
      "191/191 - 8s - loss: 1.6143 - accuracy: 0.3269 - val_loss: 1.5050 - val_accuracy: 0.4075\n",
      "Epoch 5/50\n",
      "191/191 - 8s - loss: 1.6178 - accuracy: 0.3420 - val_loss: 1.5577 - val_accuracy: 0.3491\n",
      "Epoch 6/50\n",
      "191/191 - 8s - loss: 1.6017 - accuracy: 0.3441 - val_loss: 1.5801 - val_accuracy: 0.3752\n",
      "Epoch 7/50\n",
      "191/191 - 8s - loss: 1.5858 - accuracy: 0.3463 - val_loss: 1.4826 - val_accuracy: 0.4089\n",
      "Epoch 8/50\n",
      "191/191 - 8s - loss: 1.5745 - accuracy: 0.3565 - val_loss: 1.5416 - val_accuracy: 0.3700\n",
      "Epoch 9/50\n",
      "191/191 - 8s - loss: 1.5767 - accuracy: 0.3602 - val_loss: 1.8172 - val_accuracy: 0.3202\n",
      "Epoch 10/50\n",
      "191/191 - 8s - loss: 1.5570 - accuracy: 0.3665 - val_loss: 1.5073 - val_accuracy: 0.3776\n",
      "Epoch 11/50\n",
      "191/191 - 8s - loss: 1.5499 - accuracy: 0.3693 - val_loss: 1.8690 - val_accuracy: 0.3212\n",
      "Epoch 12/50\n",
      "191/191 - 8s - loss: 1.5419 - accuracy: 0.3760 - val_loss: 1.8248 - val_accuracy: 0.3620\n",
      "Epoch 13/50\n",
      "191/191 - 8s - loss: 1.5430 - accuracy: 0.3818 - val_loss: 1.4135 - val_accuracy: 0.4231\n",
      "Epoch 14/50\n",
      "191/191 - 8s - loss: 1.5256 - accuracy: 0.3823 - val_loss: 1.6925 - val_accuracy: 0.3672\n",
      "Epoch 15/50\n",
      "191/191 - 8s - loss: 1.5113 - accuracy: 0.3844 - val_loss: 1.8069 - val_accuracy: 0.4061\n",
      "Epoch 16/50\n",
      "191/191 - 8s - loss: 1.5068 - accuracy: 0.4055 - val_loss: 1.5659 - val_accuracy: 0.3601\n",
      "Epoch 17/50\n",
      "191/191 - 8s - loss: 1.4825 - accuracy: 0.4114 - val_loss: 2.2959 - val_accuracy: 0.3800\n",
      "Epoch 18/50\n",
      "191/191 - 8s - loss: 1.4746 - accuracy: 0.4130 - val_loss: 2.0278 - val_accuracy: 0.3506\n",
      "Epoch 19/50\n",
      "191/191 - 8s - loss: 1.4860 - accuracy: 0.4106 - val_loss: 1.8841 - val_accuracy: 0.3515\n",
      "Epoch 20/50\n",
      "191/191 - 8s - loss: 1.4536 - accuracy: 0.4258 - val_loss: 1.6447 - val_accuracy: 0.3354\n",
      "Epoch 21/50\n",
      "191/191 - 8s - loss: 1.4713 - accuracy: 0.4247 - val_loss: 1.8270 - val_accuracy: 0.3714\n",
      "Epoch 22/50\n",
      "191/191 - 8s - loss: 1.4487 - accuracy: 0.4420 - val_loss: 1.7955 - val_accuracy: 0.3994\n",
      "Epoch 23/50\n",
      "191/191 - 8s - loss: 1.4542 - accuracy: 0.4300 - val_loss: 1.6567 - val_accuracy: 0.4028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b30d2b6d0>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "LeNet_06.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=64, # Batch size for the optimizer algorithm\n",
    "    epochs=50, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=10, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "Z4PSQtbZp_t0"
   },
   "outputs": [],
   "source": [
    "probs = LeNet_06.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXaF_W_4p_t0",
    "outputId": "a1d4b6f5-057d-423e-d021-c7742d35af50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23589157, 0.0440163 , 0.16817558, 0.17633902, 0.17667933,\n",
       "        0.19889818],\n",
       "       [0.2489544 , 0.01607711, 0.16696072, 0.09495644, 0.32523087,\n",
       "        0.14782053],\n",
       "       [0.11172562, 0.11255375, 0.4448231 , 0.17382877, 0.09572788,\n",
       "        0.06134091],\n",
       "       ...,\n",
       "       [0.40642926, 0.01189675, 0.05434922, 0.11631133, 0.3557462 ,\n",
       "        0.05526725],\n",
       "       [0.14000016, 0.05717981, 0.2731279 , 0.12943642, 0.1030966 ,\n",
       "        0.29715914],\n",
       "       [0.41237572, 0.01341014, 0.07585468, 0.20993933, 0.26378378,\n",
       "        0.02463632]], dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ziaFc6rCp_t0",
    "outputId": "1cd40c3e-4093-4aff-8164-da51994a3a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s 29ms/step - loss: 1.3986 - accuracy: 0.4319\n",
      "Test loss 1.3985600471496582\n",
      "Test accuracy 0.4318840503692627\n"
     ]
    }
   ],
   "source": [
    "score = LeNet_06.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcWTLhRwwmvN"
   },
   "source": [
    "#### **\"LeNet_07\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "OUndhHjmwmvN"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"LeNet_07\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling, RandomContrast\n",
    "from keras.models import Sequential\n",
    "\n",
    "image_size=128\n",
    "\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "LeNet_07 = Sequential()\n",
    "\n",
    "LeNet_07.add(RandomFlip(mode=\"horizontal\"))\n",
    "#LeNet_07.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "LeNet_07.add(RandomRotation(factor=(-0.2,0.2)))\n",
    "#LeNet_07.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#LeNet_07.add(RandomCrop(height=85, width=85))\n",
    "#LeNet_07.add(RandomContrast(factor=0.2))\n",
    "\n",
    "#LeNet_07.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "LeNet_07.add(Convolution2D(\n",
    "    32, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_07.add(BatchNormalization())\n",
    "\n",
    "LeNet_07.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_07.add(Convolution2D(\n",
    "    64, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_07.add(BatchNormalization())\n",
    "\n",
    "LeNet_07.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "LeNet_07.add(Convolution2D(\n",
    "    128, # Number convolution channels to generate\n",
    "    (kernel_size, kernel_size), # Size of convolution kernels\n",
    "    padding='valid', # Strategy to deal with borders\n",
    "    input_shape=(img_rows, img_cols, 3), # Size = image rows x image columns x channels\n",
    "    activation=\"relu\"  # Activation function after the convolution\n",
    "))\n",
    "\n",
    "LeNet_07.add(BatchNormalization())\n",
    "\n",
    "LeNet_07.add(MaxPooling2D(pool_size=(pool_size, pool_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "WsLtju6jwmvO"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "\n",
    "LeNet_07.add(Flatten())\n",
    "LeNet_07.add(Dense(1024, activation=\"relu\"))\n",
    "LeNet_07.add(Dropout(0.4))\n",
    "LeNet_07.add(Dense(1024, activation=\"relu\"))\n",
    "LeNet_07.add(Dropout(0.4))\n",
    "LeNet_07.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "UEeAbNnxwmvO"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "LeNet_07.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78m-XJ_SwmvO",
    "outputId": "e3a17125-ef5d-42a0-8f42-0fdaad77f81e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "191/191 - 10s - loss: 4.4189 - accuracy: 0.2647 - val_loss: 1.6051 - val_accuracy: 0.3036\n",
      "Epoch 2/40\n",
      "191/191 - 8s - loss: 1.7472 - accuracy: 0.3178 - val_loss: 1.5938 - val_accuracy: 0.3311\n",
      "Epoch 3/40\n",
      "191/191 - 8s - loss: 1.6055 - accuracy: 0.3418 - val_loss: 1.5421 - val_accuracy: 0.3397\n",
      "Epoch 4/40\n",
      "191/191 - 8s - loss: 1.5498 - accuracy: 0.3760 - val_loss: 1.5321 - val_accuracy: 0.3705\n",
      "Epoch 5/40\n",
      "191/191 - 8s - loss: 1.5060 - accuracy: 0.3870 - val_loss: 1.4908 - val_accuracy: 0.3781\n",
      "Epoch 6/40\n",
      "191/191 - 8s - loss: 1.4875 - accuracy: 0.3935 - val_loss: 1.5005 - val_accuracy: 0.4004\n",
      "Epoch 7/40\n",
      "191/191 - 8s - loss: 1.4657 - accuracy: 0.4138 - val_loss: 1.6967 - val_accuracy: 0.3814\n",
      "Epoch 8/40\n",
      "191/191 - 8s - loss: 1.4613 - accuracy: 0.4074 - val_loss: 1.4430 - val_accuracy: 0.4421\n",
      "Epoch 9/40\n",
      "191/191 - 8s - loss: 1.4475 - accuracy: 0.4268 - val_loss: 1.5721 - val_accuracy: 0.3847\n",
      "Epoch 10/40\n",
      "191/191 - 8s - loss: 1.4084 - accuracy: 0.4433 - val_loss: 1.4712 - val_accuracy: 0.4127\n",
      "Epoch 11/40\n",
      "191/191 - 8s - loss: 1.4153 - accuracy: 0.4332 - val_loss: 2.1774 - val_accuracy: 0.3629\n",
      "Epoch 12/40\n",
      "191/191 - 8s - loss: 1.3828 - accuracy: 0.4673 - val_loss: 2.0623 - val_accuracy: 0.3340\n",
      "Epoch 13/40\n",
      "191/191 - 8s - loss: 1.3949 - accuracy: 0.4490 - val_loss: 1.4516 - val_accuracy: 0.4507\n",
      "Epoch 14/40\n",
      "191/191 - 8s - loss: 1.3785 - accuracy: 0.4665 - val_loss: 2.2465 - val_accuracy: 0.3349\n",
      "Epoch 15/40\n",
      "191/191 - 8s - loss: 1.3622 - accuracy: 0.4808 - val_loss: 1.5199 - val_accuracy: 0.3975\n",
      "Epoch 16/40\n",
      "191/191 - 8s - loss: 1.3242 - accuracy: 0.4918 - val_loss: 1.3569 - val_accuracy: 0.4768\n",
      "Epoch 17/40\n",
      "191/191 - 8s - loss: 1.3231 - accuracy: 0.4854 - val_loss: 1.7281 - val_accuracy: 0.3871\n",
      "Epoch 18/40\n",
      "191/191 - 8s - loss: 1.2953 - accuracy: 0.5041 - val_loss: 2.2248 - val_accuracy: 0.3420\n",
      "Epoch 19/40\n",
      "191/191 - 8s - loss: 1.2768 - accuracy: 0.5143 - val_loss: 1.4005 - val_accuracy: 0.4322\n",
      "Epoch 20/40\n",
      "191/191 - 8s - loss: 1.2747 - accuracy: 0.5192 - val_loss: 1.3120 - val_accuracy: 0.5176\n",
      "Epoch 21/40\n",
      "191/191 - 8s - loss: 1.2415 - accuracy: 0.5360 - val_loss: 1.8920 - val_accuracy: 0.3563\n",
      "Epoch 22/40\n",
      "191/191 - 8s - loss: 1.2343 - accuracy: 0.5334 - val_loss: 1.7503 - val_accuracy: 0.4208\n",
      "Epoch 23/40\n",
      "191/191 - 8s - loss: 1.2081 - accuracy: 0.5452 - val_loss: 1.8307 - val_accuracy: 0.4061\n",
      "Epoch 24/40\n",
      "191/191 - 8s - loss: 1.2063 - accuracy: 0.5566 - val_loss: 1.2925 - val_accuracy: 0.5185\n",
      "Epoch 25/40\n",
      "191/191 - 8s - loss: 1.1520 - accuracy: 0.5730 - val_loss: 1.6075 - val_accuracy: 0.4545\n",
      "Epoch 26/40\n",
      "191/191 - 8s - loss: 1.1496 - accuracy: 0.5630 - val_loss: 1.3543 - val_accuracy: 0.4910\n",
      "Epoch 27/40\n",
      "191/191 - 8s - loss: 1.1487 - accuracy: 0.5829 - val_loss: 1.4145 - val_accuracy: 0.4644\n",
      "Epoch 28/40\n",
      "191/191 - 8s - loss: 1.1048 - accuracy: 0.5883 - val_loss: 1.5173 - val_accuracy: 0.5014\n",
      "Epoch 29/40\n",
      "191/191 - 8s - loss: 1.1115 - accuracy: 0.5881 - val_loss: 1.4046 - val_accuracy: 0.5375\n",
      "Epoch 30/40\n",
      "191/191 - 8s - loss: 1.1212 - accuracy: 0.5814 - val_loss: 2.2028 - val_accuracy: 0.3719\n",
      "Epoch 31/40\n",
      "191/191 - 8s - loss: 1.0704 - accuracy: 0.5990 - val_loss: 2.2812 - val_accuracy: 0.4227\n",
      "Epoch 32/40\n",
      "191/191 - 8s - loss: 1.0274 - accuracy: 0.6158 - val_loss: 1.3348 - val_accuracy: 0.5527\n",
      "Epoch 33/40\n",
      "191/191 - 8s - loss: 1.0574 - accuracy: 0.6024 - val_loss: 1.5450 - val_accuracy: 0.5451\n",
      "Epoch 34/40\n",
      "191/191 - 8s - loss: 1.0161 - accuracy: 0.6273 - val_loss: 1.3264 - val_accuracy: 0.5683\n",
      "Epoch 35/40\n",
      "191/191 - 8s - loss: 1.0113 - accuracy: 0.6263 - val_loss: 1.4868 - val_accuracy: 0.5337\n",
      "Epoch 36/40\n",
      "191/191 - 8s - loss: 0.9788 - accuracy: 0.6417 - val_loss: 1.4393 - val_accuracy: 0.5508\n",
      "Epoch 37/40\n",
      "191/191 - 8s - loss: 0.9994 - accuracy: 0.6287 - val_loss: 1.4344 - val_accuracy: 0.5323\n",
      "Epoch 38/40\n",
      "191/191 - 8s - loss: 0.9959 - accuracy: 0.6365 - val_loss: 1.1842 - val_accuracy: 0.5906\n",
      "Epoch 39/40\n",
      "191/191 - 8s - loss: 0.9272 - accuracy: 0.6488 - val_loss: 1.5191 - val_accuracy: 0.5375\n",
      "Epoch 40/40\n",
      "191/191 - 8s - loss: 0.9577 - accuracy: 0.6485 - val_loss: 1.2610 - val_accuracy: 0.5825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06da4d9490>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "LeNet_07.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=64, # Batch size for the optimizer algorithm\n",
    "    epochs=40, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "8wd8L86JwmvP"
   },
   "outputs": [],
   "source": [
    "probs = LeNet_07.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6V9RR7EwmvP",
    "outputId": "67e1e11d-4089-414a-831a-68d22aa49f3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.68821526e-02, 3.15077491e-02, 2.28998080e-01, 1.17171695e-02,\n",
       "        7.62218833e-02, 6.04672968e-01],\n",
       "       [5.72833240e-01, 9.47223231e-03, 1.34899810e-01, 1.64995879e-01,\n",
       "        5.98481409e-02, 5.79506755e-02],\n",
       "       [7.24207098e-07, 1.41055324e-07, 5.08181984e-03, 3.26416716e-09,\n",
       "        3.50917981e-06, 9.94913697e-01],\n",
       "       ...,\n",
       "       [1.46231383e-01, 2.31810600e-01, 2.25347057e-01, 2.00837970e-01,\n",
       "        1.40768930e-01, 5.50040491e-02],\n",
       "       [1.64767459e-01, 1.54148385e-01, 3.88039768e-01, 1.66465640e-01,\n",
       "        1.16331734e-01, 1.02470387e-02],\n",
       "       [3.73025192e-04, 8.78274077e-05, 4.87759802e-03, 1.22566911e-04,\n",
       "        4.88753198e-04, 9.94050205e-01]], dtype=float32)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VN3AVOaUwmvP",
    "outputId": "efaabdb9-2d38-433d-991e-1112dcf7ce6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s 29ms/step - loss: 1.2412 - accuracy: 0.5903\n",
      "Test loss 1.2411900758743286\n",
      "Test accuracy 0.5903381705284119\n"
     ]
    }
   ],
   "source": [
    "score = LeNet_07.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSthCK87bC3F"
   },
   "source": [
    "#### **Conclusiones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-p__kgbXbQcN"
   },
   "source": [
    "Dado que el modelo **\"LetNet_07\"** alcanza el rendimiento buscado se toma como válido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrLe9mFwhRKC"
   },
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a5xs6_RhRKC"
   },
   "source": [
    "While designing your own network might produce some nice results, it is generally better to transfer the knowledge available in a pre-trained network. This not only can produce better results, but also saves a lot of design time. The [Keras Applications](https://keras.io/api/applications/) module contains several network designs ready to use. For instance, to exploit the famous VGG16 network we do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTLIqMTAhRKD",
    "outputId": "7c32ecac-8024-4155-a781-816c390d0584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "58900480/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16  # cargamos la red VGG16\n",
    "\n",
    "vgg16_model = VGG16(include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# \"include_top=False\" parámetro para que traiga sólo las capas convolucionales (capas de clasificación no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZUvx4zdhRKD"
   },
   "source": [
    "By default all Keras Applications networks are preloaded with the weights that were obtained from training the network over the [ImageNet dataset](http://www.image-net.org/). To adapt the network to our problem we need to specify the shape of our input images, and also remove the output layers (top) of the original network, since we have a different number of classes.\n",
    "\n",
    "Now, how do we do transfer learning over this network? We will show here how to implement the bottleneck features strategy. First, we will mark the VGG16 model as **non-trainable**, so that the weights remain frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWsuQg0phRKD"
   },
   "outputs": [],
   "source": [
    "vgg16_model.trainable = False    # congelamos entrenamiento de capa convolucional (\"FEATURES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljtS1PhRhRKE"
   },
   "source": [
    "Now we will build a neural network that includes the VGG16 model as one of its \"layers\". Since the VGG16 was trained with an specific way of normalizing the images, we will need to normalize our images in the same way. Conveniently, Keras also provides a function for doing VGG16-style normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjFpoNRIhRKE"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTBk5uRChRKF"
   },
   "source": [
    "We can try this with some image ir our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6ukW26shRKF",
    "outputId": "850ba1e4-5ba6-49ac-cb62-5025073d2ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalizing: [[[137.83594 185.83594 234.83594]\n",
      "  [142.92969 190.92969 238.92969]\n",
      "  [148.9375  196.9375  244.9375 ]]\n",
      "\n",
      " [[151.30469 198.30469 244.30469]\n",
      "  [145.375   192.625   241.     ]\n",
      "  [246.3125  251.57812 255.     ]]\n",
      "\n",
      " [[191.34375 220.46094 250.38281]\n",
      "  [128.00781 150.84375 207.39844]\n",
      "  [ 80.92969 108.42969 173.95312]]]\n",
      "After normalizing: [[[130.89694   69.05694   14.155937]\n",
      "  [134.99069   74.15069   19.249687]\n",
      "  [140.9985    80.1585    25.2575  ]]\n",
      "\n",
      " [[140.36569   81.52569   27.624687]\n",
      "  [137.061     75.846     21.695   ]\n",
      "  [151.061    134.79913  122.6325  ]]\n",
      "\n",
      " [[146.44382  103.68194   67.66375 ]\n",
      "  [103.459435  34.06475    4.327812]\n",
      "  [ 70.01412   -8.349312 -42.750313]]]\n"
     ]
    }
   ],
   "source": [
    "for X_batch, _ in train_dataset:\n",
    "    break\n",
    "    \n",
    "print(f\"Before normalizing: {X_batch[0, :3, :3, :]}\")\n",
    "print(f\"After normalizing: {preprocess_input(X_batch)[0, :3, :3, :]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx3EQeEThRKF"
   },
   "source": [
    "The normalization required by VGG16 involves swapping the order of color channels (RGB -> BGR) and substracting the mean values over the ImageNet dataset for each color channel separately. Fortunately the `preprocess_input` function does all the work for us. Furthermore, we can plug this function as the first layer of our network, similarly to the `Rescaling` we used before. We can do this with a `Lambda` layer, which allows building a layer out of any (differentiable!) function. Let's start our model with this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnSoUUrQhRKG"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3)))  # 1ª capa que preprocesa las imágenes según necesita la red VGG16\n",
    "\n",
    "# \"Lambda()\" funcción de KERAS que nos permite introducir cualquier función de la librería TensorFlow en una capa de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k83-_MmdhRKG"
   },
   "source": [
    "After this, we can add the whole VGG16 network as a layer, and our custom trainable layers after it. Note this is an overly simple model with some mistakes introduced; a real transfer learning network would have a better design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f0RdEumhRKG",
    "outputId": "a1f943e2-7aa9-45c6-876f-367ed76579cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_75 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 6)                 49158     \n",
      "=================================================================\n",
      "Total params: 14,763,846\n",
      "Trainable params: 49,158\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(vgg16_model)  # introduzco red VGG16 entera como si fuera una capa\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NueAGF7DhRKG"
   },
   "source": [
    "Notice how in the model summary we can see the whole network has millions of parameters, but since we have frozen the VGG16 part, only a few thousand parameters will be trained: those in the Dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn7iMKlQhRKH"
   },
   "source": [
    "We can now compile and train this model in the usual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaCIyssdb-C4"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=[\"accuracy\"])\n",
    "model.fit(train_dataset, epochs=1)\n",
    "\n",
    "loss, acc = model.evaluate(test_dataset)\n",
    "print(f\"Loss {loss:.3}, accuracy {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At4nOovAdEuE"
   },
   "source": [
    "### **\"VGG16\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChqbyqkiIbsj",
    "outputId": "1a4dbf1d-f7b6-4115-8bf3-cd160cff4865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6082 files belonging to 6 classes.\n",
      "Found 2108 files belonging to 6 classes.\n",
      "Found 2070 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset128, val_dataset128, test_dataset128 = create_datasets(TRAINDIR, VALDIR, TESTDIR, image_size=128, batch_size=64)\n",
    "\n",
    "# Test whether all returned objects are valid Tensorflow datasets\n",
    "assert isinstance(train_dataset128, tf.data.Dataset)\n",
    "assert isinstance(val_dataset128, tf.data.Dataset)\n",
    "assert isinstance(test_dataset128, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nin-HurFEMCY"
   },
   "source": [
    "#### **\"VGG16_01\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "XG9uA5pNeUk7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16  # cargamos la red VGG16\n",
    "from keras.applications.vgg16 import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red VGG16\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "vgg16_model_01 = VGG16(include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# \"include_top=False\" parámetro para que traiga sólo las capas convolucionales (capas de clasificación no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "BOUYMgAaEAx8"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"vgg16_01\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "vgg16_model_01.trainable = False\n",
    "\n",
    "image_size=128\n",
    "\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "vgg16_01 = Sequential()\n",
    "\n",
    "vgg16_01.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "vgg16_01.add(RandomFlip(mode=\"horizontal\"))\n",
    "#vgg16_01.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "vgg16_01.add(RandomRotation(factor=(-0.2,0.2)))\n",
    "#vgg16_01.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#vgg16_01.add(RandomCrop(height=85, width=85))\n",
    "vgg16_01.add(RandomContrast(factor=0.1))\n",
    "\n",
    "#vgg16_01.add(Rescaling(scale=1.0/255.0, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "#vgg16_01.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "vgg16_01.add(vgg16_model_01) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "TDIFrX9uEAx8"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#vgg16_01.add(BatchNormalization())\n",
    "vgg16_01.add(GlobalAveragePooling2D())\n",
    "#vgg16_01.add(Flatten(name=\"flatten\"))\n",
    "#vgg16_01.add(Dense(512, activation=\"relu\"))\n",
    "#vgg16_01.add(Dropout(0.25))\n",
    "#vgg16_01.add(Dense(512, activation=\"relu\"))\n",
    "#vgg16_01.add(Dense(256, activation=\"relu\"))\n",
    "vgg16_01.add(Dropout(0.2))\n",
    "\n",
    "vgg16_01.add(Dense(128, activation=\"relu\"))\n",
    "#vgg16_01.add(Dropout(0.2))\n",
    "\n",
    "vgg16_01.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "LiLpUxleEAx9"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "vgg16_01.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfzjNOpWEAx9",
    "outputId": "0c675f22-f304-4df4-8cb0-f41a3a555ade"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 - 12s - loss: 2.3666 - accuracy: 0.4850 - val_loss: 1.1047 - val_accuracy: 0.6110\n",
      "Epoch 2/50\n",
      "191/191 - 8s - loss: 1.1778 - accuracy: 0.5814 - val_loss: 0.9409 - val_accuracy: 0.6679\n",
      "Epoch 3/50\n",
      "191/191 - 9s - loss: 1.0094 - accuracy: 0.6402 - val_loss: 0.8680 - val_accuracy: 0.6983\n",
      "Epoch 4/50\n",
      "191/191 - 8s - loss: 0.9438 - accuracy: 0.6508 - val_loss: 0.8057 - val_accuracy: 0.7135\n",
      "Epoch 5/50\n",
      "191/191 - 8s - loss: 0.8931 - accuracy: 0.6621 - val_loss: 0.8127 - val_accuracy: 0.7135\n",
      "Epoch 6/50\n",
      "191/191 - 8s - loss: 0.8535 - accuracy: 0.6866 - val_loss: 0.7779 - val_accuracy: 0.7396\n",
      "Epoch 7/50\n",
      "191/191 - 8s - loss: 0.8247 - accuracy: 0.6929 - val_loss: 0.7843 - val_accuracy: 0.7277\n",
      "Epoch 8/50\n",
      "191/191 - 8s - loss: 0.8007 - accuracy: 0.7001 - val_loss: 0.7422 - val_accuracy: 0.7453\n",
      "Epoch 9/50\n",
      "191/191 - 8s - loss: 0.7826 - accuracy: 0.7024 - val_loss: 0.7101 - val_accuracy: 0.7543\n",
      "Epoch 10/50\n",
      "191/191 - 8s - loss: 0.7692 - accuracy: 0.7142 - val_loss: 0.7191 - val_accuracy: 0.7505\n",
      "Epoch 11/50\n",
      "191/191 - 8s - loss: 0.7259 - accuracy: 0.7280 - val_loss: 0.7276 - val_accuracy: 0.7448\n",
      "Epoch 12/50\n",
      "191/191 - 8s - loss: 0.7233 - accuracy: 0.7292 - val_loss: 0.7178 - val_accuracy: 0.7562\n",
      "Epoch 13/50\n",
      "191/191 - 8s - loss: 0.7287 - accuracy: 0.7290 - val_loss: 0.7176 - val_accuracy: 0.7514\n",
      "Epoch 14/50\n",
      "191/191 - 8s - loss: 0.7008 - accuracy: 0.7419 - val_loss: 0.7185 - val_accuracy: 0.7495\n",
      "Epoch 15/50\n",
      "191/191 - 8s - loss: 0.6870 - accuracy: 0.7486 - val_loss: 0.7192 - val_accuracy: 0.7448\n",
      "Epoch 16/50\n",
      "191/191 - 8s - loss: 0.6775 - accuracy: 0.7471 - val_loss: 0.7007 - val_accuracy: 0.7590\n",
      "Epoch 17/50\n",
      "191/191 - 8s - loss: 0.6666 - accuracy: 0.7595 - val_loss: 0.7497 - val_accuracy: 0.7429\n",
      "Epoch 18/50\n",
      "191/191 - 8s - loss: 0.6613 - accuracy: 0.7567 - val_loss: 0.7039 - val_accuracy: 0.7524\n",
      "Epoch 19/50\n",
      "191/191 - 8s - loss: 0.6378 - accuracy: 0.7627 - val_loss: 0.7380 - val_accuracy: 0.7533\n",
      "Epoch 20/50\n",
      "191/191 - 8s - loss: 0.6322 - accuracy: 0.7701 - val_loss: 0.7207 - val_accuracy: 0.7562\n",
      "Epoch 21/50\n",
      "191/191 - 8s - loss: 0.6324 - accuracy: 0.7698 - val_loss: 0.7582 - val_accuracy: 0.7528\n",
      "Epoch 22/50\n",
      "191/191 - 8s - loss: 0.6149 - accuracy: 0.7747 - val_loss: 0.7413 - val_accuracy: 0.7547\n",
      "Epoch 23/50\n",
      "191/191 - 8s - loss: 0.5931 - accuracy: 0.7851 - val_loss: 0.7358 - val_accuracy: 0.7585\n",
      "Epoch 24/50\n",
      "191/191 - 8s - loss: 0.6049 - accuracy: 0.7764 - val_loss: 0.7097 - val_accuracy: 0.7604\n",
      "Epoch 25/50\n",
      "191/191 - 8s - loss: 0.5932 - accuracy: 0.7800 - val_loss: 0.7569 - val_accuracy: 0.7581\n",
      "Epoch 26/50\n",
      "191/191 - 8s - loss: 0.6033 - accuracy: 0.7784 - val_loss: 0.7240 - val_accuracy: 0.7619\n",
      "Epoch 27/50\n",
      "191/191 - 8s - loss: 0.5765 - accuracy: 0.7884 - val_loss: 0.7380 - val_accuracy: 0.7595\n",
      "Epoch 28/50\n",
      "191/191 - 8s - loss: 0.5731 - accuracy: 0.7914 - val_loss: 0.7231 - val_accuracy: 0.7585\n",
      "Epoch 29/50\n",
      "191/191 - 8s - loss: 0.5748 - accuracy: 0.7894 - val_loss: 0.7216 - val_accuracy: 0.7619\n",
      "Epoch 30/50\n",
      "191/191 - 8s - loss: 0.5541 - accuracy: 0.8002 - val_loss: 0.7243 - val_accuracy: 0.7562\n",
      "Epoch 31/50\n",
      "191/191 - 8s - loss: 0.5630 - accuracy: 0.7937 - val_loss: 0.7233 - val_accuracy: 0.7661\n",
      "Epoch 32/50\n",
      "191/191 - 8s - loss: 0.5389 - accuracy: 0.8004 - val_loss: 0.7633 - val_accuracy: 0.7680\n",
      "Epoch 33/50\n",
      "191/191 - 8s - loss: 0.5352 - accuracy: 0.8057 - val_loss: 0.7413 - val_accuracy: 0.7576\n",
      "Epoch 34/50\n",
      "191/191 - 8s - loss: 0.5362 - accuracy: 0.8053 - val_loss: 0.7378 - val_accuracy: 0.7699\n",
      "Epoch 35/50\n",
      "191/191 - 8s - loss: 0.5234 - accuracy: 0.8080 - val_loss: 0.7234 - val_accuracy: 0.7694\n",
      "Epoch 36/50\n",
      "191/191 - 8s - loss: 0.5323 - accuracy: 0.8094 - val_loss: 0.7319 - val_accuracy: 0.7609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b306c6e90>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "vgg16_01.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    #batch_size=256, # Batch size for the optimizer algorithm\n",
    "    epochs=50, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "yYH7E6oGEAx9"
   },
   "outputs": [],
   "source": [
    "probs = vgg16_01.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYPSP27XEAx9",
    "outputId": "b54fd2fc-0622-48d2-8882-d2a595fa6c0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.28458928e-04, 9.67403830e-05, 8.53784800e-01, 7.50848930e-03,\n",
       "        1.21925779e-01, 1.58558711e-02],\n",
       "       [6.71644375e-05, 4.02063997e-05, 1.00918836e-03, 6.86462081e-05,\n",
       "        1.14158483e-03, 9.97673213e-01],\n",
       "       [6.48988411e-02, 2.26989463e-01, 4.43399340e-01, 2.00094700e-01,\n",
       "        2.39927880e-03, 6.22183681e-02],\n",
       "       ...,\n",
       "       [1.99622336e-05, 9.90576863e-01, 6.76888926e-03, 5.33143175e-04,\n",
       "        2.09718826e-03, 3.95471125e-06],\n",
       "       [1.07907504e-01, 2.84180492e-02, 4.21103477e-01, 2.51666158e-01,\n",
       "        3.72622460e-02, 1.53642550e-01],\n",
       "       [3.78257856e-02, 3.07839885e-02, 6.51563555e-02, 1.34852044e-02,\n",
       "        1.70890152e-01, 6.81858540e-01]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdElrMBqEAx9",
    "outputId": "8a3ec54a-a4db-4b37-ac11-62f3fd21f75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s 31ms/step - loss: 0.7092 - accuracy: 0.7498\n",
      "Test loss 0.7092249989509583\n",
      "Test accuracy 0.7497584819793701\n"
     ]
    }
   ],
   "source": [
    "score = vgg16_01.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTY6-bwRRQvf"
   },
   "source": [
    "#### **\"VGG16_02\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "DCFpnwG2efmt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16  # cargamos la red VGG16\n",
    "from keras.applications.vgg16 import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red VGG16\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "vgg16_model_02 = VGG16(include_top=False, input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# \"include_top=False\" parámetro para que traiga sólo las capas convolucionales (capas de clasificación no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "W_2XvzARRQvg"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"vgg16_02\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "vgg16_model_02.trainable = False\n",
    "\n",
    "image_size=128\n",
    "\n",
    "vgg16_02 = Sequential()\n",
    "\n",
    "vgg16_02.add(RandomFlip(mode=\"horizontal\"))\n",
    "#vgg16_02.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "vgg16_02.add(RandomRotation(factor=(-0.1,0.1)))\n",
    "#vgg16_02.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#vgg16_02.add(RandomCrop(height=64, width=64))\n",
    "vgg16_02.add(RandomContrast(factor=0.1))\n",
    "\n",
    "#vgg16_02.add(Resizing(image_size, image_size))\n",
    "\n",
    "vgg16_02.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "vgg16_02.add(vgg16_model_02)\n",
    "\n",
    "vgg16_02.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "_cc4BbP0RQvg"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "vgg16_02.add(GlobalAveragePooling2D())\n",
    "vgg16_02.add(Dense(4096, activation=\"relu\"))\n",
    "vgg16_02.add(Dropout(0.825))\n",
    "vgg16_02.add(Dense(4096, activation=\"relu\"))\n",
    "vgg16_02.add(Dropout(0.825))\n",
    "vgg16_02.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "LrhUN_VCRQvh"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "vgg16_02.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtJlO93sRQvh",
    "outputId": "510a3243-1694-4f48-e12c-f38f76b64fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "191/191 - 10s - loss: 1.7261 - accuracy: 0.5035 - val_loss: 0.8830 - val_accuracy: 0.6964\n",
      "Epoch 2/40\n",
      "191/191 - 8s - loss: 1.2449 - accuracy: 0.6062 - val_loss: 0.7862 - val_accuracy: 0.7073\n",
      "Epoch 3/40\n",
      "191/191 - 8s - loss: 1.0592 - accuracy: 0.6388 - val_loss: 0.7886 - val_accuracy: 0.7253\n",
      "Epoch 4/40\n",
      "191/191 - 8s - loss: 1.0653 - accuracy: 0.6542 - val_loss: 0.8466 - val_accuracy: 0.7068\n",
      "Epoch 5/40\n",
      "191/191 - 8s - loss: 1.0321 - accuracy: 0.6495 - val_loss: 0.7893 - val_accuracy: 0.7234\n",
      "Epoch 6/40\n",
      "191/191 - 8s - loss: 1.0222 - accuracy: 0.6641 - val_loss: 0.7797 - val_accuracy: 0.7315\n",
      "Epoch 7/40\n",
      "191/191 - 8s - loss: 0.9820 - accuracy: 0.6717 - val_loss: 0.7628 - val_accuracy: 0.7353\n",
      "Epoch 8/40\n",
      "191/191 - 8s - loss: 1.0197 - accuracy: 0.6725 - val_loss: 0.7435 - val_accuracy: 0.7467\n",
      "Epoch 9/40\n",
      "191/191 - 8s - loss: 1.0087 - accuracy: 0.6628 - val_loss: 0.7476 - val_accuracy: 0.7519\n",
      "Epoch 10/40\n",
      "191/191 - 8s - loss: 0.9587 - accuracy: 0.6891 - val_loss: 0.7592 - val_accuracy: 0.7410\n",
      "Epoch 11/40\n",
      "191/191 - 8s - loss: 0.9721 - accuracy: 0.6925 - val_loss: 0.7470 - val_accuracy: 0.7476\n",
      "Epoch 12/40\n",
      "191/191 - 8s - loss: 0.9882 - accuracy: 0.6833 - val_loss: 0.7370 - val_accuracy: 0.7633\n",
      "Epoch 13/40\n",
      "191/191 - 8s - loss: 0.9922 - accuracy: 0.6815 - val_loss: 0.7722 - val_accuracy: 0.7438\n",
      "Epoch 14/40\n",
      "191/191 - 8s - loss: 0.9500 - accuracy: 0.6968 - val_loss: 0.7679 - val_accuracy: 0.7547\n",
      "Epoch 15/40\n",
      "191/191 - 8s - loss: 0.9509 - accuracy: 0.6841 - val_loss: 0.7459 - val_accuracy: 0.7628\n",
      "Epoch 16/40\n",
      "191/191 - 8s - loss: 0.9243 - accuracy: 0.7021 - val_loss: 0.7580 - val_accuracy: 0.7581\n",
      "Epoch 17/40\n",
      "191/191 - 8s - loss: 0.9188 - accuracy: 0.7032 - val_loss: 0.7642 - val_accuracy: 0.7500\n",
      "Epoch 18/40\n",
      "191/191 - 8s - loss: 0.8815 - accuracy: 0.7077 - val_loss: 0.7560 - val_accuracy: 0.7600\n",
      "Epoch 19/40\n",
      "191/191 - 8s - loss: 0.9213 - accuracy: 0.7116 - val_loss: 0.7612 - val_accuracy: 0.7519\n",
      "Epoch 20/40\n",
      "191/191 - 8s - loss: 0.9069 - accuracy: 0.7129 - val_loss: 0.7633 - val_accuracy: 0.7638\n",
      "Epoch 21/40\n",
      "191/191 - 8s - loss: 0.8812 - accuracy: 0.7152 - val_loss: 0.7707 - val_accuracy: 0.7652\n",
      "Epoch 22/40\n",
      "191/191 - 8s - loss: 0.8470 - accuracy: 0.7287 - val_loss: 0.7495 - val_accuracy: 0.7699\n",
      "Epoch 23/40\n",
      "191/191 - 8s - loss: 0.8957 - accuracy: 0.7156 - val_loss: 0.7803 - val_accuracy: 0.7566\n",
      "Epoch 24/40\n",
      "191/191 - 8s - loss: 0.8592 - accuracy: 0.7277 - val_loss: 0.7623 - val_accuracy: 0.7694\n",
      "Epoch 25/40\n",
      "191/191 - 8s - loss: 0.8574 - accuracy: 0.7287 - val_loss: 0.7389 - val_accuracy: 0.7751\n",
      "Epoch 26/40\n",
      "191/191 - 8s - loss: 0.8348 - accuracy: 0.7346 - val_loss: 0.7528 - val_accuracy: 0.7585\n",
      "Epoch 27/40\n",
      "191/191 - 8s - loss: 0.8393 - accuracy: 0.7315 - val_loss: 0.7694 - val_accuracy: 0.7638\n",
      "Epoch 28/40\n",
      "191/191 - 8s - loss: 0.8294 - accuracy: 0.7414 - val_loss: 0.7264 - val_accuracy: 0.7837\n",
      "Epoch 29/40\n",
      "191/191 - 8s - loss: 0.8380 - accuracy: 0.7371 - val_loss: 0.7583 - val_accuracy: 0.7799\n",
      "Epoch 30/40\n",
      "191/191 - 8s - loss: 0.8340 - accuracy: 0.7351 - val_loss: 0.7651 - val_accuracy: 0.7642\n",
      "Epoch 31/40\n",
      "191/191 - 8s - loss: 0.8077 - accuracy: 0.7486 - val_loss: 0.7654 - val_accuracy: 0.7671\n",
      "Epoch 32/40\n",
      "191/191 - 8s - loss: 0.7958 - accuracy: 0.7506 - val_loss: 0.7600 - val_accuracy: 0.7718\n",
      "Epoch 33/40\n",
      "191/191 - 8s - loss: 0.8281 - accuracy: 0.7368 - val_loss: 0.7721 - val_accuracy: 0.7590\n",
      "Epoch 34/40\n",
      "191/191 - 8s - loss: 0.8141 - accuracy: 0.7430 - val_loss: 0.7632 - val_accuracy: 0.7666\n",
      "Epoch 35/40\n",
      "191/191 - 8s - loss: 0.7610 - accuracy: 0.7549 - val_loss: 0.7595 - val_accuracy: 0.7718\n",
      "Epoch 36/40\n",
      "191/191 - 8s - loss: 0.7664 - accuracy: 0.7537 - val_loss: 0.7661 - val_accuracy: 0.7694\n",
      "Epoch 37/40\n",
      "191/191 - 8s - loss: 0.7424 - accuracy: 0.7627 - val_loss: 0.7473 - val_accuracy: 0.7742\n",
      "Epoch 38/40\n",
      "191/191 - 8s - loss: 0.7807 - accuracy: 0.7527 - val_loss: 0.7607 - val_accuracy: 0.7756\n",
      "Epoch 39/40\n",
      "191/191 - 8s - loss: 0.7495 - accuracy: 0.7599 - val_loss: 0.7524 - val_accuracy: 0.7766\n",
      "Epoch 40/40\n",
      "191/191 - 8s - loss: 0.7574 - accuracy: 0.7652 - val_loss: 0.7493 - val_accuracy: 0.7766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b303e0110>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "vgg16_02.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=1024, # Batch size for the optimizer algorithm\n",
    "    epochs=40, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "UPW5UWrYRQvh"
   },
   "outputs": [],
   "source": [
    "probs = vgg16_02.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRN8kYtdRQvh",
    "outputId": "34a120b9-f60b-4805-9074-acd17b33ac6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.81734090e-02, 3.20767947e-02, 6.72657669e-01, 1.34000704e-02,\n",
       "        4.10379879e-02, 1.92654103e-01],\n",
       "       [6.20243690e-10, 5.56742109e-12, 3.86946281e-10, 4.46189301e-11,\n",
       "        1.00000000e+00, 1.44314088e-10],\n",
       "       [3.21519971e-02, 2.92022829e-03, 9.80839878e-02, 1.20438579e-02,\n",
       "        1.60197243e-02, 8.38780165e-01],\n",
       "       ...,\n",
       "       [3.53159768e-09, 3.02580450e-09, 1.00000000e+00, 8.53506016e-11,\n",
       "        4.94172314e-10, 1.31170985e-08],\n",
       "       [1.08521635e-05, 6.36636230e-07, 9.99980450e-01, 5.24246104e-08,\n",
       "        4.61895198e-08, 8.03822149e-06],\n",
       "       [1.41757322e-04, 2.28704312e-06, 2.46549072e-03, 5.06732213e-05,\n",
       "        3.31269730e-05, 9.97306585e-01]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2nPpYQv8RQvi",
    "outputId": "54a2aacc-345b-43b5-9673-df82731092b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s 30ms/step - loss: 0.7251 - accuracy: 0.7845\n",
      "Test loss 0.725104570388794\n",
      "Test accuracy 0.7845410704612732\n"
     ]
    }
   ],
   "source": [
    "score = vgg16_02.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-VJPtlZeXhF"
   },
   "source": [
    "#### **Conclusiones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxdhHsbVeXhF"
   },
   "source": [
    "Dado que el modelo **\"VGG6_02\"** alcanza el rendimiento buscado se toma como válido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXY19ZDhj1JI"
   },
   "source": [
    "## **PRO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BFQlMM6ZKo_"
   },
   "source": [
    "### **\"Xception\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Jr-AViFcqpSL",
    "outputId": "34fc78a0-9b49-4884-a379-46d883f4da97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6082 files belonging to 6 classes.\n",
      "Found 2108 files belonging to 6 classes.\n",
      "Found 2070 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset128, val_dataset128, test_dataset128 = create_datasets(TRAINDIR, VALDIR, TESTDIR, image_size=128, batch_size=32)\n",
    "\n",
    "# Test whether all returned objects are valid Tensorflow datasets\n",
    "assert isinstance(train_dataset128, tf.data.Dataset)\n",
    "assert isinstance(val_dataset128, tf.data.Dataset)\n",
    "assert isinstance(test_dataset128, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "njV2nNZ3kj9u",
    "outputId": "0f0ec87e-a72c-4aa5-8713-23f4babb003a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6082 files belonging to 6 classes.\n",
      "Found 2108 files belonging to 6 classes.\n",
      "Found 2070 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset256, val_dataset256, test_dataset256 = create_datasets(TRAINDIR, VALDIR, TESTDIR, image_size=256, batch_size=32)\n",
    "\n",
    "# Test whether all returned objects are valid Tensorflow datasets\n",
    "assert isinstance(train_dataset256, tf.data.Dataset)\n",
    "assert isinstance(val_dataset256, tf.data.Dataset)\n",
    "assert isinstance(test_dataset256, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "SlglE1RiFqnh",
    "outputId": "376432d4-ba15-4e08-cb62-68664035206b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6082 files belonging to 6 classes.\n",
      "Found 2108 files belonging to 6 classes.\n",
      "Found 2070 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset299, val_dataset299, test_dataset299 = create_datasets(TRAINDIR, VALDIR, TESTDIR, image_size=299, batch_size=32)\n",
    "\n",
    "# Test whether all returned objects are valid Tensorflow datasets\n",
    "assert isinstance(train_dataset299, tf.data.Dataset)\n",
    "assert isinstance(val_dataset299, tf.data.Dataset)\n",
    "assert isinstance(test_dataset299, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtljKZ7vOqGf"
   },
   "source": [
    "#### **\"Xception_01\" (RED NEURONAL CONVOLUCIONAL)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "91G3ngon4Wf-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "Xception_model_01 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "ubTdl3YaOqGf"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_01\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_01.trainable = False\n",
    "\n",
    "image_size=128\n",
    "\n",
    "Xception_01 = Sequential()\n",
    "\n",
    "\n",
    "#Xception_01.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_01.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_01.add(RandomRotation(factor=(-0.2,0.2)))\n",
    "#Xception_01.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_01.add(RandomCrop(height=64, width=64))\n",
    "#Xception_01.add(RandomContrast(factor=0.2))\n",
    "\n",
    "#Xception_01.add(Resizing(image_size, image_size))\n",
    "\n",
    "Xception_01.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_01.add(Xception_model_01)\n",
    "\n",
    "#Xception_01.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "qHWG6OTaOqGf"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "Xception_01.add(GlobalAveragePooling2D())\n",
    "Xception_01.add(Flatten(name=\"flatten\"))\n",
    "Xception_01.add(Dense(526, activation=\"relu\"))\n",
    "Xception_01.add(Dropout(0.825))\n",
    "Xception_01.add(Dense(258, activation=\"relu\"))\n",
    "#Xception_01.add(Dropout(0.4))\n",
    "Xception_01.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "8vEpPMbIOqGg"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "Xception_01.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSfSA6OAOqGg",
    "outputId": "e375e558-eb6f-4220-cfde-0eb8cabe7e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 29s - loss: 1.4640 - accuracy: 0.4727 - val_loss: 1.0142 - val_accuracy: 0.6380\n",
      "Epoch 2/20\n",
      "191/191 - 9s - loss: 1.2034 - accuracy: 0.5543 - val_loss: 0.9371 - val_accuracy: 0.6969\n",
      "Epoch 3/20\n",
      "191/191 - 9s - loss: 1.1426 - accuracy: 0.5893 - val_loss: 0.9555 - val_accuracy: 0.6917\n",
      "Epoch 4/20\n",
      "191/191 - 9s - loss: 1.0914 - accuracy: 0.6092 - val_loss: 0.8790 - val_accuracy: 0.7135\n",
      "Epoch 5/20\n",
      "191/191 - 9s - loss: 1.0253 - accuracy: 0.6287 - val_loss: 0.9133 - val_accuracy: 0.7064\n",
      "Epoch 6/20\n",
      "191/191 - 9s - loss: 0.9971 - accuracy: 0.6412 - val_loss: 0.8839 - val_accuracy: 0.7249\n",
      "Epoch 7/20\n",
      "191/191 - 9s - loss: 0.9697 - accuracy: 0.6565 - val_loss: 0.8861 - val_accuracy: 0.7287\n",
      "Epoch 8/20\n",
      "191/191 - 9s - loss: 0.9218 - accuracy: 0.6749 - val_loss: 0.8989 - val_accuracy: 0.7173\n",
      "Epoch 9/20\n",
      "191/191 - 9s - loss: 0.9144 - accuracy: 0.6717 - val_loss: 0.8934 - val_accuracy: 0.7277\n",
      "Epoch 10/20\n",
      "191/191 - 9s - loss: 0.8718 - accuracy: 0.6883 - val_loss: 0.8827 - val_accuracy: 0.7362\n",
      "Epoch 11/20\n",
      "191/191 - 9s - loss: 0.8399 - accuracy: 0.6978 - val_loss: 0.9239 - val_accuracy: 0.7130\n",
      "Epoch 12/20\n",
      "191/191 - 9s - loss: 0.8359 - accuracy: 0.7039 - val_loss: 0.8667 - val_accuracy: 0.7415\n",
      "Epoch 13/20\n",
      "191/191 - 9s - loss: 0.8283 - accuracy: 0.6996 - val_loss: 0.8780 - val_accuracy: 0.7362\n",
      "Epoch 14/20\n",
      "191/191 - 9s - loss: 0.8083 - accuracy: 0.7091 - val_loss: 0.8971 - val_accuracy: 0.7495\n",
      "Epoch 15/20\n",
      "191/191 - 9s - loss: 0.7814 - accuracy: 0.7211 - val_loss: 0.8756 - val_accuracy: 0.7358\n",
      "Epoch 16/20\n",
      "191/191 - 9s - loss: 0.7670 - accuracy: 0.7302 - val_loss: 0.8877 - val_accuracy: 0.7291\n",
      "Epoch 17/20\n",
      "191/191 - 9s - loss: 0.7521 - accuracy: 0.7335 - val_loss: 0.8877 - val_accuracy: 0.7258\n",
      "Epoch 18/20\n",
      "191/191 - 9s - loss: 0.7558 - accuracy: 0.7277 - val_loss: 0.8710 - val_accuracy: 0.7377\n",
      "Epoch 19/20\n",
      "191/191 - 9s - loss: 0.7480 - accuracy: 0.7338 - val_loss: 0.8664 - val_accuracy: 0.7391\n",
      "Epoch 20/20\n",
      "191/191 - 9s - loss: 0.7301 - accuracy: 0.7440 - val_loss: 0.8344 - val_accuracy: 0.7434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6d64c9ed0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_01.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjrE5x1gOqGg"
   },
   "outputs": [],
   "source": [
    "probs = Xception_01.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QoYXV-esOqGg",
    "outputId": "6bf90808-3fa9-4e43-91ae-796ef79b12fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5656180e-02, 1.9363075e-01, 5.4848373e-01, 1.7532441e-01,\n",
       "        2.4570683e-02, 3.2334235e-02],\n",
       "       [1.0227151e-01, 1.2386827e-02, 3.2749197e-01, 6.3645318e-02,\n",
       "        4.1547161e-02, 4.5265725e-01],\n",
       "       [7.2836839e-03, 4.1211133e-05, 6.8927230e-04, 9.1391848e-04,\n",
       "        9.7816968e-01, 1.2902213e-02],\n",
       "       ...,\n",
       "       [2.2241887e-02, 4.6178445e-01, 2.4805592e-01, 1.5210345e-01,\n",
       "        1.0232210e-01, 1.3492165e-02],\n",
       "       [3.9172879e-01, 1.0286564e-02, 8.4050529e-02, 3.6675769e-01,\n",
       "        1.0063163e-01, 4.6544783e-02],\n",
       "       [1.0523128e-01, 8.5874749e-03, 4.0059235e-02, 6.8522340e-01,\n",
       "        9.3820438e-02, 6.7078181e-02]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hV26V4vtOqGg",
    "outputId": "f5b895dd-c0ef-44ce-ad1e-5782660a46c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 40ms/step - loss: 0.8247 - accuracy: 0.7430\n",
      "Test loss 0.8246902227401733\n",
      "Test accuracy 0.7429951429367065\n"
     ]
    }
   ],
   "source": [
    "score = Xception_01.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiFOqXoGTsGv"
   },
   "source": [
    "#### **\"Xception_02\" (RED NEURONAL CONVOLUCIONAL)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "ZaQA4vWE6Js0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "Xception_model_02 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "P6HBqmj1TsGv"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_02\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling, RandomContrast\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_02.trainable = False\n",
    "\n",
    "image_size=128\n",
    "\n",
    "Xception_02 = Sequential()\n",
    "\n",
    "Xception_02.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_02.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "Xception_02.add(RandomRotation(factor=(-0.3,0.3)))\n",
    "#Xception_02.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_02.add(RandomCrop(height=64, width=64))\n",
    "Xception_02.add(RandomContrast(factor=0.3))\n",
    "\n",
    "#Xception_02.add(Resizing(image_size, image_size))\n",
    "\n",
    "Xception_02.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_02.add(Xception_model_02)\n",
    "\n",
    "#Xception_02.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "LFKd40V9TsGv"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "Xception_02.add(GlobalAveragePooling2D())\n",
    "Xception_02.add(Flatten(name=\"flatten\"))\n",
    "Xception_02.add(Dense(124, activation=\"relu\"))\n",
    "Xception_02.add(Dropout(0.325))\n",
    "Xception_02.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "J_kec_8qTsGw"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "\n",
    "Xception_02.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PLPbKPTTsGw",
    "outputId": "d5e99dbe-ade5-4a68-c3d5-0f1e0fa15668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 15s - loss: 1.1323 - accuracy: 0.5894 - val_loss: 0.8382 - val_accuracy: 0.7016\n",
      "Epoch 2/20\n",
      "191/191 - 9s - loss: 0.9456 - accuracy: 0.6592 - val_loss: 0.7996 - val_accuracy: 0.7187\n",
      "Epoch 3/20\n",
      "191/191 - 10s - loss: 0.8857 - accuracy: 0.6748 - val_loss: 0.7670 - val_accuracy: 0.7306\n",
      "Epoch 4/20\n",
      "191/191 - 9s - loss: 0.8542 - accuracy: 0.6866 - val_loss: 0.7891 - val_accuracy: 0.7296\n",
      "Epoch 5/20\n",
      "191/191 - 9s - loss: 0.8148 - accuracy: 0.7055 - val_loss: 0.7654 - val_accuracy: 0.7377\n",
      "Epoch 6/20\n",
      "191/191 - 9s - loss: 0.7924 - accuracy: 0.7134 - val_loss: 0.7314 - val_accuracy: 0.7514\n",
      "Epoch 7/20\n",
      "191/191 - 9s - loss: 0.7783 - accuracy: 0.7106 - val_loss: 0.7738 - val_accuracy: 0.7296\n",
      "Epoch 8/20\n",
      "191/191 - 9s - loss: 0.7638 - accuracy: 0.7220 - val_loss: 0.7368 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "191/191 - 9s - loss: 0.7668 - accuracy: 0.7226 - val_loss: 0.7130 - val_accuracy: 0.7519\n",
      "Epoch 10/20\n",
      "191/191 - 9s - loss: 0.7172 - accuracy: 0.7399 - val_loss: 0.7479 - val_accuracy: 0.7448\n",
      "Epoch 11/20\n",
      "191/191 - 9s - loss: 0.7171 - accuracy: 0.7394 - val_loss: 0.7677 - val_accuracy: 0.7339\n",
      "Epoch 12/20\n",
      "191/191 - 9s - loss: 0.7280 - accuracy: 0.7289 - val_loss: 0.8024 - val_accuracy: 0.7282\n",
      "Epoch 13/20\n",
      "191/191 - 9s - loss: 0.7286 - accuracy: 0.7364 - val_loss: 0.7756 - val_accuracy: 0.7410\n",
      "Epoch 14/20\n",
      "191/191 - 9s - loss: 0.7138 - accuracy: 0.7378 - val_loss: 0.7119 - val_accuracy: 0.7472\n",
      "Epoch 15/20\n",
      "191/191 - 9s - loss: 0.6960 - accuracy: 0.7470 - val_loss: 0.7387 - val_accuracy: 0.7528\n",
      "Epoch 16/20\n",
      "191/191 - 9s - loss: 0.6926 - accuracy: 0.7461 - val_loss: 0.7159 - val_accuracy: 0.7581\n",
      "Epoch 17/20\n",
      "191/191 - 9s - loss: 0.6868 - accuracy: 0.7522 - val_loss: 0.7055 - val_accuracy: 0.7547\n",
      "Epoch 18/20\n",
      "191/191 - 9s - loss: 0.6609 - accuracy: 0.7603 - val_loss: 0.7872 - val_accuracy: 0.7334\n",
      "Epoch 19/20\n",
      "191/191 - 9s - loss: 0.6609 - accuracy: 0.7557 - val_loss: 0.7424 - val_accuracy: 0.7462\n",
      "Epoch 20/20\n",
      "191/191 - 9s - loss: 0.6636 - accuracy: 0.7598 - val_loss: 0.7215 - val_accuracy: 0.7495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b0e125790>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_02.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "E-O8FbuBTsGw"
   },
   "outputs": [],
   "source": [
    "probs = Xception_02.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Ybi1VJCTsGw",
    "outputId": "d0ea9dec-130e-47d8-fc4a-7b68f91ec949"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.66033024e-01, 1.48055179e-03, 1.12613805e-01, 1.14134848e-01,\n",
       "        2.79622450e-02, 4.77775604e-01],\n",
       "       [1.41100225e-03, 9.28487718e-01, 4.08343039e-02, 2.42909845e-02,\n",
       "        3.65057169e-03, 1.32549438e-03],\n",
       "       [8.64221990e-01, 1.20460914e-04, 1.58549671e-03, 2.39848834e-03,\n",
       "        1.31514564e-01, 1.58981115e-04],\n",
       "       ...,\n",
       "       [5.29935723e-03, 1.26845658e-01, 7.09381700e-01, 6.54348347e-04,\n",
       "        1.57780439e-01, 3.85560525e-05],\n",
       "       [8.26327085e-01, 1.08056985e-04, 1.27981221e-02, 1.33469164e-01,\n",
       "        1.52346864e-03, 2.57741306e-02],\n",
       "       [2.29764101e-03, 1.76291942e-05, 9.95881081e-01, 1.16311142e-03,\n",
       "        6.09282961e-06, 6.34524855e-04]], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lidpQA8TsGw",
    "outputId": "04619440-154f-424e-e245-171b46c2d2ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 37ms/step - loss: 0.6918 - accuracy: 0.7517\n",
      "Test loss 0.6918388605117798\n",
      "Test accuracy 0.7516908049583435\n"
     ]
    }
   ],
   "source": [
    "score = Xception_02.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZiNZo-9YHK5"
   },
   "source": [
    "#### **\"Xception_03\" (RED NEURONAL CONVOLUCIONAL)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "4SSBY2mh7WZ5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "Xception_model_03 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "hggHKT6iYHK7"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_03\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_03.trainable = False\n",
    "\n",
    "image_size=128\n",
    "\n",
    "Xception_03 = Sequential()\n",
    "\n",
    "Xception_03.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "Xception_03.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_03.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "Xception_03.add(RandomRotation(factor=(-0.3,0.3)))\n",
    "#Xception_03.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_03.add(RandomCrop(height=64, width=64))\n",
    "Xception_03.add(RandomContrast(factor=0.3))\n",
    "\n",
    "#Xception_03.add(Resizing(image_size, image_size))\n",
    "\n",
    "#Xception_03.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_03.add(Xception_model_03)\n",
    "\n",
    "#Xception_03.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "7xTco43HYHK7"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#Xception_03.add(GlobalAveragePooling2D())\n",
    "#Xception_03.add(Flatten(name=\"flatten\"))\n",
    "#Xception_03.add(Dense(124, activation=\"relu\"))\n",
    "#Xception_03.add(Dropout(0.325))\n",
    "\n",
    "Xception_03.add(GlobalAveragePooling2D())\n",
    "Xception_03.add(Dropout(0.2))\n",
    "Xception_03.add(Dense(128, activation=\"relu\"))\n",
    "Xception_03.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "tW5mqe-5YHK8"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "\n",
    "Xception_03.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10gk5tt5YHK8",
    "outputId": "fd6eaee1-c166-4c70-e371-88f24bb742fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 13s - loss: 1.0462 - accuracy: 0.6125 - val_loss: 0.8124 - val_accuracy: 0.7125\n",
      "Epoch 2/20\n",
      "191/191 - 9s - loss: 0.8858 - accuracy: 0.6756 - val_loss: 0.7744 - val_accuracy: 0.7230\n",
      "Epoch 3/20\n",
      "191/191 - 9s - loss: 0.8319 - accuracy: 0.6970 - val_loss: 0.7967 - val_accuracy: 0.7192\n",
      "Epoch 4/20\n",
      "191/191 - 9s - loss: 0.8005 - accuracy: 0.7042 - val_loss: 0.7546 - val_accuracy: 0.7358\n",
      "Epoch 5/20\n",
      "191/191 - 9s - loss: 0.7814 - accuracy: 0.7139 - val_loss: 0.7426 - val_accuracy: 0.7315\n",
      "Epoch 6/20\n",
      "191/191 - 9s - loss: 0.7424 - accuracy: 0.7261 - val_loss: 0.7626 - val_accuracy: 0.7353\n",
      "Epoch 7/20\n",
      "191/191 - 9s - loss: 0.7238 - accuracy: 0.7425 - val_loss: 0.7292 - val_accuracy: 0.7438\n",
      "Epoch 8/20\n",
      "191/191 - 9s - loss: 0.7118 - accuracy: 0.7353 - val_loss: 0.7393 - val_accuracy: 0.7495\n",
      "Epoch 9/20\n",
      "191/191 - 9s - loss: 0.6902 - accuracy: 0.7461 - val_loss: 0.7134 - val_accuracy: 0.7619\n",
      "Epoch 10/20\n",
      "191/191 - 9s - loss: 0.6584 - accuracy: 0.7558 - val_loss: 0.7301 - val_accuracy: 0.7443\n",
      "Epoch 11/20\n",
      "191/191 - 9s - loss: 0.6557 - accuracy: 0.7619 - val_loss: 0.7282 - val_accuracy: 0.7533\n",
      "Epoch 12/20\n",
      "191/191 - 9s - loss: 0.6640 - accuracy: 0.7521 - val_loss: 0.7142 - val_accuracy: 0.7524\n",
      "Epoch 13/20\n",
      "191/191 - 9s - loss: 0.6365 - accuracy: 0.7695 - val_loss: 0.7120 - val_accuracy: 0.7481\n",
      "Epoch 14/20\n",
      "191/191 - 9s - loss: 0.6194 - accuracy: 0.7710 - val_loss: 0.7289 - val_accuracy: 0.7514\n",
      "Epoch 15/20\n",
      "191/191 - 9s - loss: 0.6347 - accuracy: 0.7738 - val_loss: 0.7174 - val_accuracy: 0.7590\n",
      "Epoch 16/20\n",
      "191/191 - 9s - loss: 0.5995 - accuracy: 0.7867 - val_loss: 0.7424 - val_accuracy: 0.7453\n",
      "Epoch 17/20\n",
      "191/191 - 9s - loss: 0.6035 - accuracy: 0.7759 - val_loss: 0.7118 - val_accuracy: 0.7547\n",
      "Epoch 18/20\n",
      "191/191 - 9s - loss: 0.5712 - accuracy: 0.7899 - val_loss: 0.7388 - val_accuracy: 0.7467\n",
      "Epoch 19/20\n",
      "191/191 - 9s - loss: 0.5695 - accuracy: 0.7915 - val_loss: 0.7255 - val_accuracy: 0.7519\n",
      "Epoch 20/20\n",
      "191/191 - 9s - loss: 0.5690 - accuracy: 0.7951 - val_loss: 0.7232 - val_accuracy: 0.7543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6c12b2690>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_03.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLLLv8pZYHK9"
   },
   "outputs": [],
   "source": [
    "probs = Xception_03.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QoRU8DVYHK9",
    "outputId": "7422dd46-4d3a-4867-b196-8e2c5b516a45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8478826e-02, 9.4686824e-01, 2.9692622e-02, 4.3826941e-03,\n",
       "        3.5677222e-04, 2.2077093e-04],\n",
       "       [2.5495762e-02, 3.6125355e-03, 5.6086677e-01, 4.1423100e-03,\n",
       "        6.6999689e-04, 4.0521267e-01],\n",
       "       [2.8144272e-02, 8.6918083e-04, 9.9270009e-03, 7.5634629e-02,\n",
       "        7.0513922e-01, 1.8028568e-01],\n",
       "       ...,\n",
       "       [1.6862992e-03, 3.3198326e-04, 5.3051766e-03, 9.9083227e-01,\n",
       "        7.1992242e-04, 1.1243555e-03],\n",
       "       [2.9328457e-01, 4.1125230e-02, 2.0978114e-01, 4.3635428e-01,\n",
       "        1.7068150e-02, 2.3867500e-03],\n",
       "       [9.9407578e-01, 2.0522374e-04, 1.6179309e-03, 3.5933473e-03,\n",
       "        3.6496992e-04, 1.4268514e-04]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLZBgShmYHK-",
    "outputId": "0a426016-f3f7-4eaa-b7ed-b638be8923ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 39ms/step - loss: 0.7067 - accuracy: 0.7483\n",
      "Test loss 0.7067177295684814\n",
      "Test accuracy 0.7483091950416565\n"
     ]
    }
   ],
   "source": [
    "score = Xception_03.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d600a1euqORh"
   },
   "source": [
    "#### **\"Xception_04\" (RED NEURONAL CONVOLUCIONAL)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "_U8mq2_H7vX9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "Xception_model_04 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "9MBvvFf4qORi"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_04\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling, RandomContrast\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_04.trainable = False\n",
    "\n",
    "image_size=128\n",
    "\n",
    "Xception_04 = Sequential()\n",
    "\n",
    "Xception_04.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "Xception_04.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_04.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "Xception_04.add(RandomRotation(factor=(-0.3,0.3)))\n",
    "#Xception_04.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_04.add(RandomCrop(height=64, width=64))\n",
    "Xception_04.add(RandomContrast(factor=0.3))\n",
    "\n",
    "#Xception_04.add(Resizing(image_size, image_size))\n",
    "\n",
    "#Xception_04.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_04.add(Xception_model_04)\n",
    "\n",
    "#Xception_04.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "JysVrSdxqORi"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#Xception_04.add(GlobalAveragePooling2D())\n",
    "#Xception_04.add(Flatten(name=\"flatten\"))\n",
    "#Xception_04.add(Dense(124, activation=\"relu\"))\n",
    "#Xception_04.add(Dropout(0.325))\n",
    "\n",
    "Xception_04.add(GlobalAveragePooling2D())\n",
    "Xception_04.add(Dropout(0.4))\n",
    "Xception_04.add(Dense(128, activation=\"relu\"))\n",
    "Xception_04.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "3aC9T3ejqORj"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "\n",
    "Xception_04.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3Hj4KbaqORj",
    "outputId": "adbc1051-94b0-4fe5-b990-c9300331f904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 13s - loss: 1.1181 - accuracy: 0.5881 - val_loss: 0.8886 - val_accuracy: 0.6803\n",
      "Epoch 2/20\n",
      "191/191 - 9s - loss: 0.9348 - accuracy: 0.6488 - val_loss: 0.7898 - val_accuracy: 0.7306\n",
      "Epoch 3/20\n",
      "191/191 - 9s - loss: 0.8755 - accuracy: 0.6756 - val_loss: 0.7691 - val_accuracy: 0.7339\n",
      "Epoch 4/20\n",
      "191/191 - 9s - loss: 0.8458 - accuracy: 0.6888 - val_loss: 0.7809 - val_accuracy: 0.7258\n",
      "Epoch 5/20\n",
      "191/191 - 9s - loss: 0.8186 - accuracy: 0.7011 - val_loss: 0.7475 - val_accuracy: 0.7434\n",
      "Epoch 6/20\n",
      "191/191 - 9s - loss: 0.8207 - accuracy: 0.6989 - val_loss: 0.7664 - val_accuracy: 0.7282\n",
      "Epoch 7/20\n",
      "191/191 - 9s - loss: 0.7735 - accuracy: 0.7169 - val_loss: 0.7375 - val_accuracy: 0.7367\n",
      "Epoch 8/20\n",
      "191/191 - 9s - loss: 0.7873 - accuracy: 0.7095 - val_loss: 0.7347 - val_accuracy: 0.7472\n",
      "Epoch 9/20\n",
      "191/191 - 9s - loss: 0.7593 - accuracy: 0.7200 - val_loss: 0.7171 - val_accuracy: 0.7438\n",
      "Epoch 10/20\n",
      "191/191 - 9s - loss: 0.7422 - accuracy: 0.7308 - val_loss: 0.7178 - val_accuracy: 0.7462\n",
      "Epoch 11/20\n",
      "191/191 - 9s - loss: 0.7393 - accuracy: 0.7353 - val_loss: 0.7239 - val_accuracy: 0.7448\n",
      "Epoch 12/20\n",
      "191/191 - 9s - loss: 0.7181 - accuracy: 0.7323 - val_loss: 0.7030 - val_accuracy: 0.7547\n",
      "Epoch 13/20\n",
      "191/191 - 9s - loss: 0.7169 - accuracy: 0.7382 - val_loss: 0.7068 - val_accuracy: 0.7557\n",
      "Epoch 14/20\n",
      "191/191 - 9s - loss: 0.7104 - accuracy: 0.7325 - val_loss: 0.7346 - val_accuracy: 0.7415\n",
      "Epoch 15/20\n",
      "191/191 - 9s - loss: 0.6974 - accuracy: 0.7376 - val_loss: 0.7362 - val_accuracy: 0.7438\n",
      "Epoch 16/20\n",
      "191/191 - 9s - loss: 0.6961 - accuracy: 0.7501 - val_loss: 0.7270 - val_accuracy: 0.7415\n",
      "Epoch 17/20\n",
      "191/191 - 9s - loss: 0.6881 - accuracy: 0.7489 - val_loss: 0.7026 - val_accuracy: 0.7514\n",
      "Epoch 18/20\n",
      "191/191 - 10s - loss: 0.6758 - accuracy: 0.7514 - val_loss: 0.7001 - val_accuracy: 0.7533\n",
      "Epoch 19/20\n",
      "191/191 - 9s - loss: 0.6812 - accuracy: 0.7537 - val_loss: 0.7058 - val_accuracy: 0.7481\n",
      "Epoch 20/20\n",
      "191/191 - 9s - loss: 0.6633 - accuracy: 0.7525 - val_loss: 0.7211 - val_accuracy: 0.7514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6b4d89fd0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_04.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKE2I5mCqORj"
   },
   "outputs": [],
   "source": [
    "probs = Xception_04.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFrvXGCDqORj",
    "outputId": "d0b260ba-3de1-4aec-f3ae-8450305f72bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.2047097e-02, 9.1225374e-06, 4.2449083e-02, 4.1655727e-02,\n",
       "        2.0746699e-02, 8.1309229e-01],\n",
       "       [2.4724575e-02, 6.6795328e-04, 1.4262925e-02, 9.5509499e-01,\n",
       "        4.1303271e-03, 1.1191954e-03],\n",
       "       [2.2120936e-01, 3.9430469e-02, 8.7776214e-02, 1.3250618e-01,\n",
       "        5.0254405e-01, 1.6533744e-02],\n",
       "       ...,\n",
       "       [4.1581439e-03, 5.1826117e-07, 4.3810820e-03, 6.4870506e-03,\n",
       "        6.5566582e-04, 9.8431754e-01],\n",
       "       [1.5169637e-03, 9.7629434e-01, 1.9815119e-02, 1.5670460e-04,\n",
       "        2.1615461e-03, 5.5314977e-05],\n",
       "       [2.2778916e-03, 4.0777776e-02, 1.6461903e-01, 1.1792609e-03,\n",
       "        1.7149830e-02, 7.7399617e-01]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2_b8lSzqORk",
    "outputId": "e3899372-8a3a-4730-9281-ae548036bd90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 41ms/step - loss: 0.7059 - accuracy: 0.7498\n",
      "Test loss 0.7059474587440491\n",
      "Test accuracy 0.7497584819793701\n"
     ]
    }
   ],
   "source": [
    "score = Xception_04.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5ZGHguA0QlX"
   },
   "source": [
    "#### **\"Xception_05\" (RED NEURONAL CONVOLUCIONAL)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "S04re9Yr8Yy7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "Xception_model_05 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "GkoR3TuP0QlY"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_05\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling, RandomContrast\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_05.trainable = False\n",
    "\n",
    "image_size=128\n",
    "\n",
    "Xception_05 = Sequential()\n",
    "\n",
    "Xception_05.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "Xception_05.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_05.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "Xception_05.add(RandomRotation(factor=(-0.3,0.3)))\n",
    "#Xception_05.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_05.add(RandomCrop(height=64, width=64))\n",
    "Xception_05.add(RandomContrast(factor=0.3))\n",
    "\n",
    "#Xception_05.add(Resizing(image_size, image_size))\n",
    "\n",
    "#Xception_05.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_05.add(BatchNormalization())\n",
    "\n",
    "Xception_05.add(Xception_model_05)\n",
    "\n",
    "#Xception_05.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "tjfZU4KC0QlZ"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#Xception_05.add(GlobalAveragePooling2D())\n",
    "#Xception_05.add(Flatten(name=\"flatten\"))\n",
    "#Xception_05.add(Dense(124, activation=\"relu\"))\n",
    "#Xception_05.add(Dropout(0.325))\n",
    "\n",
    "Xception_05.add(GlobalAveragePooling2D())\n",
    "Xception_05.add(Dropout(0.4))\n",
    "Xception_05.add(Dense(10240, activation=\"relu\"))\n",
    "#Xception_05.add(Dropout(0.4))\n",
    "#Xception_05.add(Dense(4096, activation=\"relu\"))\n",
    "#Xception_05.add(Dropout(0.4))\n",
    "Xception_05.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "GLzBQqvH0Qla"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "\n",
    "Xception_05.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9642ZsL50Qla",
    "outputId": "a73ccc31-272a-4991-ae2e-5a3c207df423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 23s - loss: 1.4427 - accuracy: 0.5564 - val_loss: 0.9854 - val_accuracy: 0.6338\n",
      "Epoch 2/20\n",
      "191/191 - 18s - loss: 1.0069 - accuracy: 0.6235 - val_loss: 0.9313 - val_accuracy: 0.6556\n",
      "Epoch 3/20\n",
      "191/191 - 18s - loss: 0.9521 - accuracy: 0.6501 - val_loss: 0.8317 - val_accuracy: 0.7144\n",
      "Epoch 4/20\n",
      "191/191 - 18s - loss: 0.9048 - accuracy: 0.6672 - val_loss: 0.7950 - val_accuracy: 0.7158\n",
      "Epoch 5/20\n",
      "191/191 - 18s - loss: 0.8633 - accuracy: 0.6848 - val_loss: 0.8032 - val_accuracy: 0.7192\n",
      "Epoch 6/20\n",
      "191/191 - 18s - loss: 0.8313 - accuracy: 0.6907 - val_loss: 0.7563 - val_accuracy: 0.7348\n",
      "Epoch 7/20\n",
      "191/191 - 18s - loss: 0.8225 - accuracy: 0.7047 - val_loss: 0.7951 - val_accuracy: 0.7092\n",
      "Epoch 8/20\n",
      "191/191 - 18s - loss: 0.7617 - accuracy: 0.7203 - val_loss: 0.7691 - val_accuracy: 0.7230\n",
      "Epoch 9/20\n",
      "191/191 - 18s - loss: 0.7388 - accuracy: 0.7361 - val_loss: 0.7377 - val_accuracy: 0.7462\n",
      "Epoch 10/20\n",
      "191/191 - 18s - loss: 0.7379 - accuracy: 0.7284 - val_loss: 0.7715 - val_accuracy: 0.7334\n",
      "Epoch 11/20\n",
      "191/191 - 18s - loss: 0.7275 - accuracy: 0.7299 - val_loss: 0.7262 - val_accuracy: 0.7419\n",
      "Epoch 12/20\n",
      "191/191 - 18s - loss: 0.6903 - accuracy: 0.7369 - val_loss: 0.7363 - val_accuracy: 0.7419\n",
      "Epoch 13/20\n",
      "191/191 - 18s - loss: 0.6853 - accuracy: 0.7494 - val_loss: 0.7951 - val_accuracy: 0.7154\n",
      "Epoch 14/20\n",
      "191/191 - 18s - loss: 0.6742 - accuracy: 0.7491 - val_loss: 0.7371 - val_accuracy: 0.7557\n",
      "Epoch 15/20\n",
      "191/191 - 18s - loss: 0.6603 - accuracy: 0.7547 - val_loss: 0.7534 - val_accuracy: 0.7353\n",
      "Epoch 16/20\n",
      "191/191 - 18s - loss: 0.6511 - accuracy: 0.7622 - val_loss: 0.7396 - val_accuracy: 0.7438\n",
      "Epoch 17/20\n",
      "191/191 - 18s - loss: 0.6356 - accuracy: 0.7713 - val_loss: 0.7189 - val_accuracy: 0.7552\n",
      "Epoch 18/20\n",
      "191/191 - 18s - loss: 0.6113 - accuracy: 0.7812 - val_loss: 0.7536 - val_accuracy: 0.7405\n",
      "Epoch 19/20\n",
      "191/191 - 18s - loss: 0.6330 - accuracy: 0.7664 - val_loss: 0.7216 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "191/191 - 18s - loss: 0.5989 - accuracy: 0.7818 - val_loss: 0.7649 - val_accuracy: 0.7358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc6b79a4190>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_05.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGg2Iwc_0Qlb"
   },
   "outputs": [],
   "source": [
    "probs = Xception_05.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-cWxptg0Qlb",
    "outputId": "48013ae8-e4f2-42ee-b3f3-f0e24598c3ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.00627999e-05, 1.07990138e-01, 5.27922630e-01, 3.63992870e-01,\n",
       "        4.90229613e-05, 1.53034234e-05],\n",
       "       [1.63527020e-05, 4.28126477e-05, 3.61084181e-04, 9.99550641e-01,\n",
       "        6.61909053e-06, 2.24610267e-05],\n",
       "       [1.35537043e-01, 2.37608892e-05, 8.63934338e-01, 4.91347782e-05,\n",
       "        7.06752826e-06, 4.48691571e-04],\n",
       "       ...,\n",
       "       [5.18840551e-03, 3.37794409e-05, 3.29510751e-03, 1.81082869e-05,\n",
       "        9.91400540e-01, 6.40907383e-05],\n",
       "       [9.08057094e-02, 6.72620197e-04, 9.90287662e-02, 5.85549064e-02,\n",
       "        1.23588935e-01, 6.27349019e-01],\n",
       "       [9.99985337e-01, 1.50487990e-11, 1.32580344e-05, 1.25287431e-06,\n",
       "        4.69386983e-08, 7.55105205e-08]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RE46_UH0Qlc",
    "outputId": "ecd31edd-445f-4700-c7bf-705ab6fd3f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 39ms/step - loss: 0.7389 - accuracy: 0.7464\n",
      "Test loss 0.7388555407524109\n",
      "Test accuracy 0.7463768124580383\n"
     ]
    }
   ],
   "source": [
    "score = Xception_05.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FO-3S8YgaYqm"
   },
   "source": [
    "#### **\"Xception_06\" (RED NEURONAL CONVOLUCIONAL)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "5uk1q2PQA9R-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "Xception_model_06 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "E4FopkOGaYqn"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_06\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling, RandomContrast\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_06.trainable = False\n",
    "\n",
    "image_size=128\n",
    "\n",
    "Xception_06 = Sequential()\n",
    "\n",
    "Xception_06.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "Xception_06.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_06.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "Xception_06.add(RandomRotation(factor=(-0.3,0.3)))\n",
    "#Xception_06.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_06.add(RandomCrop(height=64, width=64))\n",
    "Xception_06.add(RandomContrast(factor=0.3))\n",
    "\n",
    "#Xception_06.add(Resizing(image_size, image_size))\n",
    "\n",
    "#Xception_06.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_06.add(BatchNormalization())\n",
    "\n",
    "Xception_06.add(Xception_model_06)\n",
    "\n",
    "#Xception_06.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "N6BWF6F1aYqn"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#Xception_06.add(GlobalAveragePooling2D())\n",
    "#Xception_06.add(Flatten(name=\"flatten\"))\n",
    "#Xception_06.add(Dense(124, activation=\"relu\"))\n",
    "#Xception_06.add(Dropout(0.325))\n",
    "\n",
    "Xception_06.add(GlobalAveragePooling2D())\n",
    "Xception_06.add(Dropout(0.425))\n",
    "Xception_06.add(Dense(4096, activation=\"relu\"))\n",
    "#Xception_06.add(Dropout(0.4))\n",
    "#Xception_06.add(Dense(4096, activation=\"relu\"))\n",
    "#Xception_06.add(Dropout(0.4))\n",
    "Xception_06.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "ncPDpN9VaYqn"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "\n",
    "Xception_06.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg0puDcPaYqo",
    "outputId": "ca6f95e8-e936-49d6-fa0d-3d06c781dd67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 22s - loss: 1.3089 - accuracy: 0.5554 - val_loss: 0.9781 - val_accuracy: 0.6395\n",
      "Epoch 2/20\n",
      "191/191 - 17s - loss: 1.0271 - accuracy: 0.6143 - val_loss: 0.8907 - val_accuracy: 0.6736\n",
      "Epoch 3/20\n",
      "191/191 - 17s - loss: 0.9436 - accuracy: 0.6516 - val_loss: 0.8522 - val_accuracy: 0.6969\n",
      "Epoch 4/20\n",
      "191/191 - 17s - loss: 0.9058 - accuracy: 0.6677 - val_loss: 0.8445 - val_accuracy: 0.7002\n",
      "Epoch 5/20\n",
      "191/191 - 17s - loss: 0.8736 - accuracy: 0.6802 - val_loss: 0.8403 - val_accuracy: 0.6992\n",
      "Epoch 6/20\n",
      "191/191 - 17s - loss: 0.8388 - accuracy: 0.6917 - val_loss: 0.8228 - val_accuracy: 0.7102\n",
      "Epoch 7/20\n",
      "191/191 - 17s - loss: 0.8186 - accuracy: 0.6991 - val_loss: 0.7572 - val_accuracy: 0.7367\n",
      "Epoch 8/20\n",
      "191/191 - 17s - loss: 0.7960 - accuracy: 0.6978 - val_loss: 0.8022 - val_accuracy: 0.7149\n",
      "Epoch 9/20\n",
      "191/191 - 17s - loss: 0.7563 - accuracy: 0.7238 - val_loss: 0.7610 - val_accuracy: 0.7339\n",
      "Epoch 10/20\n",
      "191/191 - 17s - loss: 0.7610 - accuracy: 0.7179 - val_loss: 0.7570 - val_accuracy: 0.7324\n",
      "Epoch 11/20\n",
      "191/191 - 17s - loss: 0.7115 - accuracy: 0.7389 - val_loss: 0.7330 - val_accuracy: 0.7381\n",
      "Epoch 12/20\n",
      "191/191 - 17s - loss: 0.7237 - accuracy: 0.7346 - val_loss: 0.7286 - val_accuracy: 0.7467\n",
      "Epoch 13/20\n",
      "191/191 - 17s - loss: 0.6862 - accuracy: 0.7511 - val_loss: 0.7495 - val_accuracy: 0.7429\n",
      "Epoch 14/20\n",
      "191/191 - 17s - loss: 0.6892 - accuracy: 0.7494 - val_loss: 0.7348 - val_accuracy: 0.7467\n",
      "Epoch 15/20\n",
      "191/191 - 17s - loss: 0.6662 - accuracy: 0.7540 - val_loss: 0.7699 - val_accuracy: 0.7372\n",
      "Epoch 16/20\n",
      "191/191 - 17s - loss: 0.6500 - accuracy: 0.7670 - val_loss: 0.7555 - val_accuracy: 0.7348\n",
      "Epoch 17/20\n",
      "191/191 - 17s - loss: 0.6403 - accuracy: 0.7685 - val_loss: 0.7318 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "191/191 - 17s - loss: 0.6395 - accuracy: 0.7654 - val_loss: 0.7612 - val_accuracy: 0.7339\n",
      "Epoch 19/20\n",
      "191/191 - 17s - loss: 0.6160 - accuracy: 0.7767 - val_loss: 0.7290 - val_accuracy: 0.7514\n",
      "Epoch 20/20\n",
      "191/191 - 17s - loss: 0.6158 - accuracy: 0.7728 - val_loss: 0.7257 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc44ac75310>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_06.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qko2E9xtaYqo"
   },
   "outputs": [],
   "source": [
    "probs = Xception_06.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVHNu4a8aYqo",
    "outputId": "b99c1d7b-cd6f-48c0-c9ce-5339fdb5881e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.21622381e-02, 1.86057448e-01, 7.66516566e-01, 1.55370180e-02,\n",
       "        5.21354517e-03, 4.51317988e-03],\n",
       "       [1.04911085e-02, 1.20130882e-01, 4.20834839e-01, 4.32155073e-01,\n",
       "        1.22003406e-02, 4.18765983e-03],\n",
       "       [7.88803935e-01, 2.38671655e-05, 6.71056448e-04, 1.89846812e-03,\n",
       "        2.03412652e-01, 5.19000692e-03],\n",
       "       ...,\n",
       "       [4.50996886e-05, 3.24213170e-02, 9.67521548e-01, 2.42718806e-06,\n",
       "        8.37386597e-06, 1.31022159e-06],\n",
       "       [1.29110576e-03, 7.86271021e-02, 8.91767859e-01, 1.70600452e-02,\n",
       "        2.04129890e-03, 9.21260938e-03],\n",
       "       [3.90130794e-03, 8.38731008e-04, 3.68128978e-02, 4.80816874e-04,\n",
       "        1.15844328e-03, 9.56807852e-01]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivnVFis7aYqo",
    "outputId": "96d81a46-cac6-4ae3-d7e7-b6b4db3a5d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 39ms/step - loss: 0.7215 - accuracy: 0.7517\n",
      "Test loss 0.7214577198028564\n",
      "Test accuracy 0.7516908049583435\n"
     ]
    }
   ],
   "source": [
    "score = Xception_06.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Mv5e1aP-idz"
   },
   "source": [
    "#### **\"Xception_07\" (RED NEURONAL CONVOLUCIONAL)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "AteTTGrPBcXL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "Xception_model_07 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "BtD9-2VJ-idz"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_07\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling, RandomContrast\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_07.trainable = False\n",
    "\n",
    "image_size=128\n",
    "\n",
    "Xception_07 = Sequential()\n",
    "\n",
    "Xception_07.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "Xception_07.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_07.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "Xception_07.add(RandomRotation(factor=(-0.3,0.3)))\n",
    "#Xception_07.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_07.add(RandomCrop(height=64, width=64))\n",
    "Xception_07.add(RandomContrast(factor=0.35))\n",
    "\n",
    "#Xception_07.add(Resizing(image_size, image_size))\n",
    "\n",
    "#Xception_07.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_07.add(BatchNormalization())\n",
    "\n",
    "Xception_07.add(Xception_model_07)\n",
    "\n",
    "#Xception_07.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "d1I2QgnD-id0"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#Xception_07.add(GlobalAveragePooling2D())\n",
    "#Xception_07.add(Flatten(name=\"flatten\"))\n",
    "#Xception_07.add(Dense(124, activation=\"relu\"))\n",
    "#Xception_07.add(Dropout(0.325))\n",
    "\n",
    "Xception_07.add(GlobalAveragePooling2D())\n",
    "Xception_07.add(Dropout(0.4))\n",
    "Xception_07.add(Dense(20000, activation=\"relu\"))\n",
    "#Xception_07.add(Dropout(0.4))\n",
    "#Xception_07.add(Dense(4096, activation=\"relu\"))\n",
    "#Xception_07.add(Dropout(0.4))\n",
    "Xception_07.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "ZW0g843J-id0"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "Xception_07.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVlEcvRk-id0",
    "outputId": "9b4fc3f7-8cec-4236-b73a-6f30c3420946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 23s - loss: 1.6992 - accuracy: 0.5311 - val_loss: 1.0773 - val_accuracy: 0.6176\n",
      "Epoch 2/20\n",
      "191/191 - 18s - loss: 1.0222 - accuracy: 0.6220 - val_loss: 0.8899 - val_accuracy: 0.6845\n",
      "Epoch 3/20\n",
      "191/191 - 18s - loss: 0.9363 - accuracy: 0.6565 - val_loss: 0.8326 - val_accuracy: 0.7144\n",
      "Epoch 4/20\n",
      "191/191 - 18s - loss: 0.9086 - accuracy: 0.6620 - val_loss: 0.8288 - val_accuracy: 0.6988\n",
      "Epoch 5/20\n",
      "191/191 - 18s - loss: 0.8638 - accuracy: 0.6800 - val_loss: 0.7798 - val_accuracy: 0.7296\n",
      "Epoch 6/20\n",
      "191/191 - 18s - loss: 0.8410 - accuracy: 0.6810 - val_loss: 0.7791 - val_accuracy: 0.7263\n",
      "Epoch 7/20\n",
      "191/191 - 18s - loss: 0.8146 - accuracy: 0.6943 - val_loss: 0.7726 - val_accuracy: 0.7244\n",
      "Epoch 8/20\n",
      "191/191 - 18s - loss: 0.7926 - accuracy: 0.7116 - val_loss: 0.7683 - val_accuracy: 0.7329\n",
      "Epoch 9/20\n",
      "191/191 - 18s - loss: 0.7671 - accuracy: 0.7137 - val_loss: 0.7461 - val_accuracy: 0.7348\n",
      "Epoch 10/20\n",
      "191/191 - 18s - loss: 0.7370 - accuracy: 0.7294 - val_loss: 0.7898 - val_accuracy: 0.7225\n",
      "Epoch 11/20\n",
      "191/191 - 18s - loss: 0.7211 - accuracy: 0.7424 - val_loss: 0.7402 - val_accuracy: 0.7362\n",
      "Epoch 12/20\n",
      "191/191 - 18s - loss: 0.6909 - accuracy: 0.7451 - val_loss: 0.7812 - val_accuracy: 0.7315\n",
      "Epoch 13/20\n",
      "191/191 - 18s - loss: 0.6921 - accuracy: 0.7458 - val_loss: 0.7407 - val_accuracy: 0.7372\n",
      "Epoch 14/20\n",
      "191/191 - 18s - loss: 0.6813 - accuracy: 0.7456 - val_loss: 0.7761 - val_accuracy: 0.7372\n",
      "Epoch 15/20\n",
      "191/191 - 18s - loss: 0.6559 - accuracy: 0.7547 - val_loss: 0.7222 - val_accuracy: 0.7424\n",
      "Epoch 16/20\n",
      "191/191 - 18s - loss: 0.6469 - accuracy: 0.7659 - val_loss: 0.7508 - val_accuracy: 0.7358\n",
      "Epoch 17/20\n",
      "191/191 - 18s - loss: 0.6252 - accuracy: 0.7741 - val_loss: 0.7944 - val_accuracy: 0.7306\n",
      "Epoch 18/20\n",
      "191/191 - 18s - loss: 0.6240 - accuracy: 0.7700 - val_loss: 0.7454 - val_accuracy: 0.7358\n",
      "Epoch 19/20\n",
      "191/191 - 18s - loss: 0.6058 - accuracy: 0.7820 - val_loss: 0.7425 - val_accuracy: 0.7391\n",
      "Epoch 20/20\n",
      "191/191 - 18s - loss: 0.6215 - accuracy: 0.7761 - val_loss: 0.7151 - val_accuracy: 0.7566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc60cdeed10>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_07.fit(\n",
    "    train_dataset128, # Training data\n",
    "    validation_data=val_dataset128,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_carY4qV-id0"
   },
   "outputs": [],
   "source": [
    "probs = Xception_07.predict(test_dataset128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0kdgjVD-id0",
    "outputId": "833f98fd-42b9-46df-f86d-6e4da6a28ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.1187331e-02, 4.1809768e-04, 2.8119015e-02, 9.2365104e-01,\n",
       "        6.9186245e-03, 9.7058555e-03],\n",
       "       [2.3326330e-04, 1.4647424e-05, 8.2416018e-04, 1.2806116e-04,\n",
       "        4.0253748e-05, 9.9875963e-01],\n",
       "       [1.7799764e-03, 8.8318489e-02, 2.7713068e-02, 8.7967795e-01,\n",
       "        1.3059330e-03, 1.2046031e-03],\n",
       "       ...,\n",
       "       [4.3919794e-03, 1.7319683e-02, 7.0950590e-02, 1.2932039e-03,\n",
       "        8.2007367e-03, 8.9784384e-01],\n",
       "       [6.5933824e-02, 4.0969956e-03, 8.9316779e-01, 3.3819363e-02,\n",
       "        1.0071383e-03, 1.9747640e-03],\n",
       "       [1.9798519e-02, 2.0853510e-02, 8.9422983e-01, 1.3158223e-02,\n",
       "        9.0952022e-03, 4.2864766e-02]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLWISJcO-id1",
    "outputId": "6946e601-c5f9-4c5e-9282-4e36b737bed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 40ms/step - loss: 0.7161 - accuracy: 0.7498\n",
      "Test loss 0.7160783410072327\n",
      "Test accuracy 0.7497584819793701\n"
     ]
    }
   ],
   "source": [
    "score = Xception_07.evaluate(test_dataset128)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plZRC1wpLVEF"
   },
   "source": [
    "#### **\"Xception_08\" (RED NEURONAL CONVOLUCIONAL)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "Q4jZbzmBLVEI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "Xception_model_08 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "MUinEtEpLVEJ"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_08\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling, RandomContrast\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_08.trainable = False\n",
    "\n",
    "image_size_in=256\n",
    "\n",
    "image_size_model=128\n",
    "\n",
    "Xception_08 = Sequential()\n",
    "\n",
    "Xception_08.add(Lambda(preprocess_input, input_shape=(image_size_in, image_size_in, 3)))\n",
    "\n",
    "Xception_08.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_08.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "Xception_08.add(RandomRotation(factor=(-0.35,0.35)))\n",
    "#Xception_08.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_08.add(RandomCrop(height=64, width=64))\n",
    "Xception_08.add(RandomContrast(factor=0.35))\n",
    "\n",
    "Xception_08.add(Resizing(image_size_model, image_size_model))\n",
    "\n",
    "#Xception_08.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_08.add(BatchNormalization())\n",
    "\n",
    "Xception_08.add(Xception_model_08)\n",
    "\n",
    "#Xception_08.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "UKEtlm5PLVEJ"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#Xception_08.add(GlobalAveragePooling2D())\n",
    "#Xception_08.add(Flatten(name=\"flatten\"))\n",
    "#Xception_08.add(Dense(124, activation=\"relu\"))\n",
    "#Xception_08.add(Dropout(0.325))\n",
    "\n",
    "Xception_08.add(GlobalAveragePooling2D())\n",
    "Xception_08.add(Dropout(0.4))\n",
    "Xception_08.add(Dense(4096, activation=\"relu\"))\n",
    "Xception_08.add(Dropout(0.4))\n",
    "Xception_08.add(Dense(4096, activation=\"relu\"))\n",
    "#Xception_08.add(Dropout(0.4))\n",
    "Xception_08.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "XcBfV9tnLVEK"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "\n",
    "Xception_08.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IzqkH2z8LVEK",
    "outputId": "74423a61-6255-44cf-be5e-26ecf53a1139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 24s - loss: 1.4879 - accuracy: 0.5099 - val_loss: 1.0204 - val_accuracy: 0.6257\n",
      "Epoch 2/20\n",
      "191/191 - 20s - loss: 1.1136 - accuracy: 0.5842 - val_loss: 0.9823 - val_accuracy: 0.6518\n",
      "Epoch 3/20\n",
      "191/191 - 20s - loss: 1.0256 - accuracy: 0.6246 - val_loss: 1.0276 - val_accuracy: 0.6276\n",
      "Epoch 4/20\n",
      "191/191 - 20s - loss: 1.0107 - accuracy: 0.6282 - val_loss: 0.8887 - val_accuracy: 0.6945\n",
      "Epoch 5/20\n",
      "191/191 - 20s - loss: 0.9495 - accuracy: 0.6595 - val_loss: 0.9364 - val_accuracy: 0.6665\n",
      "Epoch 6/20\n",
      "191/191 - 20s - loss: 0.9351 - accuracy: 0.6588 - val_loss: 0.8800 - val_accuracy: 0.6912\n",
      "Epoch 7/20\n",
      "191/191 - 20s - loss: 0.9168 - accuracy: 0.6624 - val_loss: 0.7963 - val_accuracy: 0.7234\n",
      "Epoch 8/20\n",
      "191/191 - 20s - loss: 0.9029 - accuracy: 0.6744 - val_loss: 0.8054 - val_accuracy: 0.7139\n",
      "Epoch 9/20\n",
      "191/191 - 20s - loss: 0.8878 - accuracy: 0.6743 - val_loss: 0.8036 - val_accuracy: 0.7225\n",
      "Epoch 10/20\n",
      "191/191 - 20s - loss: 0.8767 - accuracy: 0.6841 - val_loss: 0.8136 - val_accuracy: 0.7130\n",
      "Epoch 11/20\n",
      "191/191 - 20s - loss: 0.8585 - accuracy: 0.6850 - val_loss: 0.7767 - val_accuracy: 0.7348\n",
      "Epoch 12/20\n",
      "191/191 - 20s - loss: 0.8396 - accuracy: 0.6924 - val_loss: 0.7965 - val_accuracy: 0.7201\n",
      "Epoch 13/20\n",
      "191/191 - 19s - loss: 0.8281 - accuracy: 0.6986 - val_loss: 0.7829 - val_accuracy: 0.7277\n",
      "Epoch 14/20\n",
      "191/191 - 19s - loss: 0.8120 - accuracy: 0.7034 - val_loss: 0.7751 - val_accuracy: 0.7343\n",
      "Epoch 15/20\n",
      "191/191 - 19s - loss: 0.8151 - accuracy: 0.7065 - val_loss: 0.7447 - val_accuracy: 0.7486\n",
      "Epoch 16/20\n",
      "191/191 - 19s - loss: 0.8182 - accuracy: 0.7059 - val_loss: 0.7513 - val_accuracy: 0.7362\n",
      "Epoch 17/20\n",
      "191/191 - 19s - loss: 0.8022 - accuracy: 0.7006 - val_loss: 0.7288 - val_accuracy: 0.7476\n",
      "Epoch 18/20\n",
      "191/191 - 19s - loss: 0.7806 - accuracy: 0.7128 - val_loss: 0.7370 - val_accuracy: 0.7476\n",
      "Epoch 19/20\n",
      "191/191 - 19s - loss: 0.7919 - accuracy: 0.7113 - val_loss: 0.7410 - val_accuracy: 0.7481\n",
      "Epoch 20/20\n",
      "191/191 - 19s - loss: 0.7766 - accuracy: 0.7131 - val_loss: 0.7745 - val_accuracy: 0.7306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc443361590>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_08.fit(\n",
    "    train_dataset256, # Training data\n",
    "    validation_data=val_dataset256,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpeLV6JsLVEL"
   },
   "outputs": [],
   "source": [
    "probs = Xception_08.predict(test_dataset256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvaCP3yqLVEL",
    "outputId": "f8d805fb-575d-498e-a296-bd8c516e2252"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4079761e-04, 2.9214441e-03, 6.5671408e-01, 3.3376923e-01,\n",
       "        6.2656025e-03, 1.8878197e-04],\n",
       "       [8.9763325e-01, 2.4986803e-05, 7.9193758e-04, 9.0257592e-02,\n",
       "        1.5704862e-03, 9.7216163e-03],\n",
       "       [2.2637451e-01, 2.0104339e-02, 3.3889678e-01, 1.4850448e-01,\n",
       "        1.1009477e-01, 1.5602517e-01],\n",
       "       ...,\n",
       "       [2.2778795e-03, 6.7920035e-07, 2.5282163e-04, 2.7742670e-04,\n",
       "        9.0592615e-03, 9.8813194e-01],\n",
       "       [3.4372300e-01, 4.9109990e-04, 1.2647092e-01, 5.0628030e-01,\n",
       "        1.6728515e-02, 6.3062599e-03],\n",
       "       [3.5477662e-04, 1.9524005e-07, 3.7100490e-06, 2.0562878e-05,\n",
       "        9.9926931e-01, 3.5139910e-04]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJymZ1eZLVEL",
    "outputId": "d24ee8bd-9f95-42bd-959b-c51ec1f902e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 47ms/step - loss: 0.7593 - accuracy: 0.7353\n",
      "Test loss 0.7593244910240173\n",
      "Test accuracy 0.7352656722068787\n"
     ]
    }
   ],
   "source": [
    "score = Xception_08.evaluate(test_dataset256)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5WXaOWz-aMt"
   },
   "source": [
    "#### **\"Xception_09\" (RED NEURONAL CONVOLUCIONAL)** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "E1tASRJM-aMt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "Xception_model_09 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "cqHyRamV-aMt"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_09\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling, RandomContrast\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_09.trainable = False\n",
    "\n",
    "image_size_in=256\n",
    "\n",
    "image_size_model=128\n",
    "\n",
    "Xception_09 = Sequential()\n",
    "\n",
    "Xception_09.add(Lambda(preprocess_input, input_shape=(image_size_in, image_size_in, 3)))\n",
    "\n",
    "Xception_09.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_09.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "Xception_09.add(RandomRotation(factor=(-0.4,0.4)))\n",
    "#Xception_09.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_09.add(RandomCrop(height=64, width=64))\n",
    "Xception_09.add(RandomContrast(factor=0.4))\n",
    "\n",
    "Xception_09.add(Resizing(image_size_model, image_size_model))\n",
    "\n",
    "#Xception_09.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_09.add(BatchNormalization())\n",
    "\n",
    "Xception_09.add(Xception_model_09)\n",
    "\n",
    "#Xception_09.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "uFoJlbdw-aMu"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#Xception_09.add(GlobalAveragePooling2D())\n",
    "#Xception_09.add(Flatten(name=\"flatten\"))\n",
    "#Xception_09.add(Dense(124, activation=\"relu\"))\n",
    "#Xception_09.add(Dropout(0.325))\n",
    "\n",
    "Xception_09.add(GlobalAveragePooling2D())\n",
    "Xception_09.add(Dropout(0.5))\n",
    "Xception_09.add(Dense(4096, activation=\"relu\"))\n",
    "Xception_09.add(Dropout(0.5))\n",
    "Xception_09.add(Dense(4096, activation=\"relu\"))\n",
    "#Xception_09.add(Dropout(0.4))\n",
    "Xception_09.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "fkD_SU34-aMu"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "\n",
    "Xception_09.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3mlFOWT-aMu",
    "outputId": "aa2b630b-0edf-42ac-f808-3ea8cd2d06ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 23s - loss: 1.5857 - accuracy: 0.4824 - val_loss: 1.0571 - val_accuracy: 0.6229\n",
      "Epoch 2/20\n",
      "191/191 - 19s - loss: 1.1738 - accuracy: 0.5715 - val_loss: 0.9862 - val_accuracy: 0.6414\n",
      "Epoch 3/20\n",
      "191/191 - 19s - loss: 1.1060 - accuracy: 0.5983 - val_loss: 0.9472 - val_accuracy: 0.6708\n",
      "Epoch 4/20\n",
      "191/191 - 19s - loss: 1.0597 - accuracy: 0.6084 - val_loss: 0.9131 - val_accuracy: 0.6898\n",
      "Epoch 5/20\n",
      "191/191 - 19s - loss: 1.0274 - accuracy: 0.6208 - val_loss: 0.9275 - val_accuracy: 0.6784\n",
      "Epoch 6/20\n",
      "191/191 - 19s - loss: 0.9958 - accuracy: 0.6407 - val_loss: 0.9160 - val_accuracy: 0.6660\n",
      "Epoch 7/20\n",
      "191/191 - 19s - loss: 0.9887 - accuracy: 0.6274 - val_loss: 0.9003 - val_accuracy: 0.6855\n",
      "Epoch 8/20\n",
      "191/191 - 19s - loss: 0.9720 - accuracy: 0.6447 - val_loss: 0.8642 - val_accuracy: 0.7002\n",
      "Epoch 9/20\n",
      "191/191 - 19s - loss: 0.9673 - accuracy: 0.6468 - val_loss: 0.8428 - val_accuracy: 0.7168\n",
      "Epoch 10/20\n",
      "191/191 - 19s - loss: 0.9564 - accuracy: 0.6490 - val_loss: 0.8548 - val_accuracy: 0.6888\n",
      "Epoch 11/20\n",
      "191/191 - 19s - loss: 0.9246 - accuracy: 0.6552 - val_loss: 0.8355 - val_accuracy: 0.7144\n",
      "Epoch 12/20\n",
      "191/191 - 19s - loss: 0.9131 - accuracy: 0.6684 - val_loss: 0.8108 - val_accuracy: 0.7187\n",
      "Epoch 13/20\n",
      "191/191 - 19s - loss: 0.8977 - accuracy: 0.6728 - val_loss: 0.7994 - val_accuracy: 0.7059\n",
      "Epoch 14/20\n",
      "191/191 - 19s - loss: 0.9114 - accuracy: 0.6703 - val_loss: 0.7681 - val_accuracy: 0.7291\n",
      "Epoch 15/20\n",
      "191/191 - 19s - loss: 0.8964 - accuracy: 0.6710 - val_loss: 0.7906 - val_accuracy: 0.7310\n",
      "Epoch 16/20\n",
      "191/191 - 19s - loss: 0.8820 - accuracy: 0.6809 - val_loss: 0.7735 - val_accuracy: 0.7234\n",
      "Epoch 17/20\n",
      "191/191 - 19s - loss: 0.8703 - accuracy: 0.6758 - val_loss: 0.7606 - val_accuracy: 0.7268\n",
      "Epoch 18/20\n",
      "191/191 - 19s - loss: 0.8692 - accuracy: 0.6818 - val_loss: 0.7663 - val_accuracy: 0.7386\n",
      "Epoch 19/20\n",
      "191/191 - 19s - loss: 0.8714 - accuracy: 0.6837 - val_loss: 0.7749 - val_accuracy: 0.7400\n",
      "Epoch 20/20\n",
      "191/191 - 19s - loss: 0.8720 - accuracy: 0.6809 - val_loss: 0.7720 - val_accuracy: 0.7358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc440c00890>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_09.fit(\n",
    "    train_dataset256, # Training data\n",
    "    validation_data=val_dataset256,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZIhVnA--aMw"
   },
   "outputs": [],
   "source": [
    "probs = Xception_09.predict(test_dataset256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKT6ZX1u-aMw",
    "outputId": "5e5d2089-079d-4936-a255-4b4c91974b88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.5813513e-02, 2.7820815e-03, 1.2146912e-01, 3.2051552e-02,\n",
       "        2.8838214e-02, 7.1904546e-01],\n",
       "       [5.5781585e-01, 4.0686498e-03, 1.0557474e-01, 1.3272688e-01,\n",
       "        1.4643119e-01, 5.3382616e-02],\n",
       "       [4.4676349e-02, 6.7304023e-02, 1.5760207e-01, 6.9047964e-01,\n",
       "        2.8783629e-02, 1.1154248e-02],\n",
       "       ...,\n",
       "       [5.3633563e-02, 7.5486349e-04, 3.6047988e-02, 2.3316128e-02,\n",
       "        1.1174751e-02, 8.7507272e-01],\n",
       "       [9.8427469e-01, 3.5312232e-11, 2.2840503e-04, 1.5496218e-02,\n",
       "        1.4051924e-10, 7.4728200e-07],\n",
       "       [2.4423765e-01, 7.9063801e-03, 2.0636912e-01, 2.8913486e-01,\n",
       "        2.0707361e-01, 4.5278393e-02]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ND-Feh-f-aMw",
    "outputId": "4ca88173-59be-4339-85f1-4c87466389ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 49ms/step - loss: 0.7605 - accuracy: 0.7329\n",
      "Test loss 0.7605149745941162\n",
      "Test accuracy 0.7328502535820007\n"
     ]
    }
   ],
   "source": [
    "score = Xception_09.evaluate(test_dataset256)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVS3i-2XGP6k"
   },
   "source": [
    "#### **\"Xception_10\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-sc3e2vJGP6k"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception  # cargamos la red Xception\n",
    "from keras.applications.xception import preprocess_input   # para importar función de prepocesamiento de imágenes necesario para la red Xception\n",
    "\n",
    "image_size = 299\n",
    "\n",
    "Xception_model_10 = Xception(include_top=False, input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "NKvQFpj-GP6l"
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LA RED NEURONAL CONVOLUCIONAL \"Xception_10\"\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Resizing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomCrop, RandomTranslation, RandomRotation, RandomZoom, Rescaling, RandomContrast\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "\n",
    "Xception_model_10.trainable = False\n",
    "\n",
    "image_size_in=299\n",
    "\n",
    "#image_size_model=128\n",
    "\n",
    "Xception_10 = Sequential()\n",
    "\n",
    "Xception_10.add(Lambda(preprocess_input, input_shape=(image_size_in, image_size_in, 3)))\n",
    "\n",
    "Xception_10.add(RandomFlip(mode=\"horizontal\"))\n",
    "#Xception_10.add(RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "Xception_10.add(RandomRotation(factor=(-0.35,0.35)))\n",
    "#Xception_10.add(RandomTranslation(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2)))\n",
    "#Xception_10.add(RandomCrop(height=64, width=64))\n",
    "Xception_10.add(RandomContrast(factor=0.35))\n",
    "\n",
    "#Xception_10.add(Resizing(image_size_model, image_size_model))\n",
    "\n",
    "#Xception_10.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3))) \n",
    "\n",
    "Xception_10.add(BatchNormalization())\n",
    "\n",
    "Xception_10.add(Xception_model_10)\n",
    "\n",
    "#Xception_10.add(BatchNormalization())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_FBVqTyFGP6l"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "#Xception_10.add(GlobalAveragePooling2D())\n",
    "#Xception_10.add(Flatten(name=\"flatten\"))\n",
    "#Xception_10.add(Dense(124, activation=\"relu\"))\n",
    "#Xception_10.add(Dropout(0.325))\n",
    "\n",
    "Xception_10.add(GlobalAveragePooling2D())\n",
    "Xception_10.add(Dropout(0.45))\n",
    "Xception_10.add(Dense(4096, activation=\"relu\"))\n",
    "Xception_10.add(Dropout(0.45))\n",
    "Xception_10.add(Dense(4096, activation=\"relu\"))\n",
    "#Xception_10.add(Dropout(0.4))\n",
    "Xception_10.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Z56VdKQtGP6l"
   },
   "outputs": [],
   "source": [
    "# COMPILAMOS Y ENTRENAMOS EL MODELO\n",
    "\n",
    "Xception_10.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCuXPSUVFKB0"
   },
   "source": [
    "#####  **Nº de épocas: 50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "MUea6Ok9GP6l",
    "outputId": "89f5a1e3-3637-435e-b591-0df8e877c25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 - 88s - loss: 0.9814 - accuracy: 0.6636 - val_loss: 0.6091 - val_accuracy: 0.7936\n",
      "Epoch 2/50\n",
      "191/191 - 83s - loss: 0.7224 - accuracy: 0.7432 - val_loss: 0.5616 - val_accuracy: 0.8060\n",
      "Epoch 3/50\n",
      "191/191 - 83s - loss: 0.6621 - accuracy: 0.7655 - val_loss: 0.4909 - val_accuracy: 0.8207\n",
      "Epoch 4/50\n",
      "191/191 - 83s - loss: 0.6248 - accuracy: 0.7739 - val_loss: 0.4811 - val_accuracy: 0.8283\n",
      "Epoch 5/50\n",
      "191/191 - 83s - loss: 0.6010 - accuracy: 0.7828 - val_loss: 0.4481 - val_accuracy: 0.8539\n",
      "Epoch 6/50\n",
      "191/191 - 83s - loss: 0.5519 - accuracy: 0.8014 - val_loss: 0.4409 - val_accuracy: 0.8449\n",
      "Epoch 7/50\n",
      "191/191 - 83s - loss: 0.5384 - accuracy: 0.8103 - val_loss: 0.4738 - val_accuracy: 0.8245\n",
      "Epoch 8/50\n",
      "191/191 - 83s - loss: 0.5449 - accuracy: 0.8057 - val_loss: 0.4176 - val_accuracy: 0.8558\n",
      "Epoch 9/50\n",
      "191/191 - 83s - loss: 0.5093 - accuracy: 0.8231 - val_loss: 0.3944 - val_accuracy: 0.8733\n",
      "Epoch 10/50\n",
      "191/191 - 83s - loss: 0.4816 - accuracy: 0.8325 - val_loss: 0.4452 - val_accuracy: 0.8406\n",
      "Epoch 11/50\n",
      "191/191 - 83s - loss: 0.4896 - accuracy: 0.8295 - val_loss: 0.3904 - val_accuracy: 0.8657\n",
      "Epoch 12/50\n",
      "191/191 - 83s - loss: 0.4711 - accuracy: 0.8354 - val_loss: 0.4130 - val_accuracy: 0.8591\n",
      "Epoch 13/50\n",
      "191/191 - 83s - loss: 0.4544 - accuracy: 0.8387 - val_loss: 0.4017 - val_accuracy: 0.8629\n",
      "Epoch 14/50\n",
      "191/191 - 83s - loss: 0.4577 - accuracy: 0.8362 - val_loss: 0.4438 - val_accuracy: 0.8482\n",
      "Epoch 15/50\n",
      "191/191 - 83s - loss: 0.4352 - accuracy: 0.8489 - val_loss: 0.4113 - val_accuracy: 0.8629\n",
      "Epoch 16/50\n",
      "191/191 - 83s - loss: 0.4407 - accuracy: 0.8450 - val_loss: 0.4349 - val_accuracy: 0.8510\n",
      "Epoch 17/50\n",
      "191/191 - 83s - loss: 0.4268 - accuracy: 0.8459 - val_loss: 0.4104 - val_accuracy: 0.8610\n",
      "Epoch 18/50\n",
      "191/191 - 83s - loss: 0.4178 - accuracy: 0.8491 - val_loss: 0.3721 - val_accuracy: 0.8757\n",
      "Epoch 19/50\n",
      "191/191 - 83s - loss: 0.4170 - accuracy: 0.8530 - val_loss: 0.3846 - val_accuracy: 0.8700\n",
      "Epoch 20/50\n",
      "191/191 - 83s - loss: 0.4189 - accuracy: 0.8520 - val_loss: 0.3568 - val_accuracy: 0.8824\n",
      "Epoch 21/50\n",
      "191/191 - 83s - loss: 0.3908 - accuracy: 0.8581 - val_loss: 0.3588 - val_accuracy: 0.8890\n",
      "Epoch 22/50\n",
      "191/191 - 83s - loss: 0.3838 - accuracy: 0.8632 - val_loss: 0.3704 - val_accuracy: 0.8743\n",
      "Epoch 23/50\n",
      "191/191 - 83s - loss: 0.3774 - accuracy: 0.8721 - val_loss: 0.4059 - val_accuracy: 0.8733\n",
      "Epoch 24/50\n",
      "191/191 - 83s - loss: 0.3821 - accuracy: 0.8604 - val_loss: 0.4082 - val_accuracy: 0.8634\n",
      "Epoch 25/50\n",
      "191/191 - 83s - loss: 0.3768 - accuracy: 0.8653 - val_loss: 0.3639 - val_accuracy: 0.8824\n",
      "Epoch 26/50\n",
      "191/191 - 83s - loss: 0.3613 - accuracy: 0.8714 - val_loss: 0.3684 - val_accuracy: 0.8786\n",
      "Epoch 27/50\n",
      "191/191 - 83s - loss: 0.3672 - accuracy: 0.8693 - val_loss: 0.3894 - val_accuracy: 0.8719\n",
      "Epoch 28/50\n",
      "191/191 - 83s - loss: 0.3881 - accuracy: 0.8642 - val_loss: 0.4153 - val_accuracy: 0.8648\n",
      "Epoch 29/50\n",
      "191/191 - 83s - loss: 0.3747 - accuracy: 0.8693 - val_loss: 0.3957 - val_accuracy: 0.8672\n",
      "Epoch 30/50\n",
      "191/191 - 83s - loss: 0.3781 - accuracy: 0.8657 - val_loss: 0.3993 - val_accuracy: 0.8700\n",
      "Epoch 31/50\n",
      "191/191 - 83s - loss: 0.3557 - accuracy: 0.8741 - val_loss: 0.3954 - val_accuracy: 0.8724\n",
      "Epoch 32/50\n",
      "191/191 - 83s - loss: 0.3620 - accuracy: 0.8773 - val_loss: 0.3646 - val_accuracy: 0.8833\n",
      "Epoch 33/50\n",
      "191/191 - 83s - loss: 0.3477 - accuracy: 0.8741 - val_loss: 0.3459 - val_accuracy: 0.8824\n",
      "Epoch 34/50\n",
      "191/191 - 83s - loss: 0.3534 - accuracy: 0.8750 - val_loss: 0.3660 - val_accuracy: 0.8743\n",
      "Epoch 35/50\n",
      "191/191 - 83s - loss: 0.3371 - accuracy: 0.8831 - val_loss: 0.3826 - val_accuracy: 0.8743\n",
      "Epoch 36/50\n",
      "191/191 - 83s - loss: 0.3541 - accuracy: 0.8755 - val_loss: 0.3592 - val_accuracy: 0.8828\n",
      "Epoch 37/50\n",
      "191/191 - 83s - loss: 0.3281 - accuracy: 0.8829 - val_loss: 0.3679 - val_accuracy: 0.8795\n",
      "Epoch 38/50\n",
      "191/191 - 83s - loss: 0.3195 - accuracy: 0.8867 - val_loss: 0.3912 - val_accuracy: 0.8724\n",
      "Epoch 39/50\n",
      "191/191 - 83s - loss: 0.3354 - accuracy: 0.8839 - val_loss: 0.3681 - val_accuracy: 0.8781\n",
      "Epoch 40/50\n",
      "191/191 - 83s - loss: 0.3310 - accuracy: 0.8879 - val_loss: 0.3567 - val_accuracy: 0.8814\n",
      "Epoch 41/50\n",
      "191/191 - 83s - loss: 0.3331 - accuracy: 0.8828 - val_loss: 0.3665 - val_accuracy: 0.8819\n",
      "Epoch 42/50\n",
      "191/191 - 83s - loss: 0.3278 - accuracy: 0.8842 - val_loss: 0.3595 - val_accuracy: 0.8843\n",
      "Epoch 43/50\n",
      "191/191 - 83s - loss: 0.3384 - accuracy: 0.8768 - val_loss: 0.3368 - val_accuracy: 0.8952\n",
      "Epoch 44/50\n",
      "191/191 - 83s - loss: 0.3136 - accuracy: 0.8884 - val_loss: 0.3540 - val_accuracy: 0.8805\n",
      "Epoch 45/50\n",
      "191/191 - 83s - loss: 0.3265 - accuracy: 0.8805 - val_loss: 0.3519 - val_accuracy: 0.8819\n",
      "Epoch 46/50\n",
      "191/191 - 83s - loss: 0.3030 - accuracy: 0.8946 - val_loss: 0.3626 - val_accuracy: 0.8885\n",
      "Epoch 47/50\n",
      "191/191 - 83s - loss: 0.3006 - accuracy: 0.8913 - val_loss: 0.3516 - val_accuracy: 0.8909\n",
      "Epoch 48/50\n",
      "191/191 - 83s - loss: 0.2979 - accuracy: 0.8944 - val_loss: 0.3624 - val_accuracy: 0.8795\n",
      "Epoch 49/50\n",
      "191/191 - 83s - loss: 0.3218 - accuracy: 0.8903 - val_loss: 0.3547 - val_accuracy: 0.8838\n",
      "Epoch 50/50\n",
      "191/191 - 83s - loss: 0.3094 - accuracy: 0.8920 - val_loss: 0.3429 - val_accuracy: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0bb003aa10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_10.fit(\n",
    "    train_dataset299, # Training data\n",
    "    validation_data=val_dataset299,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=50, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0j1CCCr5GP6m"
   },
   "outputs": [],
   "source": [
    "probs = Xception_10.predict(test_dataset299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "vS-YDEJqGP6m",
    "outputId": "f9670c77-4919-4948-9e82-95fc61d98259"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.18627206e-07, 1.20628911e-07, 8.67798924e-04, 3.36065204e-06,\n",
       "        4.65487719e-05, 9.99081969e-01],\n",
       "       [8.85337770e-01, 2.03542513e-04, 1.68135238e-03, 1.10408992e-01,\n",
       "        1.50760100e-03, 8.60724656e-04],\n",
       "       [1.03369064e-04, 9.98573542e-01, 1.27541542e-03, 5.43339411e-06,\n",
       "        4.13511079e-05, 8.85504051e-07],\n",
       "       ...,\n",
       "       [7.13247017e-09, 9.99988198e-01, 1.17397976e-05, 4.75969628e-08,\n",
       "        5.53768587e-10, 2.79845203e-10],\n",
       "       [6.40492067e-02, 5.96018566e-04, 2.68951785e-02, 8.13652694e-01,\n",
       "        2.13847235e-02, 7.34222680e-02],\n",
       "       [3.35683092e-03, 5.08859375e-05, 5.62456204e-03, 1.47494718e-01,\n",
       "        9.36805853e-04, 8.42536211e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "DckARcg2GP6m",
    "outputId": "2c417d5e-802a-4ed3-8d62-b1392ea90936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 10s 146ms/step - loss: 0.3054 - accuracy: 0.8961\n",
      "Test loss 0.30535322427749634\n",
      "Test accuracy 0.8961352705955505\n"
     ]
    }
   ],
   "source": [
    "score = Xception_10.evaluate(test_dataset299)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kve2ikWcFUAB"
   },
   "source": [
    "##### **Nº de épocas: 50 + 50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "7p57vgelFUAC",
    "outputId": "9ba9aa89-5114-4864-812e-66d5dc93d26f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 - 83s - loss: 0.3075 - accuracy: 0.8944 - val_loss: 0.3478 - val_accuracy: 0.8971\n",
      "Epoch 2/50\n",
      "191/191 - 83s - loss: 0.2845 - accuracy: 0.8995 - val_loss: 0.3650 - val_accuracy: 0.8819\n",
      "Epoch 3/50\n",
      "191/191 - 83s - loss: 0.3062 - accuracy: 0.8941 - val_loss: 0.3647 - val_accuracy: 0.8805\n",
      "Epoch 4/50\n",
      "191/191 - 83s - loss: 0.3036 - accuracy: 0.8897 - val_loss: 0.3400 - val_accuracy: 0.8885\n",
      "Epoch 5/50\n",
      "191/191 - 83s - loss: 0.3031 - accuracy: 0.8905 - val_loss: 0.3449 - val_accuracy: 0.8876\n",
      "Epoch 6/50\n",
      "191/191 - 83s - loss: 0.3046 - accuracy: 0.8944 - val_loss: 0.3529 - val_accuracy: 0.8824\n",
      "Epoch 7/50\n",
      "191/191 - 83s - loss: 0.2925 - accuracy: 0.8989 - val_loss: 0.3346 - val_accuracy: 0.8923\n",
      "Epoch 8/50\n",
      "191/191 - 83s - loss: 0.2796 - accuracy: 0.9045 - val_loss: 0.3604 - val_accuracy: 0.8914\n",
      "Epoch 9/50\n",
      "191/191 - 83s - loss: 0.2990 - accuracy: 0.8979 - val_loss: 0.3444 - val_accuracy: 0.8899\n",
      "Epoch 10/50\n",
      "191/191 - 83s - loss: 0.2883 - accuracy: 0.8995 - val_loss: 0.3468 - val_accuracy: 0.8923\n",
      "Epoch 11/50\n",
      "191/191 - 83s - loss: 0.2794 - accuracy: 0.8954 - val_loss: 0.3618 - val_accuracy: 0.8828\n",
      "Epoch 12/50\n",
      "191/191 - 83s - loss: 0.2969 - accuracy: 0.9028 - val_loss: 0.3653 - val_accuracy: 0.8771\n",
      "Epoch 13/50\n",
      "191/191 - 83s - loss: 0.2757 - accuracy: 0.8992 - val_loss: 0.3592 - val_accuracy: 0.8885\n",
      "Epoch 14/50\n",
      "191/191 - 83s - loss: 0.2720 - accuracy: 0.9041 - val_loss: 0.3526 - val_accuracy: 0.8909\n",
      "Epoch 15/50\n",
      "191/191 - 83s - loss: 0.2685 - accuracy: 0.9050 - val_loss: 0.3485 - val_accuracy: 0.8880\n",
      "Epoch 16/50\n",
      "191/191 - 83s - loss: 0.2787 - accuracy: 0.8995 - val_loss: 0.3477 - val_accuracy: 0.8937\n",
      "Epoch 17/50\n",
      "191/191 - 83s - loss: 0.2916 - accuracy: 0.8994 - val_loss: 0.3894 - val_accuracy: 0.8762\n",
      "Epoch 18/50\n",
      "191/191 - 83s - loss: 0.2790 - accuracy: 0.9009 - val_loss: 0.3438 - val_accuracy: 0.8985\n",
      "Epoch 19/50\n",
      "191/191 - 83s - loss: 0.2638 - accuracy: 0.9053 - val_loss: 0.3494 - val_accuracy: 0.8956\n",
      "Epoch 20/50\n",
      "191/191 - 83s - loss: 0.2755 - accuracy: 0.9058 - val_loss: 0.3488 - val_accuracy: 0.8866\n",
      "Epoch 21/50\n",
      "191/191 - 83s - loss: 0.2779 - accuracy: 0.9035 - val_loss: 0.3596 - val_accuracy: 0.8909\n",
      "Epoch 22/50\n",
      "191/191 - 83s - loss: 0.2484 - accuracy: 0.9124 - val_loss: 0.3342 - val_accuracy: 0.8994\n",
      "Epoch 23/50\n",
      "191/191 - 83s - loss: 0.2673 - accuracy: 0.9079 - val_loss: 0.3728 - val_accuracy: 0.8838\n",
      "Epoch 24/50\n",
      "191/191 - 83s - loss: 0.2647 - accuracy: 0.9079 - val_loss: 0.3565 - val_accuracy: 0.8890\n",
      "Epoch 25/50\n",
      "191/191 - 83s - loss: 0.2738 - accuracy: 0.9073 - val_loss: 0.3674 - val_accuracy: 0.8857\n",
      "Epoch 26/50\n",
      "191/191 - 83s - loss: 0.2691 - accuracy: 0.9069 - val_loss: 0.3659 - val_accuracy: 0.8890\n",
      "Epoch 27/50\n",
      "191/191 - 83s - loss: 0.2643 - accuracy: 0.9079 - val_loss: 0.3408 - val_accuracy: 0.8966\n",
      "Epoch 28/50\n",
      "191/191 - 83s - loss: 0.2416 - accuracy: 0.9193 - val_loss: 0.3567 - val_accuracy: 0.8904\n",
      "Epoch 29/50\n",
      "191/191 - 83s - loss: 0.2586 - accuracy: 0.9081 - val_loss: 0.3605 - val_accuracy: 0.8857\n",
      "Epoch 30/50\n",
      "191/191 - 83s - loss: 0.2616 - accuracy: 0.9073 - val_loss: 0.3804 - val_accuracy: 0.8800\n",
      "Epoch 31/50\n",
      "191/191 - 83s - loss: 0.2584 - accuracy: 0.9115 - val_loss: 0.3457 - val_accuracy: 0.8923\n",
      "Epoch 32/50\n",
      "191/191 - 83s - loss: 0.2557 - accuracy: 0.9114 - val_loss: 0.3783 - val_accuracy: 0.8824\n",
      "Epoch 33/50\n",
      "191/191 - 83s - loss: 0.2544 - accuracy: 0.9081 - val_loss: 0.3546 - val_accuracy: 0.8928\n",
      "Epoch 34/50\n",
      "191/191 - 83s - loss: 0.2510 - accuracy: 0.9124 - val_loss: 0.3661 - val_accuracy: 0.8899\n",
      "Epoch 35/50\n",
      "191/191 - 83s - loss: 0.2569 - accuracy: 0.9102 - val_loss: 0.3603 - val_accuracy: 0.8895\n",
      "Epoch 36/50\n",
      "191/191 - 83s - loss: 0.2531 - accuracy: 0.9120 - val_loss: 0.3440 - val_accuracy: 0.8971\n",
      "Epoch 37/50\n",
      "191/191 - 83s - loss: 0.2440 - accuracy: 0.9152 - val_loss: 0.3764 - val_accuracy: 0.8890\n",
      "Epoch 38/50\n",
      "191/191 - 83s - loss: 0.2504 - accuracy: 0.9165 - val_loss: 0.3663 - val_accuracy: 0.8847\n",
      "Epoch 39/50\n",
      "191/191 - 83s - loss: 0.2345 - accuracy: 0.9155 - val_loss: 0.3627 - val_accuracy: 0.8961\n",
      "Epoch 40/50\n",
      "191/191 - 83s - loss: 0.2461 - accuracy: 0.9148 - val_loss: 0.3694 - val_accuracy: 0.8800\n",
      "Epoch 41/50\n",
      "191/191 - 83s - loss: 0.2472 - accuracy: 0.9176 - val_loss: 0.3639 - val_accuracy: 0.8918\n",
      "Epoch 42/50\n",
      "191/191 - 83s - loss: 0.2417 - accuracy: 0.9175 - val_loss: 0.3613 - val_accuracy: 0.8876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b31040150>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_10.fit(\n",
    "    train_dataset299, # Training data\n",
    "    validation_data=val_dataset299,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=50, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "YqjBpRyZFUAC"
   },
   "outputs": [],
   "source": [
    "probs = Xception_10.predict(test_dataset299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "qOsizRivFUAC",
    "outputId": "c9121df8-fc03-4bc8-8969-a46fa8c35d8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.74953000e-05, 6.96649181e-07, 1.49692729e-04, 9.98509467e-01,\n",
       "        1.23137410e-03, 1.12065763e-05],\n",
       "       [8.33027928e-13, 5.83586431e-16, 6.92941147e-13, 2.34400628e-12,\n",
       "        1.00000000e+00, 9.70207248e-10],\n",
       "       [3.04816453e-16, 3.80840365e-18, 2.88884819e-11, 2.02111048e-16,\n",
       "        1.21254320e-12, 1.00000000e+00],\n",
       "       ...,\n",
       "       [5.12775150e-04, 3.09812069e-01, 2.29609553e-02, 1.02298521e-03,\n",
       "        8.92471639e-04, 6.64798796e-01],\n",
       "       [3.90470050e-05, 6.34582602e-06, 3.55994445e-03, 2.43122177e-03,\n",
       "        1.48798063e-04, 9.93814707e-01],\n",
       "       [1.57969898e-05, 1.30352285e-02, 9.86312568e-01, 5.20277070e-04,\n",
       "        4.84380234e-06, 1.11280766e-04]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "3v4zXHc1FUAC",
    "outputId": "81a01303-4f08-49cd-9885-b878a2265dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 10s 145ms/step - loss: 0.3089 - accuracy: 0.9024\n",
      "Test loss 0.3089087903499603\n",
      "Test accuracy 0.9024154543876648\n"
     ]
    }
   ],
   "source": [
    "score = Xception_10.evaluate(test_dataset299)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFmrXJ96FUm2"
   },
   "source": [
    "##### **Nº de épocas: 50 + 50 + 50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6AwxZwrDFUm3",
    "outputId": "0723d583-d2f3-49f4-8bd7-056fe9cf51f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 - 83s - loss: 0.2672 - accuracy: 0.9079 - val_loss: 0.3388 - val_accuracy: 0.8952\n",
      "Epoch 2/50\n",
      "191/191 - 83s - loss: 0.2752 - accuracy: 0.9015 - val_loss: 0.3816 - val_accuracy: 0.8857\n",
      "Epoch 3/50\n",
      "191/191 - 83s - loss: 0.2694 - accuracy: 0.9092 - val_loss: 0.3961 - val_accuracy: 0.8786\n",
      "Epoch 4/50\n",
      "191/191 - 83s - loss: 0.2626 - accuracy: 0.9064 - val_loss: 0.3652 - val_accuracy: 0.8786\n",
      "Epoch 5/50\n",
      "191/191 - 83s - loss: 0.2509 - accuracy: 0.9097 - val_loss: 0.3819 - val_accuracy: 0.8748\n",
      "Epoch 6/50\n",
      "191/191 - 83s - loss: 0.2675 - accuracy: 0.9094 - val_loss: 0.3650 - val_accuracy: 0.8866\n",
      "Epoch 7/50\n",
      "191/191 - 83s - loss: 0.2525 - accuracy: 0.9073 - val_loss: 0.3542 - val_accuracy: 0.8928\n",
      "Epoch 8/50\n",
      "191/191 - 83s - loss: 0.2598 - accuracy: 0.9132 - val_loss: 0.3942 - val_accuracy: 0.8805\n",
      "Epoch 9/50\n",
      "191/191 - 83s - loss: 0.2562 - accuracy: 0.9122 - val_loss: 0.3706 - val_accuracy: 0.8895\n",
      "Epoch 10/50\n",
      "191/191 - 83s - loss: 0.2566 - accuracy: 0.9137 - val_loss: 0.3770 - val_accuracy: 0.8852\n",
      "Epoch 11/50\n",
      "191/191 - 83s - loss: 0.2599 - accuracy: 0.9129 - val_loss: 0.3956 - val_accuracy: 0.8714\n",
      "Epoch 12/50\n",
      "191/191 - 83s - loss: 0.2453 - accuracy: 0.9140 - val_loss: 0.3853 - val_accuracy: 0.8843\n",
      "Epoch 13/50\n",
      "191/191 - 83s - loss: 0.2427 - accuracy: 0.9127 - val_loss: 0.3534 - val_accuracy: 0.8942\n",
      "Epoch 14/50\n",
      "191/191 - 83s - loss: 0.2462 - accuracy: 0.9124 - val_loss: 0.3506 - val_accuracy: 0.8918\n",
      "Epoch 15/50\n",
      "191/191 - 83s - loss: 0.2455 - accuracy: 0.9155 - val_loss: 0.3757 - val_accuracy: 0.8800\n",
      "Epoch 16/50\n",
      "191/191 - 83s - loss: 0.2586 - accuracy: 0.9110 - val_loss: 0.3890 - val_accuracy: 0.8890\n",
      "Epoch 17/50\n",
      "191/191 - 83s - loss: 0.2344 - accuracy: 0.9124 - val_loss: 0.3925 - val_accuracy: 0.8928\n",
      "Epoch 18/50\n",
      "191/191 - 83s - loss: 0.2547 - accuracy: 0.9102 - val_loss: 0.4057 - val_accuracy: 0.8790\n",
      "Epoch 19/50\n",
      "191/191 - 83s - loss: 0.2494 - accuracy: 0.9134 - val_loss: 0.3787 - val_accuracy: 0.8843\n",
      "Epoch 20/50\n",
      "191/191 - 83s - loss: 0.2511 - accuracy: 0.9129 - val_loss: 0.3594 - val_accuracy: 0.8914\n",
      "Epoch 21/50\n",
      "191/191 - 83s - loss: 0.2518 - accuracy: 0.9099 - val_loss: 0.3900 - val_accuracy: 0.8824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b319a9990>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_10.fit(\n",
    "    train_dataset299, # Training data\n",
    "    validation_data=val_dataset299,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=50, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "TkpirYuTFUm3"
   },
   "outputs": [],
   "source": [
    "probs = Xception_10.predict(test_dataset299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "xpT7zSu8FUm3",
    "outputId": "fc47b975-9982-47bc-e718-7a4ba8fcd2fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9929142e-01, 6.8384054e-08, 8.3365139e-06, 6.8162096e-04,\n",
       "        1.3849587e-05, 4.6370978e-06],\n",
       "       [1.1549933e-02, 5.8126204e-07, 3.3914373e-04, 3.1851768e-04,\n",
       "        3.6775210e-04, 9.8742408e-01],\n",
       "       [3.5137851e-02, 2.6176520e-02, 4.8096859e-01, 4.7047056e-02,\n",
       "        3.2363400e-02, 3.7830663e-01],\n",
       "       ...,\n",
       "       [9.0010273e-01, 3.6528561e-06, 1.0921769e-04, 9.8520711e-02,\n",
       "        8.6261437e-04, 4.0102482e-04],\n",
       "       [2.8510609e-05, 2.5033564e-06, 9.9994135e-01, 2.0801377e-05,\n",
       "        5.4946699e-06, 1.3392091e-06],\n",
       "       [2.3601269e-03, 4.7729854e-03, 2.6802598e-02, 3.9099134e-03,\n",
       "        9.6150720e-01, 6.4710109e-04]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "K2G4TnuAFUm3",
    "outputId": "bdf907d1-6e7f-40ac-98f7-14d69ae83fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 10s 148ms/step - loss: 0.2983 - accuracy: 0.9063\n",
      "Test loss 0.298338383436203\n",
      "Test accuracy 0.9062802195549011\n"
     ]
    }
   ],
   "source": [
    "score = Xception_10.evaluate(test_dataset299)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9UJgzmnFyLG"
   },
   "source": [
    "##### **Nº de épocas: 50 + 50 + 50 + 50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Hy4CVJLbFyLG",
    "outputId": "43d98fe4-46b8-41e3-82b3-38ac7dff6b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "191/191 - 83s - loss: 0.2581 - accuracy: 0.9087 - val_loss: 0.3566 - val_accuracy: 0.8899\n",
      "Epoch 2/50\n",
      "191/191 - 83s - loss: 0.2663 - accuracy: 0.9066 - val_loss: 0.3473 - val_accuracy: 0.8914\n",
      "Epoch 3/50\n",
      "191/191 - 83s - loss: 0.2708 - accuracy: 0.9061 - val_loss: 0.3807 - val_accuracy: 0.8833\n",
      "Epoch 4/50\n",
      "191/191 - 83s - loss: 0.2854 - accuracy: 0.9032 - val_loss: 0.3901 - val_accuracy: 0.8838\n",
      "Epoch 5/50\n",
      "191/191 - 83s - loss: 0.2668 - accuracy: 0.9066 - val_loss: 0.3909 - val_accuracy: 0.8843\n",
      "Epoch 6/50\n",
      "191/191 - 83s - loss: 0.2703 - accuracy: 0.9084 - val_loss: 0.3390 - val_accuracy: 0.8904\n",
      "Epoch 7/50\n",
      "191/191 - 83s - loss: 0.2533 - accuracy: 0.9114 - val_loss: 0.3814 - val_accuracy: 0.8857\n",
      "Epoch 8/50\n",
      "191/191 - 83s - loss: 0.2653 - accuracy: 0.9081 - val_loss: 0.3597 - val_accuracy: 0.8871\n",
      "Epoch 9/50\n",
      "191/191 - 83s - loss: 0.2586 - accuracy: 0.9112 - val_loss: 0.3458 - val_accuracy: 0.8928\n",
      "Epoch 10/50\n",
      "191/191 - 83s - loss: 0.2426 - accuracy: 0.9150 - val_loss: 0.3502 - val_accuracy: 0.8966\n",
      "Epoch 11/50\n",
      "191/191 - 83s - loss: 0.2608 - accuracy: 0.9112 - val_loss: 0.3497 - val_accuracy: 0.8876\n",
      "Epoch 12/50\n",
      "191/191 - 83s - loss: 0.2550 - accuracy: 0.9099 - val_loss: 0.3511 - val_accuracy: 0.8942\n",
      "Epoch 13/50\n",
      "191/191 - 83s - loss: 0.2547 - accuracy: 0.9084 - val_loss: 0.3645 - val_accuracy: 0.8843\n",
      "Epoch 14/50\n",
      "191/191 - 83s - loss: 0.2419 - accuracy: 0.9191 - val_loss: 0.3434 - val_accuracy: 0.8980\n",
      "Epoch 15/50\n",
      "191/191 - 83s - loss: 0.2346 - accuracy: 0.9224 - val_loss: 0.3629 - val_accuracy: 0.8838\n",
      "Epoch 16/50\n",
      "191/191 - 83s - loss: 0.2730 - accuracy: 0.9078 - val_loss: 0.3621 - val_accuracy: 0.8824\n",
      "Epoch 17/50\n",
      "191/191 - 83s - loss: 0.2695 - accuracy: 0.9110 - val_loss: 0.3645 - val_accuracy: 0.8828\n",
      "Epoch 18/50\n",
      "191/191 - 83s - loss: 0.2401 - accuracy: 0.9180 - val_loss: 0.3551 - val_accuracy: 0.8928\n",
      "Epoch 19/50\n",
      "191/191 - 83s - loss: 0.2627 - accuracy: 0.9114 - val_loss: 0.3510 - val_accuracy: 0.8899\n",
      "Epoch 20/50\n",
      "191/191 - 83s - loss: 0.2487 - accuracy: 0.9155 - val_loss: 0.3747 - val_accuracy: 0.8914\n",
      "Epoch 21/50\n",
      "191/191 - 83s - loss: 0.2442 - accuracy: 0.9134 - val_loss: 0.3827 - val_accuracy: 0.8838\n",
      "Epoch 22/50\n",
      "191/191 - 83s - loss: 0.2489 - accuracy: 0.9124 - val_loss: 0.3532 - val_accuracy: 0.8961\n",
      "Epoch 23/50\n",
      "191/191 - 83s - loss: 0.2318 - accuracy: 0.9229 - val_loss: 0.3386 - val_accuracy: 0.8975\n",
      "Epoch 24/50\n",
      "191/191 - 83s - loss: 0.2288 - accuracy: 0.9180 - val_loss: 0.3976 - val_accuracy: 0.8866\n",
      "Epoch 25/50\n",
      "191/191 - 83s - loss: 0.2316 - accuracy: 0.9196 - val_loss: 0.3610 - val_accuracy: 0.8961\n",
      "Epoch 26/50\n",
      "191/191 - 83s - loss: 0.2372 - accuracy: 0.9165 - val_loss: 0.3912 - val_accuracy: 0.8819\n",
      "Epoch 27/50\n",
      "191/191 - 83s - loss: 0.2388 - accuracy: 0.9160 - val_loss: 0.3764 - val_accuracy: 0.8861\n",
      "Epoch 28/50\n",
      "191/191 - 83s - loss: 0.2294 - accuracy: 0.9232 - val_loss: 0.3559 - val_accuracy: 0.8866\n",
      "Epoch 29/50\n",
      "191/191 - 83s - loss: 0.2315 - accuracy: 0.9170 - val_loss: 0.3688 - val_accuracy: 0.8795\n",
      "Epoch 30/50\n",
      "191/191 - 83s - loss: 0.2488 - accuracy: 0.9170 - val_loss: 0.3960 - val_accuracy: 0.8786\n",
      "Epoch 31/50\n",
      "191/191 - 83s - loss: 0.2444 - accuracy: 0.9173 - val_loss: 0.3856 - val_accuracy: 0.8805\n",
      "Epoch 32/50\n",
      "191/191 - 83s - loss: 0.2345 - accuracy: 0.9157 - val_loss: 0.3861 - val_accuracy: 0.8833\n",
      "Epoch 33/50\n",
      "191/191 - 83s - loss: 0.2249 - accuracy: 0.9217 - val_loss: 0.3523 - val_accuracy: 0.8937\n",
      "Epoch 34/50\n",
      "191/191 - 83s - loss: 0.2264 - accuracy: 0.9207 - val_loss: 0.3931 - val_accuracy: 0.8824\n",
      "Epoch 35/50\n",
      "191/191 - 83s - loss: 0.2483 - accuracy: 0.9148 - val_loss: 0.3802 - val_accuracy: 0.8847\n",
      "Epoch 36/50\n",
      "191/191 - 83s - loss: 0.2422 - accuracy: 0.9142 - val_loss: 0.4047 - val_accuracy: 0.8752\n",
      "Epoch 37/50\n",
      "191/191 - 83s - loss: 0.2286 - accuracy: 0.9193 - val_loss: 0.3821 - val_accuracy: 0.8866\n",
      "Epoch 38/50\n",
      "191/191 - 83s - loss: 0.2390 - accuracy: 0.9181 - val_loss: 0.3708 - val_accuracy: 0.8819\n",
      "Epoch 39/50\n",
      "191/191 - 83s - loss: 0.2258 - accuracy: 0.9224 - val_loss: 0.3655 - val_accuracy: 0.8866\n",
      "Epoch 40/50\n",
      "191/191 - 83s - loss: 0.2277 - accuracy: 0.9186 - val_loss: 0.3761 - val_accuracy: 0.8876\n",
      "Epoch 41/50\n",
      "191/191 - 83s - loss: 0.2382 - accuracy: 0.9168 - val_loss: 0.3733 - val_accuracy: 0.8861\n",
      "Epoch 42/50\n",
      "191/191 - 83s - loss: 0.2177 - accuracy: 0.9240 - val_loss: 0.3617 - val_accuracy: 0.8918\n",
      "Epoch 43/50\n",
      "191/191 - 83s - loss: 0.2118 - accuracy: 0.9281 - val_loss: 0.3717 - val_accuracy: 0.8876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b103f3310>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "Xception_10.fit(\n",
    "    train_dataset299, # Training data\n",
    "    validation_data=val_dataset299,\n",
    "    batch_size=32, # Batch size for the optimizer algorithm\n",
    "    epochs=50, # Number of epochs to run the optimizer algorithm\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=20, restore_best_weights=True)               \n",
    "    ],\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "z7FM4jVRFyLH"
   },
   "outputs": [],
   "source": [
    "probs = Xception_10.predict(test_dataset299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "BAosKuVTFyLH",
    "outputId": "2e6cb84c-970e-4cfe-f5fb-2466fee0918b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9607421e-02, 5.1900349e-04, 9.9962968e-03, 9.6207148e-01,\n",
       "        4.6953617e-04, 7.3362472e-03],\n",
       "       [1.7687078e-05, 1.8729182e-06, 9.5011288e-04, 2.9217533e-04,\n",
       "        9.4929838e-01, 4.9439888e-02],\n",
       "       [7.5429962e-03, 7.4959683e-01, 2.3058675e-01, 8.6206188e-03,\n",
       "        2.4295936e-03, 1.2232118e-03],\n",
       "       ...,\n",
       "       [4.1726927e-31, 2.6253481e-38, 4.6247807e-38, 8.5097145e-38,\n",
       "        1.0000000e+00, 6.4483641e-38],\n",
       "       [2.1838639e-07, 1.6965743e-04, 9.9981123e-01, 2.8602522e-06,\n",
       "        1.2464875e-07, 1.5965108e-05],\n",
       "       [2.8991927e-03, 1.4049674e-02, 8.8600737e-01, 9.5658094e-02,\n",
       "        9.2295336e-04, 4.6271365e-04]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "CFBZPMfGFyLH",
    "outputId": "e09b6f88-df27-4ee0-9413-98ce5cb79c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 10s 145ms/step - loss: 0.2955 - accuracy: 0.9092\n",
      "Test loss 0.2955189049243927\n",
      "Test accuracy 0.9091787338256836\n"
     ]
    }
   ],
   "source": [
    "score = Xception_10.evaluate(test_dataset299)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTlVNl7gcGPN"
   },
   "source": [
    "#### **Conclusiones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hR7vgYjcGPO"
   },
   "source": [
    "Dado que el modelo **\"Xception_10\" entrenado con 100 épocas (50 + 50)** alcanza el rendimiento buscado se toma como válido.\n",
    "\n",
    "Se ha continuado entrenando el modelo en bloques de 50 épocas para comprobar si se conseguía mejorar el rendimiento. Éste aumenta, pero la mejora podría considerarse poco significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVJc7DMJhRKK"
   },
   "source": [
    "## Summary of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EofHCraehRKL"
   },
   "source": [
    "Example results table\n",
    "\n",
    "|Image processing|Neural network model|Training strategy|Test accuracy|\n",
    "|----------------|--------------------|-----------------|-------------|\n",
    "|Size 32x32, batch size 16|Convolutional(32) + Flatten + Dense(64)|Train from scratch|xx%|\n",
    "|Size 64x64, batch size 32|VGG16 + Flatten + Dense(32)|Bottleneck features|yy%|\n",
    "|...|...|...|...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMbmem1Gq2nJ"
   },
   "source": [
    "A continuación, se muestran las arquitecturas de las redes definidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRxe7YYCYuQ5"
   },
   "source": [
    "### **\"LeNet\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGnXI-noZLIr"
   },
   "source": [
    "##### **\"LeNet_01\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gY8K8D-4XLyp",
    "outputId": "e53d7e7c-a1d5-4fbc-9fa2-cbb4647f1ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 611,398\n",
      "Trainable params: 611,206\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeNet_01.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrXSuv1NZQFr"
   },
   "source": [
    "##### **\"LeNet_02\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o51RQrfLZQcq",
    "outputId": "459c6a52-b8a4-431b-ea79-58fb8e62af7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip_21 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_zoom_7 (RandomZoom)   (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_21 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_translation_7 (Random (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_8 (Rescaling)      (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 126, 126, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 126, 126, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,443,142\n",
      "Trainable params: 1,442,374\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeNet_02.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXQR8J2BZQxf"
   },
   "source": [
    "##### **\"LeNet_03\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVsmMICZZRAh",
    "outputId": "37003b53-1915-4871-98c8-dcc76a4b942a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip_22 (RandomFlip)  (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_zoom_8 (RandomZoom)   (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_22 (RandomRo (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_translation_8 (Random (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_crop_5 (RandomCrop)   (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_9 (Rescaling)      (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 126, 126, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 126, 126, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 1,085,766\n",
      "Trainable params: 1,084,486\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeNet_03.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG1ZCW0iZRWj"
   },
   "source": [
    "##### **\"LeNet_04\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6IjDLQxZRqY",
    "outputId": "77d78a90-ed87-40c1-f4e4-8bbb3991d550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip_28 (RandomFlip)  (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_zoom_13 (RandomZoom)  (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_28 (RandomRo (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_translation_13 (Rando (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_crop_10 (RandomCrop)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_14 (Rescaling)     (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 125, 125, 120)     5880      \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 125, 125, 120)     480       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 62, 62, 120)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 59, 59, 256)       491776    \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 59, 59, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 26, 26, 360)       1474920   \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 26, 26, 360)       1440      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 13, 13, 360)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 10, 10, 360)       2073960   \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 10, 10, 360)       1440      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 5, 5, 360)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 2, 2, 360)         2073960   \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 2, 2, 360)         1440      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 1, 1, 360)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 512)               184832    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 6,444,022\n",
      "Trainable params: 6,441,110\n",
      "Non-trainable params: 2,912\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeNet_04.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d8Qny30ZVVx"
   },
   "source": [
    "##### **\"LeNet_05\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUrRp3g4ZVVz",
    "outputId": "4b188132-5bde-404b-e507-0938bf3a3711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip_24 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_zoom_10 (RandomZoom)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_24 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_translation_10 (Rando (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_crop_7 (RandomCrop)   (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_11 (Rescaling)     (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 125, 125, 128)     6272      \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 125, 125, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 59, 59, 256)       524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 59, 59, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 26, 26, 360)       1474920   \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 26, 26, 360)       1440      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 13, 13, 360)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 10, 10, 360)       2073960   \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 10, 10, 360)       1440      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 5, 5, 360)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 4096)              36868096  \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 57,758,102\n",
      "Trainable params: 57,755,894\n",
      "Non-trainable params: 2,208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeNet_05.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VExKtwSmZVeV"
   },
   "source": [
    "##### **\"LeNet_06\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMxHEsYVZVeW",
    "outputId": "86b4e534-ee02-45d5-9d38-00a95956a7da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip_25 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_zoom_11 (RandomZoom)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_25 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_translation_11 (Rando (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_crop_8 (RandomCrop)   (None, 85, 85, 3)         0         \n",
      "_________________________________________________________________\n",
      "rescaling_12 (Rescaling)     (None, 85, 85, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 83, 83, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 83, 83, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 41, 41, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 39, 39, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 39, 39, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 8,489,926\n",
      "Trainable params: 8,489,478\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeNet_06.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41pbvLC4ZVpV"
   },
   "source": [
    "##### **\"LeNet_07\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRf0UI4wZVpW",
    "outputId": "8672f80c-20f9-410f-c2ef-5824daf325c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip_34 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_34 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_135 (Bat (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_136 (Bat (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_137 (Bat (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 26,841,030\n",
      "Trainable params: 26,840,582\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LeNet_07.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpGLlxnjYvgH"
   },
   "source": [
    "### **\"VGG16\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KEQb6SjZMKk"
   },
   "source": [
    "##### **\"VGG16_01\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CaQs9QzeXL1L",
    "outputId": "1d786178-5ed7-4df0-bc43-530ca2b7d4e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_4 (Lambda)            (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_flip_10 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_10 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_4 (RandomCon (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 14,781,126\n",
      "Trainable params: 66,438\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_01.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTUm17I2ZM9K"
   },
   "source": [
    "##### **\"VGG16_02 (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWQYbFcMZNii",
    "outputId": "1069b442-7f5a-49bc-9bd7-9776b19b2735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip_11 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_11 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_5 (RandomCon (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 33,623,878\n",
      "Trainable params: 18,908,166\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_02.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJX7REG7YvEY"
   },
   "source": [
    "### **\"Xception\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0iOHQ4gaIcH"
   },
   "source": [
    "##### **\"Xception_01\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0IBPUOtaIcH",
    "outputId": "c8ed8203-7169-4c35-a152-d52f85c0fdee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_6 (Lambda)            (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 526)               1077774   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 526)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 258)               135966    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 6)                 1554      \n",
      "=================================================================\n",
      "Total params: 22,076,774\n",
      "Trainable params: 1,215,294\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_01.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FsRC2-qaIpo"
   },
   "source": [
    "##### **\"Xception_02\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fiDpyA3aIpp",
    "outputId": "322416a1-43d7-4570-ef3e-af605acf52a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip_27 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_27 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_14 (RandomCo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_15 (Lambda)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_15  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 124)               254076    \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 124)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 6)                 750       \n",
      "=================================================================\n",
      "Total params: 21,116,306\n",
      "Trainable params: 254,826\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_02.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFv6ApPvaI15"
   },
   "source": [
    "##### **\"Xception_03\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-69oppjaI16",
    "outputId": "a25a3f25-a817-45b4-fe0f-bb42370a71b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_8 (Lambda)            (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_flip_13 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_13 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_7 (RandomCon (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 21,124,526\n",
      "Trainable params: 263,046\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_03.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jrff_jVEaH4K"
   },
   "source": [
    "##### **\"Xception_04\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1MeBee9aH4L",
    "outputId": "deed8c67-d04f-4af3-9438-1b578cdd9c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_9 (Lambda)            (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_flip_14 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_14 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_8 (RandomCon (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 21,124,526\n",
      "Trainable params: 263,046\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_04.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsQmN-hEaIFK"
   },
   "source": [
    "##### **\"Xception_05\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMH_GdHAaIFL",
    "outputId": "b4c3f89f-f8af-4ff6-fbcf-2619475118e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_10 (Lambda)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_flip_15 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_15 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_9 (RandomCon (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10240)             20981760  \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 6)                 61446     \n",
      "=================================================================\n",
      "Total params: 41,904,698\n",
      "Trainable params: 21,043,212\n",
      "Non-trainable params: 20,861,486\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_05.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYzY-6o5aJMb"
   },
   "source": [
    "##### **\"Xception_06\" (RED NEURONAL CONVOLUCIONAL)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Az3RnaQbaJMc",
    "outputId": "d50893f9-1d83-4351-80cc-888ad872006b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_11 (Lambda)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_flip_16 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_16 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_10 (RandomCo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 29,278,778\n",
      "Trainable params: 8,417,292\n",
      "Non-trainable params: 20,861,486\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_06.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb39gIGKaJeO"
   },
   "source": [
    "##### **\"Xception_07\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMGUdMfuaJeP",
    "outputId": "668e20c2-5303-46ed-807d-0634c018601f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_12 (Lambda)           (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_flip_17 (RandomFlip)  (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_17 (RandomRo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_11 (RandomCo (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_12  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 20000)             40980000  \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 6)                 120006    \n",
      "=================================================================\n",
      "Total params: 61,961,498\n",
      "Trainable params: 41,100,012\n",
      "Non-trainable params: 20,861,486\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_07.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgFUDC1gaJuL"
   },
   "source": [
    "##### **\"Xception_08\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtFeG57uaJuM",
    "outputId": "9e4e2d1f-47c0-4d1c-d048-4dbaedd28be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_13 (Lambda)           (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_flip_18 (RandomFlip)  (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_18 (RandomRo (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_12 (RandomCo (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "resizing (Resizing)          (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_13  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 46,060,090\n",
      "Trainable params: 25,198,604\n",
      "Non-trainable params: 20,861,486\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_08.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl2OITK5aJAj"
   },
   "source": [
    "##### **\"Xception_09\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXyxADusaJAk",
    "outputId": "f16f6eac-192c-4ab0-b247-e48549bdd87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_14 (Lambda)           (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_flip_19 (RandomFlip)  (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_19 (RandomRo (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_13 (RandomCo (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "resizing_1 (Resizing)        (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 4, 4, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_14  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 46,060,090\n",
      "Trainable params: 25,198,604\n",
      "Non-trainable params: 20,861,486\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_09.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbTbAbnva_Np"
   },
   "source": [
    "##### **\"Xception_10\" (RED NEURONAL CONVOLUCIONAL)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-BN5FYZa_Nq",
    "outputId": "7ab89fdd-18f7-4a1a-9b08-813131406891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_flip_2 (RandomFlip)   (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation_2 (RandomRot (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_2 (RandomCon (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 299, 299, 3)       12        \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 10, 10, 2048)      20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 24582     \n",
      "=================================================================\n",
      "Total params: 46,060,090\n",
      "Trainable params: 25,198,604\n",
      "Non-trainable params: 20,861,486\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Xception_10.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "tMd6Lstb-ReB",
    "AtZUR7_gqnvR",
    "V1E2gtmYfNYY",
    "sQiDE3jqkcMy",
    "adsQItgxm4PH",
    "FMy__3-0p_ty",
    "fcWTLhRwwmvN",
    "nin-HurFEMCY",
    "RTY6-bwRRQvf",
    "rtljKZ7vOqGf",
    "wiFOqXoGTsGv",
    "OZiNZo-9YHK5",
    "d600a1euqORh",
    "G5ZGHguA0QlX",
    "FO-3S8YgaYqm",
    "6Mv5e1aP-idz",
    "plZRC1wpLVEF",
    "P5WXaOWz-aMt",
    "sVS3i-2XGP6k",
    "hCuXPSUVFKB0",
    "kve2ikWcFUAB",
    "VFmrXJ96FUm2",
    "F9UJgzmnFyLG",
    "yTlVNl7gcGPN",
    "gGnXI-noZLIr",
    "LrXSuv1NZQFr",
    "YXQR8J2BZQxf",
    "OG1ZCW0iZRWj",
    "0d8Qny30ZVVx",
    "VExKtwSmZVeV",
    "41pbvLC4ZVpV",
    "6KEQb6SjZMKk",
    "FTUm17I2ZM9K",
    "l0iOHQ4gaIcH",
    "0FsRC2-qaIpo",
    "SFv6ApPvaI15",
    "Jrff_jVEaH4K",
    "OsQmN-hEaIFK",
    "YYzY-6o5aJMb",
    "tb39gIGKaJeO",
    "GgFUDC1gaJuL",
    "Kl2OITK5aJAj",
    "jbTbAbnva_Np"
   ],
   "machine_shape": "hm",
   "name": "Practica_DL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
